{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Photoredox Yield Noise Detection Benchmark\n",
    "\n",
    "## Goal\n",
    "Compare **Old GGH (DBSCAN)** vs **New GGH (Soft Refinement)** for noise detection.\n",
    "\n",
    "## Challenge\n",
    "- **Unsupervised**: No labeled clean samples available during detection\n",
    "- **Simulated noise**: 30% of target values corrupted (range 0.4-0.6 around mean)\n",
    "- **Evaluation only**: Labels used only to measure detection performance\n",
    "\n",
    "## Methods Compared\n",
    "1. **Full Info (No Noise)**: Oracle upper bound\n",
    "2. **Full Info Noisy**: Baseline with noise, no removal\n",
    "3. **Old GGH (DBSCAN)**: Existing unsupervised clustering approach\n",
    "4. **New GGH (Soft Refinement)**: Bootstrap anchors from data, iterative refinement\n",
    "\n",
    "## Expected Results\n",
    "Based on old notebooks:\n",
    "- Full Info: R2 ~0.858\n",
    "- Full Info Noisy: R2 ~0.608\n",
    "- Old GGH: R2 ~0.674 (improvement of 0.066)\n",
    "- **Target**: New GGH R2 > 0.70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport sys\nimport math\nfrom copy import deepcopy\nsys.path.insert(0, '../')\nsys.path.insert(0, '../GGH')\n\nfrom GGH.data_ops import DataOperator\nfrom GGH.selection_algorithms import AlgoModulators\nfrom GGH.models import initialize_model\nfrom GGH.train_val_loop import TrainValidationManager\nfrom GGH.inspector import Inspector, get_gradarrays_n_labels\nfrom scipy import stats\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch.autograd import grad\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef set_to_deterministic(rand_state):\n    import random\n    random.seed(rand_state)\n    np.random.seed(rand_state)\n    torch.manual_seed(rand_state)\n    torch.set_num_threads(1)\n    torch.use_deterministic_algorithms(True)\n\nprint(\"Imports successful!\")\n\n# GPU Detection\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {DEVICE}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - Photoredox Yield Dataset\n",
    "# =============================================================================\n",
    "data_path = '../data/photoredox_yield/photo_redox_merck2021_1649reactions.csv'\n",
    "results_path = \"../saved_results/Photoredox Yield Noise Detection Benchmark\"\n",
    "\n",
    "# Variables\n",
    "inpt_vars = ['aryl_halides', 'photocalysts', 'piperidines_moles', 'photocalysts_moles']\n",
    "target_vars = ['uplcms']\n",
    "miss_vars = []\n",
    "hypothesis = [[0.02, 0.05, 0.50, 5.0]]\n",
    "\n",
    "# Model parameters\n",
    "hidden_size = 32\n",
    "output_size = len(target_vars)\n",
    "\n",
    "# Noise simulation parameters\n",
    "DATA_NOISE_PERC = 0.30  # 30% of data will have noise\n",
    "NOISE_MINRANGE = 0.40   # Noise factor range\n",
    "NOISE_MAXRANGE = 0.60\n",
    "noise_profile = {\n",
    "    \"DATA_NOISE_PERC\": DATA_NOISE_PERC,\n",
    "    \"NOISE_MINRANGE\": NOISE_MINRANGE,\n",
    "    \"NOISE_MAXRANGE\": NOISE_MAXRANGE\n",
    "}\n",
    "\n",
    "# Training parameters\n",
    "partial_perc = 0.3  # Not used for noise detection, but required by DataOperator\n",
    "batch_size = 299\n",
    "dropout = 0.05\n",
    "lr = 0.001\n",
    "nu = 0.1\n",
    "\n",
    "# Benchmark parameters\n",
    "BENCHMARK_N_RUNS = 15\n",
    "FULL_INFO_EPOCHS = 300\n",
    "NOISY_EPOCHS = 300\n",
    "\n",
    "# New GGH parameters\n",
    "GGH_ITER1_EPOCHS = 60\n",
    "GGH_ITER1_ANALYSIS_EPOCHS = 5\n",
    "GGH_ITER2_EPOCHS = 30\n",
    "GGH_FINAL_EPOCHS = 300\n",
    "GGH_MIN_WEIGHT = 0.1\n",
    "GGH_TEMPERATURE = 1.0\n",
    "GGH_NOISE_THRESHOLD = 0.3\n",
    "GGH_CLEAN_PERCENTILE = 0.60  # Bottom 60% by loss = likely clean\n",
    "\n",
    "# Old GGH (DBSCAN) parameters\n",
    "OLD_GGH_EPOCHS = 200\n",
    "OLD_GGH_END_EPOCHS = 10\n",
    "OLD_GGH_EPS_VALUES = [0.15, 0.25]\n",
    "OLD_GGH_MIN_SAMPLES_RATIOS = [0.15, 0.2, 0.25]\n",
    "\n",
    "# Create directories\n",
    "import os\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "\n",
    "print(f\"Dataset: Photoredox Yield\")\n",
    "print(f\"Noise simulation: {DATA_NOISE_PERC*100}% of data, range [{NOISE_MINRANGE}, {NOISE_MAXRANGE}]\")\n",
    "print(f\"Benchmark runs: {BENCHMARK_N_RUNS}\")\n",
    "print(f\"Results path: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helper_functions_header",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Shared utility functions for both old and new GGH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helper_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_stable(x):\n",
    "    \"\"\"Numerically stable sigmoid.\"\"\"\n",
    "    x = np.array(x, dtype=np.float64)\n",
    "    return np.where(x >= 0,\n",
    "                    1 / (1 + np.exp(-x)),\n",
    "                    np.exp(x) / (1 + np.exp(x)))\n",
    "\n",
    "def compute_soft_weights(scores, min_weight=0.1, temperature=1.0):\n",
    "    \"\"\"Convert scores to soft weights using sigmoid.\"\"\"\n",
    "    scores = np.array(scores, dtype=np.float64)\n",
    "    if len(scores) == 0:\n",
    "        return np.array([])\n",
    "    \n",
    "    mean_s = np.mean(scores)\n",
    "    std_s = np.std(scores) + 1e-8\n",
    "    normalized = (scores - mean_s) / std_s\n",
    "    \n",
    "    raw_weights = sigmoid_stable(normalized / temperature)\n",
    "    weights = min_weight + (1 - min_weight) * raw_weights\n",
    "    \n",
    "    return weights\n",
    "\n",
    "def evaluate_detection(detected_noisy_indices, true_noisy_indices, n_total):\n",
    "    \"\"\"Evaluate noise detection performance.\"\"\"\n",
    "    detected_set = set(detected_noisy_indices)\n",
    "    true_noisy_set = set(true_noisy_indices)\n",
    "    true_clean_set = set(range(n_total)) - true_noisy_set\n",
    "    \n",
    "    TP = len(detected_set & true_noisy_set)  # Correctly detected noisy\n",
    "    FP = len(detected_set & true_clean_set)  # Clean wrongly labeled as noisy\n",
    "    FN = len(true_noisy_set - detected_set)  # Noisy missed\n",
    "    TN = len(true_clean_set - detected_set)  # Clean correctly kept\n",
    "    \n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'TP': TP,\n",
    "        'FP': FP,\n",
    "        'FN': FN,\n",
    "        'TN': TN\n",
    "    }\n",
    "\n",
    "def full_info_run_existing_DO(DO, df_train_cleaned, r_state, num_epochs=300):\n",
    "    \"\"\"Train model on cleaned data (after noise removal).\"\"\"\n",
    "    use_info = \"full info\"\n",
    "    AM = AlgoModulators(DO, lr=lr)\n",
    "    DO_clean = DataOperator(data_path, inpt_vars, target_vars, miss_vars, hypothesis, \n",
    "                            partial_perc, r_state, pre_defined_train=df_train_cleaned, \n",
    "                            device=\"cpu\")\n",
    "    dataloader = DO_clean.prep_dataloader(use_info, batch_size)\n",
    "    model = initialize_model(DO_clean, dataloader, hidden_size, r_state, dropout=dropout)\n",
    "    TVM = TrainValidationManager(use_info, num_epochs, dataloader, batch_size, r_state, \n",
    "                                 results_path, best_valid_error=np.inf)\n",
    "    TVM.train_model(DO_clean, AM, model, final_analysis=False)\n",
    "    \n",
    "    return DO_clean, TVM, AM, model\n",
    "\n",
    "print(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "old_ggh_header",
   "metadata": {},
   "source": [
    "## Old GGH: DBSCAN-based Noise Detection\n",
    "\n",
    "Original approach from the noise detection notebooks:\n",
    "1. Train on noisy data\n",
    "2. Extract gradients\n",
    "3. Use DBSCAN clustering - outliers = noisy\n",
    "4. Grid search over eps and min_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "old_ggh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_old_ggh_dbscan(DO, r_state):\n",
    "    \"\"\"\n",
    "    Old GGH noise detection using DBSCAN clustering.\n",
    "    Returns best result from hyperparameter grid search.\n",
    "    \"\"\"\n",
    "    use_info = \"full info noisy\"\n",
    "    num_epochs = OLD_GGH_EPOCHS + OLD_GGH_END_EPOCHS\n",
    "    \n",
    "    best_result = None\n",
    "    best_val_error = np.inf\n",
    "    \n",
    "    for eps in OLD_GGH_EPS_VALUES:\n",
    "        for min_samples_ratio in OLD_GGH_MIN_SAMPLES_RATIOS:\n",
    "            set_to_deterministic(r_state)\n",
    "            \n",
    "            # Train on noisy data\n",
    "            AM = AlgoModulators(DO, lr=lr, eps_value=eps, min_samples_ratio=min_samples_ratio)\n",
    "            dataloader = DO.prep_dataloader(use_info, batch_size)\n",
    "            model = initialize_model(DO, dataloader, hidden_size, r_state, dropout=dropout)\n",
    "            \n",
    "            TVM = TrainValidationManager(use_info, num_epochs, dataloader, batch_size, r_state,\n",
    "                                        results_path, select_gradients=True,\n",
    "                                        end_epochs_noise_detection=OLD_GGH_END_EPOCHS,\n",
    "                                        best_valid_error=np.inf, final_analysis=False)\n",
    "            TVM.train_model(DO, AM, model, final_analysis=False)\n",
    "            \n",
    "            # Extract gradients\n",
    "            array_grads_context, do_hyp_class = get_gradarrays_n_labels(\n",
    "                DO, 0, layer=-2, remov_avg=False, include_context=False,\n",
    "                normalize_grads_context=False, loss_in_context=True, only_loss_context=True,\n",
    "                num_batches=math.ceil(len(DO.df_train_noisy) / batch_size),\n",
    "                epoch=TVM.best_checkpoint, use_case=\"noise_detection\"\n",
    "            )\n",
    "            \n",
    "            # DBSCAN clustering\n",
    "            dbscan = DBSCAN(eps=eps, min_samples=int(batch_size * min_samples_ratio))\n",
    "            pred_labels = dbscan.fit_predict(array_grads_context)\n",
    "            pred_labels = pred_labels * -1  # Invert: 1=noisy (outliers), 0=clean\n",
    "            \n",
    "            # Detect noisy samples (label == 1)\n",
    "            detected_noisy_indices = [i for i, label in enumerate(pred_labels) if label == 1]\n",
    "            \n",
    "            # Remove detected noisy and retrain\n",
    "            DO.df_train_noisy[\"noise_detected\"] = pred_labels\n",
    "            df_cleaned = deepcopy(DO.df_train_noisy[DO.df_train_noisy[\"noise_detected\"] == 0])\n",
    "            \n",
    "            DO_clean, TVM_clean, AM_clean, model_clean = full_info_run_existing_DO(\n",
    "                DO, df_cleaned, r_state, num_epochs=GGH_FINAL_EPOCHS\n",
    "            )\n",
    "            \n",
    "            # Keep best hyperparameters\n",
    "            if TVM_clean.best_valid_error < best_val_error:\n",
    "                best_val_error = TVM_clean.best_valid_error\n",
    "                \n",
    "                # Evaluate detection\n",
    "                true_noisy_indices = DO.df_train_noisy[DO.df_train_noisy['label'] == 1].index.tolist()\n",
    "                detection_metrics = evaluate_detection(\n",
    "                    detected_noisy_indices, true_noisy_indices, len(DO.df_train_noisy)\n",
    "                )\n",
    "                \n",
    "                # Test performance\n",
    "                model_clean.eval()\n",
    "                with torch.no_grad():\n",
    "                    test_inputs, test_targets = DO.get_test_tensors(use_info=\"full info\")\n",
    "                    test_preds = model_clean(test_inputs)\n",
    "                    ss_res = torch.sum((test_targets - test_preds) ** 2).item()\n",
    "                    ss_tot = torch.sum((test_targets - test_targets.mean()) ** 2).item()\n",
    "                    test_r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0.0\n",
    "                    test_mse = torch.nn.functional.mse_loss(test_preds, test_targets).item()\n",
    "                    test_mae = torch.nn.functional.l1_loss(test_preds, test_targets).item()\n",
    "                \n",
    "                best_result = {\n",
    "                    'eps': eps,\n",
    "                    'min_samples_ratio': min_samples_ratio,\n",
    "                    'test_r2': test_r2,\n",
    "                    'test_mse': test_mse,\n",
    "                    'test_mae': test_mae,\n",
    "                    'detection': detection_metrics,\n",
    "                    'n_detected': len(detected_noisy_indices),\n",
    "                    'n_removed': len(detected_noisy_indices),\n",
    "                }\n",
    "    \n",
    "    return best_result\n",
    "\n",
    "print(\"Old GGH (DBSCAN) function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new_ggh_header",
   "metadata": {},
   "source": [
    "## New GGH: Unsupervised Soft Refinement for Noise Detection\n",
    "\n",
    "Bootstrap approach:\n",
    "1. **Iter1**: Train unbiased \u2192 bootstrap clean/noisy anchors from loss distribution\n",
    "2. **Iter2**: Weighted training (high weight = likely clean)\n",
    "3. **Iter3**: Refined anchors \u2192 rescore samples\n",
    "4. **Detection**: Threshold on final weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "new_ggh_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNoiseDetectionModel(nn.Module):\n",
    "    \"\"\"Simple MLP for noise detection.\"\"\"\n",
    "    def __init__(self, n_features, hidden_size=32, output_size=1):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(n_features, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "print(\"Model defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opx556w3hw7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_new_ggh_unsupervised(DO, r_state):\n",
    "    \"\"\"\n",
    "    New GGH unsupervised noise detection using soft refinement.\n",
    "    \n",
    "    Bootstraps clean/noisy anchors from loss distribution, then iteratively refines.\n",
    "    NO LABELS USED during detection - fully unsupervised.\n",
    "    \"\"\"\n",
    "    n_features = len(inpt_vars)\n",
    "    n_samples = len(DO.df_train_noisy)\n",
    "    \n",
    "    # Create dataloader\n",
    "    train_features = torch.tensor(DO.df_train_noisy[inpt_vars].values, dtype=torch.float32)\n",
    "    train_targets = torch.tensor(DO.df_train_noisy[target_vars].values, dtype=torch.float32)\n",
    "    sample_indices = torch.arange(n_samples)\n",
    "    dataset = TensorDataset(train_features, train_targets, sample_indices)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # ITERATION 1: Unbiased training + Bootstrap anchors from loss distribution\n",
    "    # =============================================================================\n",
    "    print(\"  Iter1: Unbiased training + bootstrap anchors...\")\n",
    "    set_to_deterministic(r_state)\n",
    "    model_iter1 = SimpleNoiseDetectionModel(n_features, hidden_size, output_size)\n",
    "    optimizer = torch.optim.Adam(model_iter1.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss(reduction='none')\n",
    "    \n",
    "    # Track losses and gradients\n",
    "    sample_losses = {i: [] for i in range(n_samples)}\n",
    "    sample_gradients = {i: [] for i in range(n_samples)}\n",
    "    \n",
    "    # Train for total epochs, track during last few\n",
    "    total_iter1_epochs = GGH_ITER1_EPOCHS\n",
    "    track_start = GGH_ITER1_EPOCHS - GGH_ITER1_ANALYSIS_EPOCHS\n",
    "    \n",
    "    for epoch in range(total_iter1_epochs):\n",
    "        model_iter1.train()\n",
    "        track_this_epoch = (epoch >= track_start)\n",
    "        \n",
    "        for features, targets, indices in dataloader:\n",
    "            predictions = model_iter1(features)\n",
    "            losses = criterion(predictions, targets).squeeze()\n",
    "            batch_loss = losses.mean()\n",
    "            \n",
    "            if track_this_epoch:\n",
    "                # Track per-sample losses\n",
    "                for i, idx in enumerate(indices):\n",
    "                    sample_losses[idx.item()].append(losses[i].item())\n",
    "                \n",
    "                # Track per-sample gradients\n",
    "                for i, idx in enumerate(indices):\n",
    "                    feat = features[i:i+1].clone().requires_grad_(True)\n",
    "                    pred = model_iter1(feat)\n",
    "                    loss = criterion(pred, targets[i:i+1]).mean()\n",
    "                    \n",
    "                    params = list(model_iter1.parameters())\n",
    "                    grad_param = grad(loss, params[-2], retain_graph=False)[0]\n",
    "                    grad_vec = grad_param.flatten().detach().cpu().numpy()\n",
    "                    sample_gradients[idx.item()].append(grad_vec)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Compute average losses and gradients\n",
    "    avg_losses = {i: np.mean(sample_losses[i]) for i in range(n_samples) if sample_losses[i]}\n",
    "    avg_gradients = {i: np.mean(sample_gradients[i], axis=0) for i in range(n_samples) if sample_gradients[i]}\n",
    "    \n",
    "    # Bootstrap clean/noisy candidates from loss distribution (UNSUPERVISED)\n",
    "    loss_values = np.array([avg_losses[i] for i in range(n_samples)])\n",
    "    loss_threshold = np.percentile(loss_values, GGH_CLEAN_PERCENTILE * 100)\n",
    "    \n",
    "    clean_candidates = [i for i in range(n_samples) if avg_losses[i] <= loss_threshold]\n",
    "    noisy_candidates = [i for i in range(n_samples) if avg_losses[i] > loss_threshold]\n",
    "    \n",
    "    print(f\"    Bootstrapped: {len(clean_candidates)} clean, {len(noisy_candidates)} noisy candidates\")\n",
    "    \n",
    "    # Build initial anchors\n",
    "    if clean_candidates and noisy_candidates:\n",
    "        clean_anchor_grad = np.mean([avg_gradients[i] for i in clean_candidates if i in avg_gradients], axis=0)\n",
    "        noisy_anchor_grad = np.mean([avg_gradients[i] for i in noisy_candidates if i in avg_gradients], axis=0)\n",
    "        \n",
    "        # Score all samples\n",
    "        sample_scores = {}\n",
    "        for i in range(n_samples):\n",
    "            if i not in avg_gradients:\n",
    "                sample_scores[i] = 0.0\n",
    "                continue\n",
    "            \n",
    "            grad = avg_gradients[i]\n",
    "            sim_clean = np.dot(grad, clean_anchor_grad) / (np.linalg.norm(grad) * np.linalg.norm(clean_anchor_grad) + 1e-8)\n",
    "            sim_noisy = np.dot(grad, noisy_anchor_grad) / (np.linalg.norm(grad) * np.linalg.norm(noisy_anchor_grad) + 1e-8)\n",
    "            sample_scores[i] = float(sim_clean - sim_noisy)\n",
    "        \n",
    "        # Convert to soft weights\n",
    "        scores_list = [sample_scores[i] for i in range(n_samples)]\n",
    "        sample_weights = compute_soft_weights(scores_list, GGH_MIN_WEIGHT, GGH_TEMPERATURE)\n",
    "        sample_weights_dict = {i: float(sample_weights[i]) for i in range(n_samples)}\n",
    "    else:\n",
    "        print(\"    Warning: Could not bootstrap anchors, using uniform weights\")\n",
    "        sample_weights_dict = {i: 0.5 for i in range(n_samples)}\n",
    "    \n",
    "    avg_weight = np.mean(list(sample_weights_dict.values()))\n",
    "    print(f\"    Avg weight: {avg_weight:.3f}\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # ITERATION 2: Weighted training (high weight = likely clean)\n",
    "    # =============================================================================\n",
    "    print(\"  Iter2: Weighted training...\")\n",
    "    set_to_deterministic(r_state + 100)\n",
    "    model_iter2 = SimpleNoiseDetectionModel(n_features, hidden_size, output_size)\n",
    "    optimizer2 = torch.optim.Adam(model_iter2.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(GGH_ITER2_EPOCHS):\n",
    "        model_iter2.train()\n",
    "        for features, targets, indices in dataloader:\n",
    "            predictions = model_iter2(features)\n",
    "            losses = criterion(predictions, targets).squeeze()\n",
    "            \n",
    "            # Weight by Iter1 scores\n",
    "            weights = torch.tensor([sample_weights_dict[idx.item()] for idx in indices], dtype=torch.float32)\n",
    "            weighted_loss = (losses * weights).sum() / weights.sum()\n",
    "            \n",
    "            optimizer2.zero_grad()\n",
    "            weighted_loss.backward()\n",
    "            optimizer2.step()\n",
    "    \n",
    "    # =============================================================================\n",
    "    # ITERATION 3: Refined anchors from biased model\n",
    "    # =============================================================================\n",
    "    print(\"  Iter3: Refined anchors + rescoring...\")\n",
    "    model_iter2.eval()\n",
    "    \n",
    "    # Recompute losses and gradients with biased model\n",
    "    iter3_losses = {i: [] for i in range(n_samples)}\n",
    "    iter3_gradients = {i: [] for i in range(n_samples)}\n",
    "    \n",
    "    for _ in range(3):  # Multiple passes for stability\n",
    "        for features, targets, indices in dataloader:\n",
    "            for i, idx in enumerate(indices):\n",
    "                feat = features[i:i+1].clone().requires_grad_(True)\n",
    "                pred = model_iter2(feat)\n",
    "                loss = criterion(pred, targets[i:i+1]).mean()\n",
    "                \n",
    "                iter3_losses[idx.item()].append(loss.item())\n",
    "                \n",
    "                params = list(model_iter2.parameters())\n",
    "                grad_param = grad(loss, params[-2], retain_graph=False)[0]\n",
    "                grad_vec = grad_param.flatten().detach().cpu().numpy()\n",
    "                iter3_gradients[idx.item()].append(grad_vec)\n",
    "    \n",
    "    avg_iter3_losses = {i: np.mean(iter3_losses[i]) for i in range(n_samples) if iter3_losses[i]}\n",
    "    avg_iter3_gradients = {i: np.mean(iter3_gradients[i], axis=0) for i in range(n_samples) if iter3_gradients[i]}\n",
    "    \n",
    "    # Refined anchors: use top-weighted samples from Iter1\n",
    "    weight_threshold_top = np.percentile(list(sample_weights_dict.values()), 70)\n",
    "    weight_threshold_bottom = np.percentile(list(sample_weights_dict.values()), 30)\n",
    "    \n",
    "    refined_clean = [i for i in range(n_samples) if sample_weights_dict[i] >= weight_threshold_top]\n",
    "    refined_noisy = [i for i in range(n_samples) if sample_weights_dict[i] <= weight_threshold_bottom]\n",
    "    \n",
    "    if refined_clean and refined_noisy:\n",
    "        refined_clean_anchor = np.mean([avg_iter3_gradients[i] for i in refined_clean if i in avg_iter3_gradients], axis=0)\n",
    "        refined_noisy_anchor = np.mean([avg_iter3_gradients[i] for i in refined_noisy if i in avg_iter3_gradients], axis=0)\n",
    "        \n",
    "        # Rescore all samples\n",
    "        iter3_scores = {}\n",
    "        for i in range(n_samples):\n",
    "            if i not in avg_iter3_gradients:\n",
    "                iter3_scores[i] = 0.0\n",
    "                continue\n",
    "            \n",
    "            grad = avg_iter3_gradients[i]\n",
    "            sim_clean = np.dot(grad, refined_clean_anchor) / (np.linalg.norm(grad) * np.linalg.norm(refined_clean_anchor) + 1e-8)\n",
    "            sim_noisy = np.dot(grad, refined_noisy_anchor) / (np.linalg.norm(grad) * np.linalg.norm(refined_noisy_anchor) + 1e-8)\n",
    "            iter3_scores[i] = float(sim_clean - sim_noisy)\n",
    "        \n",
    "        scores_list_iter3 = [iter3_scores[i] for i in range(n_samples)]\n",
    "        weights_iter3 = compute_soft_weights(scores_list_iter3, GGH_MIN_WEIGHT, GGH_TEMPERATURE)\n",
    "        \n",
    "        # Multiply weights (iterative refinement)\n",
    "        for i in range(n_samples):\n",
    "            sample_weights_dict[i] = sample_weights_dict[i] * weights_iter3[i]\n",
    "        \n",
    "        # Normalize to [GGH_MIN_WEIGHT, 1.0]\n",
    "        max_weight = max(sample_weights_dict.values())\n",
    "        if max_weight > 0:\n",
    "            for i in range(n_samples):\n",
    "                sample_weights_dict[i] = GGH_MIN_WEIGHT + (sample_weights_dict[i] / max_weight) * (1 - GGH_MIN_WEIGHT)\n",
    "    \n",
    "    avg_weight_iter3 = np.mean(list(sample_weights_dict.values()))\n",
    "    print(f\"    Avg weight after refinement: {avg_weight_iter3:.3f}\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # DETECTION: Threshold on final weights\n",
    "    # =============================================================================\n",
    "    print(\"  Detection: Thresholding weights...\")\n",
    "    \n",
    "    # Method 1: Fixed threshold\n",
    "    detected_noisy_indices = [i for i in range(n_samples) if sample_weights_dict[i] < GGH_NOISE_THRESHOLD]\n",
    "    \n",
    "    # Method 2: Percentage-based (if we expect specific noise rate)\n",
    "    # sorted_by_weight = sorted(range(n_samples), key=lambda i: sample_weights_dict[i])\n",
    "    # n_expected_noisy = int(n_samples * DATA_NOISE_PERC)\n",
    "    # detected_noisy_indices = sorted_by_weight[:n_expected_noisy]\n",
    "    \n",
    "    print(f\"    Detected {len(detected_noisy_indices)} noisy samples (threshold={GGH_NOISE_THRESHOLD})\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # RETRAIN on cleaned data\n",
    "    # =============================================================================\n",
    "    print(\"  Retraining on cleaned data...\")\n",
    "    df_cleaned = DO.df_train_noisy.drop(index=detected_noisy_indices).reset_index(drop=True)\n",
    "    \n",
    "    DO_clean, TVM_clean, AM_clean, model_clean = full_info_run_existing_DO(\n",
    "        DO, df_cleaned, r_state, num_epochs=GGH_FINAL_EPOCHS\n",
    "    )\n",
    "    \n",
    "    # Evaluate detection (labels used only here for evaluation)\n",
    "    true_noisy_indices = DO.df_train_noisy[DO.df_train_noisy['label'] == 1].index.tolist()\n",
    "    detection_metrics = evaluate_detection(detected_noisy_indices, true_noisy_indices, n_samples)\n",
    "    \n",
    "    # Test performance\n",
    "    model_clean.eval()\n",
    "    with torch.no_grad():\n",
    "        test_inputs, test_targets = DO.get_test_tensors(use_info=\"full info\")\n",
    "        test_preds = model_clean(test_inputs)\n",
    "        ss_res = torch.sum((test_targets - test_preds) ** 2).item()\n",
    "        ss_tot = torch.sum((test_targets - test_targets.mean()) ** 2).item()\n",
    "        test_r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0.0\n",
    "        test_mse = torch.nn.functional.mse_loss(test_preds, test_targets).item()\n",
    "        test_mae = torch.nn.functional.l1_loss(test_preds, test_targets).item()\n",
    "    \n",
    "    return {\n",
    "        'test_r2': test_r2,\n",
    "        'test_mse': test_mse,\n",
    "        'test_mae': test_mae,\n",
    "        'detection': detection_metrics,\n",
    "        'n_detected': len(detected_noisy_indices),\n",
    "        'sample_weights': sample_weights_dict,\n",
    "    }\n",
    "\n",
    "print(\"New GGH (Unsupervised) function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0hfi2hti8fg",
   "metadata": {},
   "source": [
    "## Benchmark: Compare All Methods\n",
    "\n",
    "Run 15 trials comparing:\n",
    "1. Full Info (no noise) - oracle\n",
    "2. Full Info Noisy (with noise, no removal) - baseline\n",
    "3. Old GGH (DBSCAN)\n",
    "4. New GGH (Unsupervised Soft Refinement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vhfu7j7fn2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BENCHMARK EXECUTION\n",
    "# =============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"BENCHMARK: Old GGH vs New GGH for Noise Detection\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Dataset: Photoredox Yield\")\n",
    "print(f\"Noise: {DATA_NOISE_PERC*100}% of data, range [{NOISE_MINRANGE}, {NOISE_MAXRANGE}]\")\n",
    "print(f\"Runs: {BENCHMARK_N_RUNS}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_results = {\n",
    "    'Full Info': [],\n",
    "    'Full Info Noisy': [],\n",
    "    'Old GGH': [],\n",
    "    'New GGH': [],\n",
    "}\n",
    "\n",
    "for run_idx in range(BENCHMARK_N_RUNS):\n",
    "    r_state = run_idx\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"RUN {run_idx + 1}/{BENCHMARK_N_RUNS} (r_state={r_state})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # === Create DO with noise ===\n",
    "    set_to_deterministic(r_state)\n",
    "    DO = DataOperator(data_path, inpt_vars, target_vars, miss_vars, hypothesis,\n",
    "                      partial_perc, r_state, device=\"cpu\", use_case=\"noise detection\")\n",
    "    DO.simulate_noise(DATA_NOISE_PERC, NOISE_MINRANGE, NOISE_MAXRANGE)\n",
    "    \n",
    "    true_noisy_indices = DO.df_train_noisy[DO.df_train_noisy['label'] == 1].index.tolist()\n",
    "    n_total = len(DO.df_train_noisy)\n",
    "    print(f\"True noisy samples: {len(true_noisy_indices)}/{n_total} ({len(true_noisy_indices)/n_total*100:.1f}%)\")\n",
    "    \n",
    "    # === Full Info (No Noise) ===\n",
    "    print(\\\"\\\\nFull Info (no noise)...\\\")\n",
    "    set_to_deterministic(r_state)\n",
    "    DO_full = DataOperator(data_path, inpt_vars, target_vars, miss_vars, hypothesis,\n",
    "                           partial_perc, r_state, device=\\\"cpu\\\", use_case=\\\"noise detection\\\")\n",
    "    AM_full = AlgoModulators(DO_full, lr=lr)\n",
    "    dataloader_full = DO_full.prep_dataloader(\\\"full info\\\", batch_size)\n",
    "    model_full = initialize_model(DO_full, dataloader_full, hidden_size, r_state, dropout=dropout)\n",
    "    TVM_full = TrainValidationManager(\\\"full info\\\", FULL_INFO_EPOCHS, dataloader_full, batch_size,\n",
    "                                     r_state, results_path, select_gradients=True, final_analysis=False)\n",
    "    TVM_full.train_model(DO_full, AM_full, model_full, final_analysis=False)\n",
    "    \n",
    "    model_full.eval()\n",
    "    with torch.no_grad():\n",
    "        test_inputs, test_targets = DO_full.get_test_tensors(use_info=\\\"full info\\\")\n",
    "        test_preds = model_full(test_inputs)\n",
    "        ss_res = torch.sum((test_targets - test_preds) ** 2).item()\n",
    "        ss_tot = torch.sum((test_targets - test_targets.mean()) ** 2).item()\n",
    "        full_r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0.0\n",
    "    \n",
    "    all_results['Full Info'].append({'test_r2': full_r2})\n",
    "    print(f\\\"  R2: {full_r2:.4f}\\\")\n",
    "    \n",
    "    # === Full Info Noisy (Baseline) ===\n",
    "    print(\\\"\\\\nFull Info Noisy (baseline)...\\\")\n",
    "    set_to_deterministic(r_state)\n",
    "    AM_noisy = AlgoModulators(DO, lr=lr)\n",
    "    dataloader_noisy = DO.prep_dataloader(\\\"full info noisy\\\", batch_size)\n",
    "    model_noisy = initialize_model(DO, dataloader_noisy, hidden_size, r_state, dropout=dropout)\n",
    "    TVM_noisy = TrainValidationManager(\\\"full info noisy\\\", NOISY_EPOCHS, dataloader_noisy, batch_size,\n",
    "                                      r_state, results_path, select_gradients=True, final_analysis=False)\n",
    "    TVM_noisy.train_model(DO, AM_noisy, model_noisy, final_analysis=False)\n",
    "    \n",
    "    model_noisy.eval()\n",
    "    with torch.no_grad():\n",
    "        test_inputs, test_targets = DO.get_test_tensors(use_info=\\\"full info\\\")\n",
    "        test_preds = model_noisy(test_inputs)\n",
    "        ss_res = torch.sum((test_targets - test_preds) ** 2).item()\n",
    "        ss_tot = torch.sum((test_targets - test_targets.mean()) ** 2).item()\n",
    "        noisy_r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0.0\n",
    "    \n",
    "    all_results['Full Info Noisy'].append({'test_r2': noisy_r2})\n",
    "    print(f\\\"  R2: {noisy_r2:.4f}\\\")\n",
    "    \n",
    "    # === Old GGH (DBSCAN) ===\n",
    "    print(\\\"\\\\nOld GGH (DBSCAN)...\\\")\n",
    "    old_result = run_old_ggh_dbscan(DO, r_state)\n",
    "    all_results['Old GGH'].append(old_result)\n",
    "    print(f\\\"  R2: {old_result['test_r2']:.4f}\\\")\n",
    "    print(f\\\"  Detection - Precision: {old_result['detection']['precision']:.3f}, Recall: {old_result['detection']['recall']:.3f}\\\")\n",
    "    \n",
    "    # === New GGH (Unsupervised) ===\n",
    "    print(\\\"\\\\nNew GGH (Unsupervised)...\\\")\n",
    "    new_result = run_new_ggh_unsupervised(DO, r_state)\n",
    "    all_results['New GGH'].append(new_result)\n",
    "    print(f\\\"  R2: {new_result['test_r2']:.4f}\\\")\n",
    "    print(f\\\"  Detection - Precision: {new_result['detection']['precision']:.3f}, Recall: {new_result['detection']['recall']:.3f}\\\")\n",
    "    \n",
    "    # Run summary\n",
    "    print(f\\\"\\\\n>>> Summary for Run {run_idx + 1}:\\\")\n",
    "    print(f\\\"    Full Info: {full_r2:.4f}\\\")\n",
    "    print(f\\\"    Full Noisy: {noisy_r2:.4f}\\\")\n",
    "    print(f\\\"    Old GGH: {old_result['test_r2']:.4f} (vs noisy: {old_result['test_r2'] - noisy_r2:+.4f})\\\")\n",
    "    print(f\\\"    New GGH: {new_result['test_r2']:.4f} (vs noisy: {new_result['test_r2'] - noisy_r2:+.4f})\\\")\n",
    "\n",
    "print(f\\\"\\\\n{'='*80}\\\")\n",
    "print(\\\"BENCHMARK COMPLETE\\\")\n",
    "print(f\\\"{'='*80}\\\")\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ip0o4fu9dl",
   "metadata": {},
   "source": [
    "## Results Summary & Visualization\n",
    "\n",
    "Statistical comparison and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kuyqedri9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SUMMARY STATISTICS\n",
    "# =============================================================================\n",
    "print(\"\\\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Extract R2 scores\n",
    "full_r2_list = [r['test_r2'] for r in all_results['Full Info']]\n",
    "noisy_r2_list = [r['test_r2'] for r in all_results['Full Info Noisy']]\n",
    "old_r2_list = [r['test_r2'] for r in all_results['Old GGH']]\n",
    "new_r2_list = [r['test_r2'] for r in all_results['New GGH']]\n",
    "\n",
    "# R2 statistics\n",
    "print(f\\\"\\\\nTest R2 Score:\\\")\n",
    "print(f\\\"  Full Info (Oracle):    {np.mean(full_r2_list):.4f} \u00b1 {np.std(full_r2_list):.4f}\\\")\n",
    "print(f\\\"  Full Noisy (Baseline): {np.mean(noisy_r2_list):.4f} \u00b1 {np.std(noisy_r2_list):.4f}\\\")\n",
    "print(f\\\"  Old GGH (DBSCAN):      {np.mean(old_r2_list):.4f} \u00b1 {np.std(old_r2_list):.4f}\\\")\n",
    "print(f\\\"  New GGH (Soft Ref):    {np.mean(new_r2_list):.4f} \u00b1 {np.std(new_r2_list):.4f}\\\")\n",
    "\n",
    "# Detection statistics\n",
    "old_precision_list = [r['detection']['precision'] for r in all_results['Old GGH']]\n",
    "old_recall_list = [r['detection']['recall'] for r in all_results['Old GGH']]\n",
    "new_precision_list = [r['detection']['precision'] for r in all_results['New GGH']]\n",
    "new_recall_list = [r['detection']['recall'] for r in all_results['New GGH']]\n",
    "\n",
    "print(f\\\"\\\\nDetection Metrics:\\\")\n",
    "print(f\\\"  Old GGH - Precision: {np.mean(old_precision_list):.3f} \u00b1 {np.std(old_precision_list):.3f}\\\")\n",
    "print(f\\\"  Old GGH - Recall:    {np.mean(old_recall_list):.3f} \u00b1 {np.std(old_recall_list):.3f}\\\")\n",
    "print(f\\\"  New GGH - Precision: {np.mean(new_precision_list):.3f} \u00b1 {np.std(new_precision_list):.3f}\\\")\n",
    "print(f\\\"  New GGH - Recall:    {np.mean(new_recall_list):.3f} \u00b1 {np.std(new_recall_list):.3f}\\\")\n",
    "\n",
    "# Statistical tests\n",
    "print(f\\\"\\\\n\\\" + \\\"=\\\" * 80)\n",
    "print(\\\"STATISTICAL TESTS (Paired t-test)\\\")\n",
    "print(\\\"=\\\" * 80)\n",
    "\n",
    "# New GGH vs Old GGH\n",
    "t_stat, p_val = stats.ttest_rel(new_r2_list, old_r2_list)\n",
    "diff = np.mean(new_r2_list) - np.mean(old_r2_list)\n",
    "sig = '***' if p_val < 0.001 else '**' if p_val < 0.01 else '*' if p_val < 0.05 else ''\n",
    "print(f\\\"\\\\nNew GGH vs Old GGH:\\\")\n",
    "print(f\\\"  Difference: {diff:+.4f}\\\")\n",
    "print(f\\\"  t={t_stat:.3f}, p={p_val:.6f} {sig}\\\")\n",
    "if diff > 0 and p_val < 0.05:\n",
    "    print(f\\\"  >>> New GGH SIGNIFICANTLY OUTPERFORMS Old GGH\\\")\n",
    "elif diff < 0 and p_val < 0.05:\n",
    "    print(f\\\"  >>> Old GGH significantly outperforms New GGH\\\")\n",
    "else:\n",
    "    print(f\\\"  >>> No significant difference\\\")\n",
    "\n",
    "# New GGH vs Noisy Baseline\n",
    "t_stat2, p_val2 = stats.ttest_rel(new_r2_list, noisy_r2_list)\n",
    "diff2 = np.mean(new_r2_list) - np.mean(noisy_r2_list)\n",
    "sig2 = '***' if p_val2 < 0.001 else '**' if p_val2 < 0.01 else '*' if p_val2 < 0.05 else ''\n",
    "print(f\\\"\\\\nNew GGH vs Noisy Baseline:\\\")\n",
    "print(f\\\"  Difference: {diff2:+.4f}\\\")\n",
    "print(f\\\"  t={t_stat2:.3f}, p={p_val2:.6f} {sig2}\\\")\n",
    "\n",
    "# =============================================================================\n",
    "# VISUALIZATIONS\n",
    "# =============================================================================\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: R2 Comparison\n",
    "ax1 = axes[0, 0]\n",
    "methods = ['Full Info', 'New GGH', 'Old GGH', 'Noisy']\n",
    "r2_means = [np.mean(full_r2_list), np.mean(new_r2_list), np.mean(old_r2_list), np.mean(noisy_r2_list)]\n",
    "r2_stds = [np.std(full_r2_list), np.std(new_r2_list), np.std(old_r2_list), np.std(noisy_r2_list)]\n",
    "colors = ['#2ecc71', '#3498db', '#9b59b6', '#e74c3c']\n",
    "\n",
    "bars = ax1.bar(range(len(methods)), r2_means, yerr=r2_stds, capsize=5, color=colors, \n",
    "               edgecolor='black', linewidth=1.2)\n",
    "ax1.set_ylabel('Test R2 Score', fontsize=12)\n",
    "ax1.set_title('Test R2 Score Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(range(len(methods)))\n",
    "ax1.set_xticklabels(methods, fontsize=11)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "for bar, val in zip(bars, r2_means):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, f'{val:.3f}',\n",
    "             ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Plot 2: Per-run R2 Comparison (New vs Old GGH)\n",
    "ax2 = axes[0, 1]\n",
    "x = np.arange(BENCHMARK_N_RUNS)\n",
    "width = 0.35\n",
    "ax2.bar(x - width/2, old_r2_list, width, label='Old GGH', color='#9b59b6', alpha=0.7)\n",
    "ax2.bar(x + width/2, new_r2_list, width, label='New GGH', color='#3498db', alpha=0.7)\n",
    "ax2.set_xlabel('Run')\n",
    "ax2.set_ylabel('Test R2')\n",
    "ax2.set_title('Per-Run R2 Comparison')\n",
    "ax2.legend()\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels([str(i+1) for i in range(BENCHMARK_N_RUNS)])\n",
    "\n",
    "# Plot 3: Detection Precision & Recall\n",
    "ax3 = axes[1, 0]\n",
    "x_pos = np.arange(2)\n",
    "width = 0.35\n",
    "precision_means = [np.mean(old_precision_list), np.mean(new_precision_list)]\n",
    "recall_means = [np.mean(old_recall_list), np.mean(new_recall_list)]\n",
    "ax3.bar(x_pos - width/2, precision_means, width, label='Precision', color='#2ecc71', alpha=0.7)\n",
    "ax3.bar(x_pos + width/2, recall_means, width, label='Recall', color='#e74c3c', alpha=0.7)\n",
    "ax3.set_ylabel('Score')\n",
    "ax3.set_title('Detection Metrics Comparison')\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels(['Old GGH', 'New GGH'])\n",
    "ax3.legend()\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "for i, (prec, rec) in enumerate(zip(precision_means, recall_means)):\n",
    "    ax3.text(i - width/2, prec + 0.02, f'{prec:.2f}', ha='center', fontsize=10, fontweight='bold')\n",
    "    ax3.text(i + width/2, rec + 0.02, f'{rec:.2f}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Plot 4: Improvement Distribution\n",
    "ax4 = axes[1, 1]\n",
    "improvements_vs_old = [new - old for new, old in zip(new_r2_list, old_r2_list)]\n",
    "improvements_vs_noisy = [new - noisy for new, noisy in zip(new_r2_list, noisy_r2_list)]\n",
    "ax4.hist(improvements_vs_old, bins=10, alpha=0.6, label='New vs Old GGH', color='#3498db')\n",
    "ax4.hist(improvements_vs_noisy, bins=10, alpha=0.6, label='New vs Noisy', color='#e74c3c')\n",
    "ax4.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "ax4.axvline(x=np.mean(improvements_vs_old), color='#3498db', linestyle='--', linewidth=2)\n",
    "ax4.axvline(x=np.mean(improvements_vs_noisy), color='#e74c3c', linestyle='--', linewidth=2)\n",
    "ax4.set_xlabel('R2 Improvement')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.set_title('Improvement Distribution')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{results_path}/benchmark_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# FINAL CONCLUSION\n",
    "# =============================================================================\n",
    "print(f\\\"\\\\n\\\" + \\\"=\\\" * 80)\n",
    "print(\\\"FINAL CONCLUSION\\\")\n",
    "print(f\\\"=\\\" * 80)\n",
    "print(f\\\"\\\\nExpected (from old notebooks):\\\")\n",
    "print(f\\\"  Full Info: R2 ~0.858\\\")\n",
    "print(f\\\"  Noisy: R2 ~0.608\\\")\n",
    "print(f\\\"  Old GGH: R2 ~0.674 (improvement of 0.066)\\\")\n",
    "print(f\\\"\\\\nActual Results:\\\")\n",
    "print(f\\\"  Full Info: R2 {np.mean(full_r2_list):.4f}\\\")\n",
    "print(f\\\"  Noisy: R2 {np.mean(noisy_r2_list):.4f}\\\")\n",
    "print(f\\\"  Old GGH: R2 {np.mean(old_r2_list):.4f} (improvement of {np.mean(old_r2_list) - np.mean(noisy_r2_list):+.4f})\\\")\n",
    "print(f\\\"  New GGH: R2 {np.mean(new_r2_list):.4f} (improvement of {np.mean(new_r2_list) - np.mean(noisy_r2_list):+.4f})\\\")\n",
    "print(f\\\"\\\\n>>> New GGH vs Old GGH: {diff:+.4f} (p={p_val:.4f})\\\")\n",
    "\n",
    "if np.mean(new_r2_list) > 0.70:\n",
    "    print(f\\\"\\\\n\u2713 SUCCESS: New GGH exceeds target R2 > 0.70\\\")\n",
    "else:\n",
    "    print(f\\\"\\\\n\u2717 Target not met: R2 {np.mean(new_r2_list):.4f} < 0.70\\\")\n",
    "\n",
    "print(f\\\"\\\\n\\\" + \\\"=\\\" * 80)\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-michael_20250605]",
   "language": "python",
   "name": "conda-env-.conda-michael_20250605-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}