{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Photocell Degradation - Noise Detection Benchmark (v2)\n",
    "\n",
    "## Goal\n",
    "Benchmark GGH as a noise detection method on the Photocell Degradation dataset.\n",
    "\n",
    "## Challenge\n",
    "- **Simulated noise**: 40% of target values corrupted (range 0.4-0.6 around mean)\n",
    "- **Unsupervised**: No labeled clean samples available during detection\n",
    "- **Evaluation only**: Ground truth labels used only to measure detection performance\n",
    "\n",
    "## Methods Compared\n",
    "1. **Full Info (No Noise)**: Oracle upper bound - trained on clean data\n",
    "2. **Full Info Noisy**: Baseline - trained on noisy data without removal\n",
    "3. **Old GGH (DBSCAN)**: Gradient extraction + DBSCAN clustering + retrain on cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# CUDA determinism fix (must be before torch import)\n",
    "import os\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "sys.path.insert(0, '../GGH')\n",
    "\n",
    "from GGH.data_ops import DataOperator\n",
    "from GGH_2.noise_detection import (\n",
    "    set_to_deterministic,\n",
    "    run_full_info,\n",
    "    run_full_info_noisy,\n",
    "    run_old_ggh_dbscan,\n",
    "    run_old_ggh_dbscan_fast,\n",
    ")\n",
    "from GGH_2.noise_detection_viz import plot_all_noise_detection_metrics\n",
    "from GGH_2.benchmark_viz import save_noise_detection_results, load_noise_detection_results\n",
    "\n",
    "print('Imports successful!')\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Photocell Degradation\n",
      "Noise simulation: 40.0% of data, range [0.4, 0.6]\n",
      "Benchmark runs: 15\n",
      "Results path: ../saved_results/Photocell_Noise_Detection_v2\n",
      "Include original Old GGH (slow): False\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - Photocell Degradation Dataset\n",
    "# =============================================================================\n",
    "data_path = '../data/dataset_photo_pce10/data.csv'\n",
    "results_path = '../saved_results/Photocell_Noise_Detection_v2'\n",
    "\n",
    "# Variables\n",
    "inpt_vars = ['P3HT', 'PTB7-Th', 'PCBM']\n",
    "target_vars = ['Degradation']\n",
    "miss_vars = []\n",
    "hypothesis = [[1, 2, 3]]\n",
    "\n",
    "# Model parameters\n",
    "hidden_size = 32\n",
    "dropout = 0.05\n",
    "lr = 0.001\n",
    "\n",
    "# Noise simulation parameters\n",
    "DATA_NOISE_PERC = 0.40  # 40% of data will have noise\n",
    "NOISE_MINRANGE = 0.40   # Noise factor range\n",
    "NOISE_MAXRANGE = 0.60\n",
    "noise_profile = {\n",
    "    'DATA_NOISE_PERC': DATA_NOISE_PERC,\n",
    "    'NOISE_MINRANGE': NOISE_MINRANGE,\n",
    "    'NOISE_MAXRANGE': NOISE_MAXRANGE\n",
    "}\n",
    "\n",
    "# Training parameters\n",
    "partial_perc = 0.03\n",
    "batch_size = 250\n",
    "\n",
    "# Benchmark parameters\n",
    "BENCHMARK_N_RUNS = 15\n",
    "FULL_INFO_EPOCHS = 600\n",
    "NOISY_EPOCHS = 600\n",
    "\n",
    "# Old GGH (DBSCAN) parameters\n",
    "INCLUDE_OLD_GGH_ORIGINAL = False  # Set to True to also run the slow original variant\n",
    "OLD_GGH_EPOCHS = 585\n",
    "OLD_GGH_END_EPOCHS = 15\n",
    "OLD_GGH_EPS_VALUES = [0.15, 0.2]\n",
    "OLD_GGH_MIN_SAMPLES_RATIOS = [0.15, 0.2, 0.25]\n",
    "GGH_FINAL_EPOCHS = 600\n",
    "\n",
    "# Shared config dict for noise detection functions\n",
    "nd_config = {\n",
    "    'data_path': data_path,\n",
    "    'inpt_vars': inpt_vars,\n",
    "    'target_vars': target_vars,\n",
    "    'miss_vars': miss_vars,\n",
    "    'hypothesis': hypothesis,\n",
    "    'partial_perc': partial_perc,\n",
    "    'batch_size': batch_size,\n",
    "    'hidden_size': hidden_size,\n",
    "    'lr': lr,\n",
    "    'dropout': dropout,\n",
    "    # Noise simulation\n",
    "    'noise_perc': DATA_NOISE_PERC,\n",
    "    'noise_min': NOISE_MINRANGE,\n",
    "    'noise_max': NOISE_MAXRANGE,\n",
    "    # Old GGH\n",
    "    'old_ggh_epochs': OLD_GGH_EPOCHS,\n",
    "    'old_ggh_end_epochs': OLD_GGH_END_EPOCHS,\n",
    "    'old_ggh_eps_values': OLD_GGH_EPS_VALUES,\n",
    "    'old_ggh_min_samples_ratios': OLD_GGH_MIN_SAMPLES_RATIOS,\n",
    "    'final_epochs': GGH_FINAL_EPOCHS,\n",
    "}\n",
    "\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "\n",
    "print(f'Dataset: Photocell Degradation')\n",
    "print(f'Noise simulation: {DATA_NOISE_PERC*100}% of data, range [{NOISE_MINRANGE}, {NOISE_MAXRANGE}]')\n",
    "print(f'Benchmark runs: {BENCHMARK_N_RUNS}')\n",
    "print(f'Results path: {results_path}')\n",
    "print(f'Include original Old GGH (slow): {INCLUDE_OLD_GGH_ORIGINAL}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "benchmark_header",
   "metadata": {},
   "source": [
    "## Main Benchmark\n",
    "\n",
    "Run all methods across multiple random seeds:\n",
    "1. **Full Info (No Noise)** - Oracle upper bound\n",
    "2. **Full Info Noisy** - Baseline with noise, no removal\n",
    "3. **Old GGH (DBSCAN)** - Gradient clustering + retrain on cleaned data\n",
    "4. **New GGH (Soft Refinement)** - Bootstrap anchors, iterative refinement + retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "benchmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BENCHMARK: Noise Detection on Photocell Degradation\n",
      "================================================================================\n",
      "\n",
      "--- RUN 1/15 (r_state=0) ---\n",
      "  True noisy: 299/748 (40.0%)\n",
      "  Running Full Info (no noise)...\n",
      "    R2: 0.8473\n",
      "  Running Full Info Noisy (baseline)...\n",
      "    R2: 0.7221\n",
      "  Running Old GGH (DBSCAN)...\n",
      "    R2: 0.8549, Detection P/R: 1.000/0.375\n",
      "\n",
      "--- RUN 2/15 (r_state=1) ---\n",
      "  True noisy: 299/748 (40.0%)\n",
      "  Running Full Info (no noise)...\n",
      "    R2: 0.8720\n",
      "  Running Full Info Noisy (baseline)...\n",
      "    R2: 0.6061\n",
      "  Running Old GGH (DBSCAN)...\n",
      "    R2: 0.8637, Detection P/R: 0.991/0.375\n",
      "\n",
      "--- RUN 3/15 (r_state=2) ---\n",
      "  True noisy: 299/748 (40.0%)\n",
      "  Running Full Info (no noise)...\n",
      "    R2: 0.8910\n",
      "  Running Full Info Noisy (baseline)...\n",
      "    R2: 0.7811\n",
      "  Running Old GGH (DBSCAN)...\n",
      "    R2: 0.8716, Detection P/R: 0.986/0.696\n",
      "\n",
      "--- RUN 4/15 (r_state=3) ---\n",
      "  True noisy: 299/748 (40.0%)\n",
      "  Running Full Info (no noise)...\n",
      "    R2: 0.9212\n",
      "  Running Full Info Noisy (baseline)...\n",
      "    R2: 0.7545\n",
      "  Running Old GGH (DBSCAN)...\n",
      "    R2: 0.9150, Detection P/R: 0.985/0.217\n",
      "\n",
      "--- RUN 5/15 (r_state=4) ---\n",
      "  True noisy: 299/748 (40.0%)\n",
      "  Running Full Info (no noise)...\n",
      "    R2: 0.7989\n",
      "  Running Full Info Noisy (baseline)...\n",
      "    R2: 0.4388\n",
      "  Running Old GGH (DBSCAN)...\n",
      "    R2: 0.8269, Detection P/R: 1.000/0.080\n",
      "\n",
      "--- RUN 6/15 (r_state=5) ---\n",
      "  True noisy: 299/748 (40.0%)\n",
      "  Running Full Info (no noise)...\n",
      "    R2: 0.8094\n",
      "  Running Full Info Noisy (baseline)...\n",
      "    R2: 0.4664\n",
      "  Running Old GGH (DBSCAN)...\n",
      "    R2: 0.8150, Detection P/R: 1.000/0.060\n",
      "\n",
      "--- RUN 7/15 (r_state=6) ---\n",
      "  True noisy: 299/748 (40.0%)\n",
      "  Running Full Info (no noise)...\n",
      "    R2: 0.8402\n",
      "  Running Full Info Noisy (baseline)...\n",
      "    R2: 0.5893\n",
      "  Running Old GGH (DBSCAN)...\n",
      "    R2: 0.8605, Detection P/R: 0.977/0.418\n",
      "\n",
      "--- RUN 8/15 (r_state=7) ---\n",
      "  True noisy: 299/748 (40.0%)\n",
      "  Running Full Info (no noise)...\n",
      "    R2: 0.8668\n",
      "  Running Full Info Noisy (baseline)...\n",
      "    R2: 0.6213\n",
      "  Running Old GGH (DBSCAN)...\n",
      "    R2: 0.8656, Detection P/R: 1.000/0.211\n",
      "\n",
      "--- RUN 9/15 (r_state=8) ---\n",
      "  True noisy: 299/748 (40.0%)\n",
      "  Running Full Info (no noise)...\n",
      "    R2: 0.8867\n",
      "  Running Full Info Noisy (baseline)...\n",
      "    R2: 0.6255\n",
      "  Running Old GGH (DBSCAN)...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MLP:\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([32, 5]) from checkpoint, the shape in current model is torch.Size([32, 3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# --- Old GGH (DBSCAN) - Fast variant (default) ---\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m  Running Old GGH (DBSCAN)...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m old_result = \u001b[43mrun_old_ggh_dbscan_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnd_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m all_results[\u001b[33m'\u001b[39m\u001b[33mOld GGH (DBSCAN)\u001b[39m\u001b[33m'\u001b[39m].append(old_result)\n\u001b[32m     51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m    R2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_result[\u001b[33m\"\u001b[39m\u001b[33mtest_r2\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     52\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mDetection P/R: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_result[\u001b[33m\"\u001b[39m\u001b[33mdetection\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mprecision\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_result[\u001b[33m\"\u001b[39m\u001b[33mdetection\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mrecall\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Imputation & Noise Detection/gradient_guided_hypotheses/notebooks/../GGH_2/noise_detection.py:420\u001b[39m, in \u001b[36mrun_old_ggh_dbscan_fast\u001b[39m\u001b[34m(DO_original, r_state, config)\u001b[39m\n\u001b[32m    417\u001b[39m \u001b[38;5;66;03m# --- Phase 2: Compute gradients ONCE on best model ---\u001b[39;00m\n\u001b[32m    418\u001b[39m model = initialize_model(DO, dataloader, config[\u001b[33m'\u001b[39m\u001b[33mhidden_size\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    419\u001b[39m                          r_state, dropout=config[\u001b[33m'\u001b[39m\u001b[33mdropout\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTVM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweights_save_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m model.eval()\n\u001b[32m    423\u001b[39m loss_fn = MSEIndividualLosses()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/michael_20250605/lib/python3.12/site-packages/torch/nn/modules/module.py:2629\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2621\u001b[39m         error_msgs.insert(\n\u001b[32m   2622\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2623\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2624\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2625\u001b[39m             ),\n\u001b[32m   2626\u001b[39m         )\n\u001b[32m   2628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2629\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2630\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2631\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2632\u001b[39m         )\n\u001b[32m   2633\u001b[39m     )\n\u001b[32m   2634\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for MLP:\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([32, 5]) from checkpoint, the shape in current model is torch.Size([32, 3])."
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BENCHMARK EXECUTION\n",
    "# =============================================================================\n",
    "print('=' * 80)\n",
    "print('BENCHMARK: Noise Detection on Photocell Degradation')\n",
    "print('=' * 80)\n",
    "\n",
    "all_results = {\n",
    "    'Full Info': [],\n",
    "    'Full Info Noisy': [],\n",
    "    'Old GGH (DBSCAN)': [],\n",
    "}\n",
    "if INCLUDE_OLD_GGH_ORIGINAL:\n",
    "    all_results['Old GGH (Original)'] = []\n",
    "\n",
    "for run_idx in range(BENCHMARK_N_RUNS):\n",
    "    r_state = run_idx\n",
    "    print(f'\\n--- RUN {run_idx + 1}/{BENCHMARK_N_RUNS} (r_state={r_state}) ---')\n",
    "\n",
    "    # Create DO with noise for this run\n",
    "    set_to_deterministic(r_state)\n",
    "    DO = DataOperator(data_path, inpt_vars, target_vars, miss_vars, hypothesis,\n",
    "                      partial_perc, r_state, device='cpu', use_case='noise detection')\n",
    "    DO.simulate_noise(DATA_NOISE_PERC, NOISE_MINRANGE, NOISE_MAXRANGE)\n",
    "\n",
    "    n_total = len(DO.df_train_noisy)\n",
    "    n_noisy = DO.df_train_noisy['noise_added'].sum()\n",
    "    print(f'  True noisy: {n_noisy}/{n_total} ({n_noisy/n_total*100:.1f}%)')\n",
    "\n",
    "    # --- Full Info (No Noise) ---\n",
    "    print('  Running Full Info (no noise)...')\n",
    "    set_to_deterministic(r_state)\n",
    "    DO_clean = DataOperator(data_path, inpt_vars, target_vars, miss_vars, hypothesis,\n",
    "                            partial_perc, r_state, device='cpu', use_case='noise detection')\n",
    "    full_result = run_full_info(DO_clean, r_state, batch_size, hidden_size, lr,\n",
    "                                FULL_INFO_EPOCHS, dropout, results_path)\n",
    "    all_results['Full Info'].append(full_result)\n",
    "    print(f'    R2: {full_result[\"test_r2\"]:.4f}')\n",
    "\n",
    "    # --- Full Info Noisy (Baseline) ---\n",
    "    print('  Running Full Info Noisy (baseline)...')\n",
    "    noisy_result = run_full_info_noisy(DO, r_state, batch_size, hidden_size, lr,\n",
    "                                       NOISY_EPOCHS, dropout, results_path)\n",
    "    all_results['Full Info Noisy'].append(noisy_result)\n",
    "    print(f'    R2: {noisy_result[\"test_r2\"]:.4f}')\n",
    "\n",
    "    # --- Old GGH (DBSCAN) - Fast variant (default) ---\n",
    "    print('  Running Old GGH (DBSCAN)...')\n",
    "    old_result = run_old_ggh_dbscan_fast(DO, r_state, nd_config)\n",
    "    all_results['Old GGH (DBSCAN)'].append(old_result)\n",
    "    print(f'    R2: {old_result[\"test_r2\"]:.4f}, '\n",
    "          f'Detection P/R: {old_result[\"detection\"][\"precision\"]:.3f}/{old_result[\"detection\"][\"recall\"]:.3f}')\n",
    "\n",
    "    # --- Old GGH (Original) - Optional slow variant ---\n",
    "    if INCLUDE_OLD_GGH_ORIGINAL:\n",
    "        print('  Running Old GGH (Original, slow)...')\n",
    "        set_to_deterministic(r_state)\n",
    "        DO_orig = DataOperator(data_path, inpt_vars, target_vars, miss_vars, hypothesis,\n",
    "                               partial_perc, r_state, device='cpu', use_case='noise detection')\n",
    "        DO_orig.simulate_noise(DATA_NOISE_PERC, NOISE_MINRANGE, NOISE_MAXRANGE)\n",
    "        old_orig_result = run_old_ggh_dbscan(DO_orig, r_state, nd_config)\n",
    "        all_results['Old GGH (Original)'].append(old_orig_result)\n",
    "        print(f'    R2: {old_orig_result[\"test_r2\"]:.4f}, '\n",
    "              f'Detection P/R: {old_orig_result[\"detection\"][\"precision\"]:.3f}/{old_orig_result[\"detection\"][\"recall\"]:.3f}')\n",
    "\n",
    "print(f'\\n{\"=\" * 80}')\n",
    "print('BENCHMARK COMPLETE')\n",
    "print(f'{\"=\" * 80}')\n",
    "\n",
    "# Save results to disk\n",
    "save_noise_detection_results(all_results, 'Photocell Degradation', results_path,\n",
    "                             noise_profile=noise_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ytzws7yxw8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD RESULTS (use this cell instead of running the benchmark above)\n",
    "# =============================================================================\n",
    "import glob\n",
    "\n",
    "result_files = sorted(glob.glob(os.path.join(results_path, 'Photocell_Degradation_noise_results_*.json')))\n",
    "if not result_files:\n",
    "    raise FileNotFoundError(f\"No saved results found in {results_path}\")\n",
    "\n",
    "latest_file = result_files[-1]\n",
    "all_results, metadata = load_noise_detection_results(latest_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_header",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SUMMARY TABLE\n",
    "# =============================================================================\n",
    "print('\\n' + '=' * 90)\n",
    "print('RESULTS SUMMARY')\n",
    "print('=' * 90)\n",
    "\n",
    "print(f'\\n{\"Method\":<25} {\"R2\":>10} {\"MSE\":>12} {\"MAE\":>12}')\n",
    "print('-' * 60)\n",
    "\n",
    "for method, results in all_results.items():\n",
    "    r2_list = [r['test_r2'] for r in results]\n",
    "    mse_list = [r['test_mse'] for r in results]\n",
    "    mae_list = [r['test_mae'] for r in results]\n",
    "    print(f'{method:<25} '\n",
    "          f'{np.mean(r2_list):>6.4f} +/- {np.std(r2_list):.4f}  '\n",
    "          f'{np.mean(mse_list):.6f}  '\n",
    "          f'{np.mean(mae_list):.6f}')\n",
    "\n",
    "# Detection metrics for GGH methods\n",
    "print(f'\\n{\"=\"*90}')\n",
    "print('DETECTION METRICS')\n",
    "print(f'{\"=\"*90}')\n",
    "print(f'{\"Method\":<25} {\"Precision\":>10} {\"Recall\":>10} {\"F1\":>10} {\"Accuracy\":>10}')\n",
    "print('-' * 70)\n",
    "\n",
    "detection_methods = [m for m in all_results if 'GGH' in m]\n",
    "for method in detection_methods:\n",
    "    results = all_results[method]\n",
    "    precision = [r['detection']['precision'] for r in results]\n",
    "    recall = [r['detection']['recall'] for r in results]\n",
    "    f1 = [r['detection']['f1'] for r in results]\n",
    "    accuracy = [r['detection']['accuracy'] for r in results]\n",
    "    print(f'{method:<25} '\n",
    "          f'{np.mean(precision):>6.3f}+/-{np.std(precision):.3f} '\n",
    "          f'{np.mean(recall):>6.3f}+/-{np.std(recall):.3f} '\n",
    "          f'{np.mean(f1):>6.3f}+/-{np.std(f1):.3f} '\n",
    "          f'{np.mean(accuracy):>6.3f}+/-{np.std(accuracy):.3f}')\n",
    "\n",
    "# Statistical tests\n",
    "print(f'\\n{\"=\"*90}')\n",
    "print('STATISTICAL TESTS (Paired t-test on R2)')\n",
    "print(f'{\"=\"*90}')\n",
    "\n",
    "old_r2 = [r['test_r2'] for r in all_results['Old GGH (DBSCAN)']]\n",
    "noisy_r2 = [r['test_r2'] for r in all_results['Full Info Noisy']]\n",
    "\n",
    "t_stat, p_val = stats.ttest_rel(old_r2, noisy_r2)\n",
    "diff = np.mean(old_r2) - np.mean(noisy_r2)\n",
    "sig = '***' if p_val < 0.001 else '**' if p_val < 0.01 else '*' if p_val < 0.05 else ''\n",
    "print(f'\\nOld GGH vs Noisy: diff={diff:+.4f}, t={t_stat:.3f}, p={p_val:.4f} {sig}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz_header",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZATION: ALL METRICS\n",
    "# =============================================================================\n",
    "plot_all_noise_detection_metrics(all_results, 'Photocell Degradation', results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab71ac0c-f74a-4e71-9249-61d0d6319c55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-michael_20250605]",
   "language": "python",
   "name": "conda-env-.conda-michael_20250605-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
