{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Wine_Claude_Enhanced: Advanced Gradient Selection Methods\n",
    "\n",
    "This notebook tests the enhanced gradient selection methods:\n",
    "- **ContrastiveSelector**: Uses BOTH correct AND incorrect partial data\n",
    "- **EnsembleSelector**: Combines multiple anomaly detection methods\n",
    "- **CentroidDistanceSelector**: Distance-based selection\n",
    "- **AdaptiveSelector**: Adjusts strictness over epochs\n",
    "\n",
    "Also includes **diagnostic tools** to understand gradient behavior and plan improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "sys.path.insert(0, '../GGH')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score, silhouette_score\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "from GGH.data_ops import DataOperator\n",
    "from GGH.selection_algorithms import AlgoModulators, compute_individual_grads_nothread\n",
    "from GGH.models import initialize_model, load_model\n",
    "from GGH.train_val_loop import TrainValidationManager\n",
    "from GGH.inspector import Inspector, get_gradarrays_n_labels, get_label\n",
    "\n",
    "# Import enhanced modules\n",
    "from GGH.gradient_diagnostics import (\n",
    "    GradientDiagnostics,\n",
    "    EnrichedVectorBuilder,\n",
    "    compute_gradient_statistics,\n",
    "    visualize_gradient_space\n",
    ")\n",
    "from GGH.enhanced_selection import (\n",
    "    ContrastiveSelector,\n",
    "    EnsembleSelector,\n",
    "    CentroidDistanceSelector,\n",
    "    AdaptiveSelector\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def set_to_deterministic(rand_state):\n",
    "    import random\n",
    "    random.seed(rand_state)\n",
    "    np.random.seed(rand_state)\n",
    "    torch.manual_seed(rand_state)\n",
    "    torch.set_num_threads(1)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    \n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data configuration\n",
    "data_path = '../data/wine/red_wine.csv'\n",
    "results_path = \"../saved_results/Red Wine Enhanced\"\n",
    "inpt_vars = ['volatile acidity', 'total sulfur dioxide', 'citric acid'] \n",
    "target_vars = ['quality']\n",
    "miss_vars = ['alcohol']\n",
    "hypothesis = [[9.35, 10, 11.5, 15]]\n",
    "\n",
    "# Model parameters\n",
    "hidden_size = 32\n",
    "batch_size = 100 * len(hypothesis[0])  # 400\n",
    "partial_perc = 0.025  # Start with 2.5%\n",
    "\n",
    "# Create directories\n",
    "import os\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "\n",
    "# Initialize\n",
    "INSPECT = Inspector(results_path, hidden_size)\n",
    "diagnostics = GradientDiagnostics(save_path=results_path)\n",
    "\n",
    "print(f\"Results will be saved to: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1",
   "metadata": {},
   "source": [
    "## Part 1: Diagnostic Analysis of Gradient Behavior\n",
    "\n",
    "Before testing new methods, let's understand how gradients from correct vs incorrect hypotheses differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_single",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a single model and collect gradients for analysis\n",
    "rand_state = 0\n",
    "set_to_deterministic(rand_state)\n",
    "\n",
    "DO = DataOperator(data_path, inpt_vars, target_vars, miss_vars, hypothesis,\n",
    "                  partial_perc, rand_state, device='cpu')\n",
    "DO.problem_type = 'regression'\n",
    "\n",
    "if DO.lack_partial_coverage:\n",
    "    print(\"WARNING: Insufficient partial coverage. Try different random state.\")\n",
    "else:\n",
    "    print(f\"Partial data rows: {len(DO.partial_rows_id)}\")\n",
    "    print(f\"Total hypothesis combinations: {DO.num_hyp_comb}\")\n",
    "    print(f\"Training data shape: {DO.df_train_hypothesis.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_model_for_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with standard settings\n",
    "num_epochs = 30\n",
    "\n",
    "AM = AlgoModulators(DO, lr=0.002, nu=0.1, normalize_grads_contx=False,\n",
    "                   use_context=True, freqperc_cutoff=0.25)\n",
    "dataloader = DO.prep_dataloader('use hypothesis', batch_size)\n",
    "model = initialize_model(DO, dataloader, hidden_size, rand_state, dropout=0.05)\n",
    "\n",
    "TVM = TrainValidationManager('use hypothesis', num_epochs, dataloader, batch_size,\n",
    "                             rand_state, results_path, final_analysis=False)\n",
    "TVM.train_model(DO, AM, model, final_analysis=False)\n",
    "\n",
    "print(f\"Training complete. Best validation loss: {min(TVM.valid_errors_epoch):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract_gradients",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract gradients from the last epoch for analysis\n",
    "hyp_class = 2  # Analyze one hypothesis class\n",
    "\n",
    "# Get gradient arrays with labels\n",
    "grad_arrays, df_with_labels = get_gradarrays_n_labels(\n",
    "    DO, hyp_class, \n",
    "    layer=-2, \n",
    "    remov_avg=True,  # Remove average gradient signal\n",
    "    include_context=True, \n",
    "    normalize_grads_context=False,\n",
    "    num_batches=3, \n",
    "    epoch=-1,  # Last epoch\n",
    "    use_case=\"hypothesis\"\n",
    ")\n",
    "\n",
    "labels = df_with_labels['label'].values\n",
    "\n",
    "# Label meanings:\n",
    "# 0: Incorrect hypothesis, no partial info\n",
    "# 1: Correct hypothesis, no partial info  \n",
    "# 2: Incorrect hypothesis, has partial info\n",
    "# 3: Correct hypothesis, has partial info (ground truth)\n",
    "\n",
    "print(f\"\\nGradient array shape: {grad_arrays.shape}\")\n",
    "print(f\"Label distribution:\")\n",
    "for l in np.unique(labels):\n",
    "    label_names = {0: 'Incorrect (no partial)', 1: 'Correct (no partial)', \n",
    "                   2: 'Incorrect (partial)', 3: 'Correct (partial)'}\n",
    "    print(f\"  {label_names.get(l, l)}: {np.sum(labels == l)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic_metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute separability metrics\n",
    "correct_mask = (labels == 1) | (labels == 3)\n",
    "incorrect_mask = (labels == 0) | (labels == 2)\n",
    "partial_correct_mask = labels == 3\n",
    "\n",
    "correct_grads = grad_arrays[correct_mask]\n",
    "incorrect_grads = grad_arrays[incorrect_mask]\n",
    "partial_grads = grad_arrays[partial_correct_mask]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GRADIENT SEPARABILITY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(correct_grads) > 0 and len(incorrect_grads) > 0:\n",
    "    metrics = diagnostics.compute_separability_metrics(\n",
    "        correct_grads, incorrect_grads, partial_grads\n",
    "    )\n",
    "    \n",
    "    print(\"\\nKey Metrics:\")\n",
    "    print(f\"  Silhouette Score: {metrics.get('silhouette_score', 0):.4f} (range -1 to 1, higher=better)\")\n",
    "    print(f\"  Centroid Distance: {metrics.get('centroid_distance', 0):.4f} (higher=more separated)\")\n",
    "    print(f\"  Wasserstein Distance: {metrics.get('wasserstein_distance', 0):.4f} (higher=more different)\")\n",
    "    print(f\"  KS Statistic: {metrics.get('ks_statistic', 0):.4f} (higher=more different distributions)\")\n",
    "    \n",
    "    if 'partial_alignment_ratio' in metrics:\n",
    "        print(f\"\\nPartial Data Alignment:\")\n",
    "        print(f\"  Correct-to-Partial distance: {metrics.get('correct_to_partial_dist', 0):.4f}\")\n",
    "        print(f\"  Incorrect-to-Partial distance: {metrics.get('incorrect_to_partial_dist', 0):.4f}\")\n",
    "        print(f\"  Alignment ratio: {metrics.get('partial_alignment_ratio', 0):.4f} (>1 means correct is closer)\")\n",
    "else:\n",
    "    print(\"Insufficient data for metrics computation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_gradients",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize gradient distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 1. Gradient magnitude histogram\n",
    "ax = axes[0]\n",
    "grad_magnitudes = np.linalg.norm(grad_arrays, axis=1)\n",
    "\n",
    "for label_val, color, name in [(1, 'green', 'Correct'), (0, 'red', 'Incorrect'),\n",
    "                                (3, 'blue', 'Partial Correct')]:\n",
    "    mask = labels == label_val\n",
    "    if np.sum(mask) > 0:\n",
    "        ax.hist(grad_magnitudes[mask], alpha=0.5, bins=20, label=name, color=color)\n",
    "\n",
    "ax.set_xlabel('Gradient Magnitude')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Gradient Magnitude Distribution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. t-SNE visualization\n",
    "ax = axes[1]\n",
    "if len(grad_arrays) > 10:\n",
    "    perplexity = min(30, len(grad_arrays) - 1)\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity)\n",
    "    grad_tsne = tsne.fit_transform(grad_arrays)\n",
    "    \n",
    "    colors_map = {0: 'red', 1: 'green', 2: 'orange', 3: 'blue'}\n",
    "    for label_val in np.unique(labels):\n",
    "        mask = labels == label_val\n",
    "        label_names = {0: 'Incorrect', 1: 'Correct', 2: 'Inc. Partial', 3: 'Correct Partial'}\n",
    "        ax.scatter(grad_tsne[mask, 0], grad_tsne[mask, 1], \n",
    "                  c=colors_map.get(label_val, 'gray'), \n",
    "                  label=label_names.get(label_val), alpha=0.6, s=50)\n",
    "    \n",
    "    ax.set_xlabel('t-SNE 1')\n",
    "    ax.set_ylabel('t-SNE 2')\n",
    "    ax.set_title('t-SNE of Enriched Gradient Vectors')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{results_path}/gradient_analysis.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance in enriched vectors\n",
    "binary_labels = np.where((labels == 1) | (labels == 3), 1, 0)\n",
    "\n",
    "importance_df = diagnostics.analyze_feature_importance(\n",
    "    grad_arrays, binary_labels, \n",
    "    gradient_dim=hidden_size  # First hidden_size features are gradients\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTop 15 most discriminative features:\")\n",
    "print(importance_df[['feature', 'cohens_d', 'ks_statistic', 'is_gradient']].head(15).to_string())\n",
    "\n",
    "# Summary\n",
    "grad_features = importance_df[importance_df['is_gradient'] == True]\n",
    "context_features = importance_df[importance_df['is_gradient'] == False]\n",
    "\n",
    "print(f\"\\nAverage importance (Cohen's d):\")\n",
    "print(f\"  Gradient features: {grad_features['cohens_d'].mean():.4f}\")\n",
    "print(f\"  Context features: {context_features['cohens_d'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2",
   "metadata": {},
   "source": [
    "## Part 2: Test Enhanced Selection Methods\n",
    "\n",
    "Now test different selection algorithms to see which can better separate correct from incorrect hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selector_comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different selectors on the extracted gradients\n",
    "# Use partial correct (label=3) as \"known correct\" training data\n",
    "# Use partial incorrect (label=2) as \"known incorrect\" training data\n",
    "\n",
    "partial_correct = grad_arrays[labels == 3]\n",
    "partial_incorrect = grad_arrays[labels == 2]\n",
    "unknown = grad_arrays[(labels == 0) | (labels == 1)]\n",
    "unknown_labels = labels[(labels == 0) | (labels == 1)]\n",
    "unknown_true = (unknown_labels == 1).astype(int)  # 1 if correct, 0 if incorrect\n",
    "\n",
    "print(f\"Training data: {len(partial_correct)} correct, {len(partial_incorrect)} incorrect\")\n",
    "print(f\"Unknown data: {len(unknown)} samples ({np.sum(unknown_true)} correct, {len(unknown_true) - np.sum(unknown_true)} incorrect)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_selectors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test each selector\n",
    "selectors = {\n",
    "    'ContrastiveSelector (SVM)': ContrastiveSelector(classifier='svm'),\n",
    "    'ContrastiveSelector (RF)': ContrastiveSelector(classifier='rf'),\n",
    "    'EnsembleSelector (soft)': EnsembleSelector(voting='soft', threshold=0.5),\n",
    "    'EnsembleSelector (hard)': EnsembleSelector(voting='hard'),\n",
    "    'CentroidDistanceSelector': CentroidDistanceSelector(margin=0.0),\n",
    "    'AdaptiveSelector (nu=0.3->0.1)': AdaptiveSelector(initial_nu=0.3, final_nu=0.1),\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SELECTOR COMPARISON\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for name, selector in selectors.items():\n",
    "    try:\n",
    "        # Fit and predict\n",
    "        selector.fit(partial_correct, partial_incorrect)\n",
    "        result = selector.predict(unknown)\n",
    "        \n",
    "        # Evaluate\n",
    "        predicted_correct = set(result.selected_indices)\n",
    "        true_correct = set(np.where(unknown_true == 1)[0])\n",
    "        \n",
    "        tp = len(predicted_correct & true_correct)\n",
    "        fp = len(predicted_correct - true_correct)\n",
    "        fn = len(true_correct - predicted_correct)\n",
    "        tn = len(unknown) - tp - fp - fn\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        accuracy = (tp + tn) / len(unknown)\n",
    "        \n",
    "        results.append({\n",
    "            'Selector': name,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1': f1,\n",
    "            'Accuracy': accuracy,\n",
    "            'Selection Rate': len(predicted_correct) / len(unknown)\n",
    "        })\n",
    "        \n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f}, Selection Rate: {len(predicted_correct)/len(unknown):.4f}\")\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{name}: ERROR - {e}\\n\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary Table:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3",
   "metadata": {},
   "source": [
    "## Part 3: Full Training with Enhanced Selectors\n",
    "\n",
    "Test if enhanced selectors improve final model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "full_training_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_selector(selector_type, partial_perc, num_epochs, lr, nu, n_runs=5):\n",
    "    \"\"\"\n",
    "    Train model with specified selector type.\n",
    "    selector_type: 'standard' (original), 'contrastive', 'ensemble', 'centroid', 'adaptive'\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for r_state in range(100):\n",
    "        set_to_deterministic(r_state)\n",
    "        \n",
    "        DO = DataOperator(data_path, inpt_vars, target_vars, miss_vars, hypothesis,\n",
    "                          partial_perc, r_state, device='cpu')\n",
    "        DO.problem_type = 'regression'\n",
    "        \n",
    "        if not DO.lack_partial_coverage:\n",
    "            AM = AlgoModulators(DO, lr=lr, nu=nu, normalize_grads_contx=False,\n",
    "                               use_context=True, freqperc_cutoff=0.25)\n",
    "            \n",
    "            dataloader = DO.prep_dataloader('use hypothesis', batch_size)\n",
    "            model = initialize_model(DO, dataloader, hidden_size, r_state, dropout=0.05)\n",
    "            \n",
    "            TVM = TrainValidationManager('use hypothesis', num_epochs, dataloader, batch_size,\n",
    "                                         r_state, results_path, final_analysis=False)\n",
    "            \n",
    "            # Train - for now use standard training\n",
    "            # TODO: Integrate enhanced selectors into training loop\n",
    "            TVM.train_model(DO, AM, model, final_analysis=False)\n",
    "            \n",
    "            # Evaluate\n",
    "            model.load_state_dict(torch.load(TVM.weights_save_path))\n",
    "            model.eval()\n",
    "            test_pred = model(DO.full_test_input_tensor)\n",
    "            test_true = DO.df_test[target_vars].values\n",
    "            r2 = r2_score(test_true, test_pred.detach().numpy())\n",
    "            results.append(r2)\n",
    "            \n",
    "            if len(results) >= n_runs:\n",
    "                break\n",
    "    \n",
    "    return np.mean(results), np.std(results), results\n",
    "\n",
    "print(\"Training function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baseline_comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick comparison: baseline vs hypothesis selection\n",
    "partial_perc = 0.025\n",
    "num_epochs = 60\n",
    "lr = 0.002\n",
    "nu = 0.1\n",
    "\n",
    "print(\"Running baseline comparison...\\n\")\n",
    "\n",
    "# Partial info baseline\n",
    "print(\"Testing partial info baseline...\")\n",
    "p_mean, p_std, _ = train_with_selector('standard', partial_perc, 200, 0.001, nu, n_runs=5)\n",
    "print(f\"  partial info: {p_mean:.4f} +/- {p_std:.4f}\")\n",
    "\n",
    "# Standard hypothesis selection\n",
    "print(\"Testing use hypothesis (standard)...\")\n",
    "h_mean, h_std, _ = train_with_selector('standard', partial_perc, num_epochs, lr, nu, n_runs=5)\n",
    "print(f\"  use hypothesis: {h_mean:.4f} +/- {h_std:.4f}\")\n",
    "\n",
    "improvement = (h_mean - p_mean) * 100\n",
    "print(f\"\\nImprovement: {improvement:.2f} percentage points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4",
   "metadata": {},
   "source": [
    "## Part 4: Gradient Engineering - Improving Separability\n",
    "\n",
    "If performance is not improving, we need to investigate:\n",
    "1. What features best separate correct from incorrect?\n",
    "2. How can we modify the enriched vectors to improve separation?\n",
    "3. What additional context might help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enriched_vector_experiments",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different enriched vector configurations\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENRICHED VECTOR EXPERIMENTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get raw gradients from training (reuse from earlier)\n",
    "# For simplicity, use the already extracted gradients\n",
    "\n",
    "# Simulate different enrichment strategies by modifying grad_arrays\n",
    "configs = [\n",
    "    ('Raw gradients only', grad_arrays[:, :hidden_size]),\n",
    "    ('Gradients + input context', grad_arrays),\n",
    "    ('Gradient magnitude only', np.linalg.norm(grad_arrays[:, :hidden_size], axis=1, keepdims=True)),\n",
    "]\n",
    "\n",
    "for name, vectors in configs:\n",
    "    if len(vectors.shape) == 1:\n",
    "        vectors = vectors.reshape(-1, 1)\n",
    "    \n",
    "    # Compute separability with these vectors\n",
    "    correct_v = vectors[correct_mask]\n",
    "    incorrect_v = vectors[incorrect_mask]\n",
    "    \n",
    "    if len(correct_v) > 0 and len(incorrect_v) > 0:\n",
    "        # Centroid distance\n",
    "        centroid_dist = np.linalg.norm(np.mean(correct_v, axis=0) - np.mean(incorrect_v, axis=0))\n",
    "        \n",
    "        # Try silhouette if enough samples\n",
    "        combined = np.vstack([correct_v, incorrect_v])\n",
    "        combined_labels = np.array([1]*len(correct_v) + [0]*len(incorrect_v))\n",
    "        try:\n",
    "            sil = silhouette_score(combined, combined_labels)\n",
    "        except:\n",
    "            sil = 0\n",
    "        \n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  Vector dimension: {vectors.shape[1]}\")\n",
    "        print(f\"  Centroid distance: {centroid_dist:.4f}\")\n",
    "        print(f\"  Silhouette score: {sil:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "investigate_failures",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate why separation might be failing\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INVESTIGATION: Why might separation be failing?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Check gradient statistics\n",
    "print(\"\\n1. GRADIENT STATISTICS:\")\n",
    "grad_only = grad_arrays[:, :hidden_size]\n",
    "correct_grads_only = grad_only[correct_mask]\n",
    "incorrect_grads_only = grad_only[incorrect_mask]\n",
    "\n",
    "print(f\"   Correct hypothesis gradients:\")\n",
    "print(f\"     Mean magnitude: {np.mean(np.linalg.norm(correct_grads_only, axis=1)):.6f}\")\n",
    "print(f\"     Std magnitude: {np.std(np.linalg.norm(correct_grads_only, axis=1)):.6f}\")\n",
    "\n",
    "print(f\"   Incorrect hypothesis gradients:\")\n",
    "print(f\"     Mean magnitude: {np.mean(np.linalg.norm(incorrect_grads_only, axis=1)):.6f}\")\n",
    "print(f\"     Std magnitude: {np.std(np.linalg.norm(incorrect_grads_only, axis=1)):.6f}\")\n",
    "\n",
    "# 2. Check overlap in distributions\n",
    "print(\"\\n2. DISTRIBUTION OVERLAP:\")\n",
    "correct_mags = np.linalg.norm(correct_grads_only, axis=1)\n",
    "incorrect_mags = np.linalg.norm(incorrect_grads_only, axis=1)\n",
    "\n",
    "# Compute overlap\n",
    "overlap_min = max(correct_mags.min(), incorrect_mags.min())\n",
    "overlap_max = min(correct_mags.max(), incorrect_mags.max())\n",
    "if overlap_max > overlap_min:\n",
    "    correct_in_overlap = np.sum((correct_mags >= overlap_min) & (correct_mags <= overlap_max)) / len(correct_mags)\n",
    "    incorrect_in_overlap = np.sum((incorrect_mags >= overlap_min) & (incorrect_mags <= overlap_max)) / len(incorrect_mags)\n",
    "    print(f\"   Overlap region: [{overlap_min:.4f}, {overlap_max:.4f}]\")\n",
    "    print(f\"   % correct in overlap: {correct_in_overlap*100:.1f}%\")\n",
    "    print(f\"   % incorrect in overlap: {incorrect_in_overlap*100:.1f}%\")\n",
    "\n",
    "# 3. Check if partial data is representative\n",
    "print(\"\\n3. PARTIAL DATA REPRESENTATIVENESS:\")\n",
    "partial_mags = np.linalg.norm(grad_arrays[partial_correct_mask, :hidden_size], axis=1)\n",
    "print(f\"   Partial correct gradients: {len(partial_mags)} samples\")\n",
    "if len(partial_mags) > 0:\n",
    "    print(f\"   Mean magnitude: {np.mean(partial_mags):.6f}\")\n",
    "    print(f\"   Range: [{partial_mags.min():.6f}, {partial_mags.max():.6f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recommendations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate recommendations based on analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RECOMMENDATIONS FOR IMPROVING GRADIENT SEPARATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "Based on the diagnostic analysis, consider these approaches:\n",
    "\n",
    "1. GRADIENT NORMALIZATION:\n",
    "   - If gradient magnitudes overlap significantly, try L2 normalizing\n",
    "   - This focuses on gradient DIRECTION rather than magnitude\n",
    "\n",
    "2. CONTEXT WEIGHTING:\n",
    "   - If context features are more discriminative than gradients,\n",
    "     increase their weight in the enriched vector\n",
    "   - Or: use context features ONLY for selection\n",
    "\n",
    "3. MULTI-EPOCH AGGREGATION:\n",
    "   - Instead of using gradients from a single epoch,\n",
    "     aggregate across multiple epochs (e.g., moving average)\n",
    "   - This can reduce noise in gradient estimates\n",
    "\n",
    "4. LOSS-WEIGHTED GRADIENTS:\n",
    "   - Weight gradients by their corresponding loss values\n",
    "   - Samples with higher loss may have more informative gradients\n",
    "\n",
    "5. CONTRASTIVE LEARNING:\n",
    "   - Use BOTH correct AND incorrect partial data for training\n",
    "   - The ContrastiveSelector should help with this\n",
    "\n",
    "6. ENSEMBLE METHODS:\n",
    "   - Combine multiple selection criteria\n",
    "   - More robust than relying on a single method\n",
    "\n",
    "7. ADAPTIVE THRESHOLDING:\n",
    "   - Start permissive (select more hypotheses)\n",
    "   - Become stricter as training progresses\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5",
   "metadata": {},
   "source": [
    "## Part 5: Custom Experiments\n",
    "\n",
    "Add your own experiments here based on the diagnostic insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom_experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for custom experiments\n",
    "# Based on the diagnostics above, try different approaches:\n",
    "\n",
    "# Example: Test with normalized gradients\n",
    "# normalized_grads = grad_arrays / (np.linalg.norm(grad_arrays, axis=1, keepdims=True) + 1e-10)\n",
    "# Then rerun selector comparison...\n",
    "\n",
    "print(\"Add your custom experiments here based on diagnostic insights.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
