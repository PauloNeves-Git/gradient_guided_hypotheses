{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Wine_Hybrid: Two-Phase Training Approach\n",
    "\n",
    "This notebook implements a hybrid approach to gradient-guided hypothesis selection:\n",
    "\n",
    "**Phase 1: Unbiased Signal Extraction**\n",
    "- Train on ALL hypotheses equally (no selection)\n",
    "- Use architecture that AMPLIFIES hypothesis feature impact on gradients\n",
    "- Last N epochs: record per-hypothesis losses and gradients\n",
    "- Goal: Gather clean, unbiased data about each hypothesis\n",
    "\n",
    "**Phase 2: Informed GGH Selection**\n",
    "- Use Phase 1 insights to guide hypothesis selection\n",
    "- Standard GGH or winner-take-all training\n",
    "\n",
    "**Key insight**: Phase 1 gradients are not contaminated by selection feedback loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive context utilities loaded (with Z-score normalization).\n",
      "  - compute_anchor_data(trainer, DO): Compute all anchors\n",
      "  - compute_anchor_data_with_stats(trainer, DO): Compute anchors + score stats for normalization\n",
      "  - compute_adaptive_score(gradient, features, class_id, anchor_data): Raw adaptive score\n",
      "  - compute_adaptive_score_normalized(gradient, features, class_id, anchor_data): Z-score normalized\n",
      "  - print_adaptive_method_summary(anchor_data, hyp_per_sample): Show method per class\n",
      "  - print_score_stats(anchor_data, hyp_per_sample): Show score statistics per class\n",
      "Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "sys.path.insert(0, '../GGH')\n",
    "\n",
    "from GGH.data_ops import DataOperator\n",
    "from GGH.selection_algorithms import AlgoModulators, compute_individual_grads_nothread\n",
    "from GGH.models import initialize_model, load_model\n",
    "from GGH.train_val_loop import TrainValidationManager\n",
    "from GGH.inspector import Inspector, visualize_train_val_error, selection_histograms\n",
    "from GGH.custom_optimizer import CustomAdam\n",
    "from sklearn.metrics import r2_score\n",
    "from torch.autograd import grad\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def set_to_deterministic(rand_state):\n",
    "    import random\n",
    "    random.seed(rand_state)\n",
    "    np.random.seed(rand_state)\n",
    "    torch.manual_seed(rand_state)\n",
    "    torch.set_num_threads(1)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "# ADAPTIVE CONTEXT UTILITIES\n",
    "# Based on diagnostic finding: use gradient-only when anchor_similarity < 0, \n",
    "# enriched (gradient + features) when anchor_similarity > 0\n",
    "\n",
    "def compute_anchor_data(trainer, DO):\n",
    "    \"\"\"\n",
    "    Compute gradient-only anchors AND enriched anchors for each class.\n",
    "    Also computes anchor_similarity to decide which method to use per class.\n",
    "    \"\"\"\n",
    "    analysis = trainer.get_hypothesis_analysis()\n",
    "    hyp_per_sample = DO.num_hyp_comb\n",
    "    input_cols = DO.inpt_vars\n",
    "    \n",
    "    # Get partial data\n",
    "    partial_correct_gids = set(DO.df_train_hypothesis[\n",
    "        (DO.df_train_hypothesis['partial_full_info'] == 1) & \n",
    "        (DO.df_train_hypothesis['correct_hypothesis'] == True)\n",
    "    ].index.tolist())\n",
    "    blacklisted_gids = set(DO.df_train_hypothesis[\n",
    "        (DO.df_train_hypothesis['partial_full_info'] == 1) & \n",
    "        (DO.df_train_hypothesis['correct_hypothesis'] == False)\n",
    "    ].index.tolist())\n",
    "    partial_sample_indices = set(gid // hyp_per_sample for gid in partial_correct_gids)\n",
    "    \n",
    "    # Compute all anchors per class\n",
    "    anchor_correct_grad = {}\n",
    "    anchor_incorrect_grad = {}\n",
    "    anchor_correct_enriched = {}\n",
    "    anchor_incorrect_enriched = {}\n",
    "    anchor_similarity_grad = {}  # Gradient-only similarity\n",
    "    anchor_similarity_enriched = {}  # Enriched similarity\n",
    "    use_enriched = {}\n",
    "    \n",
    "    # For normalization: collect all gradients to get scale\n",
    "    all_grads = [analysis[gid]['avg_gradient'] for gid in analysis \n",
    "                 if analysis[gid]['avg_gradient'] is not None]\n",
    "    grad_scale = float(np.mean([np.linalg.norm(g) for g in all_grads])) if all_grads else 1.0\n",
    "    \n",
    "    # Store normalization params per class for use in scoring\n",
    "    feature_norm_params = {}\n",
    "    \n",
    "    for class_id in range(hyp_per_sample):\n",
    "        class_correct_gids = [gid for gid in partial_correct_gids \n",
    "                              if DO.df_train_hypothesis.iloc[gid]['hyp_class_id'] == class_id]\n",
    "        class_incorrect_gids = [gid for gid in blacklisted_gids \n",
    "                                if DO.df_train_hypothesis.iloc[gid]['hyp_class_id'] == class_id]\n",
    "        \n",
    "        # Collect gradients and features for correct\n",
    "        correct_grads = []\n",
    "        correct_features = []\n",
    "        for gid in class_correct_gids:\n",
    "            if gid in analysis and analysis[gid]['avg_gradient'] is not None:\n",
    "                correct_grads.append(analysis[gid]['avg_gradient'])\n",
    "                feat = DO.df_train_hypothesis.loc[gid, input_cols].values.astype(np.float64)\n",
    "                correct_features.append(feat)\n",
    "        \n",
    "        # Collect gradients and features for incorrect\n",
    "        incorrect_grads = []\n",
    "        incorrect_features = []\n",
    "        for gid in class_incorrect_gids:\n",
    "            if gid in analysis and analysis[gid]['avg_gradient'] is not None:\n",
    "                incorrect_grads.append(analysis[gid]['avg_gradient'])\n",
    "                feat = DO.df_train_hypothesis.loc[gid, input_cols].values.astype(np.float64)\n",
    "                incorrect_features.append(feat)\n",
    "        \n",
    "        if not correct_grads or not incorrect_grads:\n",
    "            continue\n",
    "            \n",
    "        # Gradient-only anchors\n",
    "        anchor_correct_grad[class_id] = np.mean(correct_grads, axis=0)\n",
    "        anchor_incorrect_grad[class_id] = np.mean(incorrect_grads, axis=0)\n",
    "        \n",
    "        # Compute gradient-only anchor similarity\n",
    "        sim_grad = float(np.dot(anchor_correct_grad[class_id], anchor_incorrect_grad[class_id]) / (\n",
    "            np.linalg.norm(anchor_correct_grad[class_id]) * np.linalg.norm(anchor_incorrect_grad[class_id]) + 1e-8))\n",
    "        anchor_similarity_grad[class_id] = sim_grad\n",
    "        \n",
    "        # Decide: use enriched if gradient anchor_similarity > 0\n",
    "        use_enriched[class_id] = sim_grad > 0\n",
    "        \n",
    "        # Enriched anchors (gradient + normalized features)\n",
    "        correct_grads = np.array(correct_grads, dtype=np.float64)\n",
    "        incorrect_grads = np.array(incorrect_grads, dtype=np.float64)\n",
    "        correct_features = np.array(correct_features, dtype=np.float64)\n",
    "        incorrect_features = np.array(incorrect_features, dtype=np.float64)\n",
    "        \n",
    "        # Normalize features to gradient scale\n",
    "        all_features = np.vstack([correct_features, incorrect_features])\n",
    "        feat_mean = np.mean(all_features, axis=0)\n",
    "        feat_std = np.std(all_features, axis=0) + 1e-8\n",
    "        \n",
    "        # Store normalization params for this class\n",
    "        feature_norm_params[class_id] = {'mean': feat_mean, 'std': feat_std, 'scale': grad_scale}\n",
    "        \n",
    "        correct_features_norm = (correct_features - feat_mean) / feat_std * grad_scale\n",
    "        incorrect_features_norm = (incorrect_features - feat_mean) / feat_std * grad_scale\n",
    "        \n",
    "        # Enriched = gradient + normalized features\n",
    "        correct_enriched = np.hstack([correct_grads, correct_features_norm])\n",
    "        incorrect_enriched = np.hstack([incorrect_grads, incorrect_features_norm])\n",
    "        \n",
    "        anchor_correct_enriched[class_id] = np.mean(correct_enriched, axis=0)\n",
    "        anchor_incorrect_enriched[class_id] = np.mean(incorrect_enriched, axis=0)\n",
    "        \n",
    "        # Compute enriched anchor similarity\n",
    "        sim_enriched = float(np.dot(anchor_correct_enriched[class_id], anchor_incorrect_enriched[class_id]) / (\n",
    "            np.linalg.norm(anchor_correct_enriched[class_id]) * np.linalg.norm(anchor_incorrect_enriched[class_id]) + 1e-8))\n",
    "        anchor_similarity_enriched[class_id] = sim_enriched\n",
    "    \n",
    "    return {\n",
    "        'anchor_correct_grad': anchor_correct_grad,\n",
    "        'anchor_incorrect_grad': anchor_incorrect_grad,\n",
    "        'anchor_correct_enriched': anchor_correct_enriched,\n",
    "        'anchor_incorrect_enriched': anchor_incorrect_enriched,\n",
    "        'anchor_similarity_grad': anchor_similarity_grad,\n",
    "        'anchor_similarity_enriched': anchor_similarity_enriched,\n",
    "        'use_enriched': use_enriched,\n",
    "        'grad_scale': grad_scale,\n",
    "        'feature_norm_params': feature_norm_params,\n",
    "        'partial_correct_gids': partial_correct_gids,\n",
    "        'blacklisted_gids': blacklisted_gids,\n",
    "        'partial_sample_indices': partial_sample_indices,\n",
    "        'input_cols': input_cols\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_adaptive_score(gradient, features, class_id, anchor_data):\n",
    "    \"\"\"\n",
    "    Compute score using adaptive method:\n",
    "    - Gradient-only for classes with good gradient separation (anchor_sim < 0)\n",
    "    - Enriched (gradient + features) for classes with poor gradient separation (anchor_sim > 0)\n",
    "    \"\"\"\n",
    "    use_enriched = anchor_data['use_enriched'].get(class_id, False)\n",
    "    \n",
    "    if use_enriched:\n",
    "        # Use enriched vectors - normalize features using stored params\n",
    "        norm_params = anchor_data['feature_norm_params'].get(class_id)\n",
    "        if norm_params:\n",
    "            features_norm = (features - norm_params['mean']) / norm_params['std'] * norm_params['scale']\n",
    "        else:\n",
    "            features_norm = features\n",
    "        enriched = np.concatenate([gradient, features_norm])\n",
    "        \n",
    "        anchor_c = anchor_data['anchor_correct_enriched'].get(class_id)\n",
    "        anchor_i = anchor_data['anchor_incorrect_enriched'].get(class_id)\n",
    "    else:\n",
    "        # Use gradient-only\n",
    "        enriched = gradient\n",
    "        anchor_c = anchor_data['anchor_correct_grad'].get(class_id)\n",
    "        anchor_i = anchor_data['anchor_incorrect_grad'].get(class_id)\n",
    "    \n",
    "    if anchor_c is None:\n",
    "        return 0.0\n",
    "    \n",
    "    sim_c = float(np.dot(enriched, anchor_c) / (np.linalg.norm(enriched) * np.linalg.norm(anchor_c) + 1e-8))\n",
    "    \n",
    "    if anchor_i is not None:\n",
    "        sim_i = float(np.dot(enriched, anchor_i) / (np.linalg.norm(enriched) * np.linalg.norm(anchor_i) + 1e-8))\n",
    "    else:\n",
    "        sim_i = 0.0\n",
    "    \n",
    "    return sim_c - sim_i\n",
    "\n",
    "\n",
    "def print_adaptive_method_summary(anchor_data, hyp_per_sample):\n",
    "    \"\"\"Print summary of adaptive method selection per class.\"\"\"\n",
    "    print(\"Per-class method selection:\")\n",
    "    for class_id in range(hyp_per_sample):\n",
    "        use_enr = anchor_data['use_enriched'].get(class_id, False)\n",
    "        sim_grad = anchor_data['anchor_similarity_grad'].get(class_id, None)\n",
    "        sim_enr = anchor_data['anchor_similarity_enriched'].get(class_id, None)\n",
    "        \n",
    "        if use_enr:\n",
    "            # Show BOTH: gradient sim (why we switched) and enriched sim (what we use)\n",
    "            print(f\"  Class {class_id}: grad_sim={sim_grad:+.3f} (poor) → ENRICHED (enriched_sim={sim_enr:+.3f})\")\n",
    "        else:\n",
    "            print(f\"  Class {class_id}: grad_sim={sim_grad:+.3f} (good) → GRADIENT-ONLY\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_score_stats(trainer, DO, anchor_data):\n",
    "    \"\"\"\n",
    "    First pass: Compute raw scores for all samples and collect statistics per class.\n",
    "    This is needed for Z-score normalization.\n",
    "    \"\"\"\n",
    "    analysis = trainer.get_hypothesis_analysis()\n",
    "    hyp_per_sample = DO.num_hyp_comb\n",
    "    n_samples = len(DO.df_train_hypothesis) // hyp_per_sample\n",
    "    input_cols = anchor_data['input_cols']\n",
    "    \n",
    "    partial_sample_indices = anchor_data['partial_sample_indices']\n",
    "    blacklisted_gids = anchor_data['blacklisted_gids']\n",
    "    \n",
    "    # Collect raw scores per class\n",
    "    class_scores = {c: [] for c in range(hyp_per_sample)}\n",
    "    \n",
    "    for sample_idx in range(n_samples):\n",
    "        if sample_idx in partial_sample_indices:\n",
    "            continue\n",
    "        \n",
    "        start = sample_idx * hyp_per_sample\n",
    "        \n",
    "        for hyp_idx in range(hyp_per_sample):\n",
    "            gid = start + hyp_idx\n",
    "            if gid in blacklisted_gids:\n",
    "                continue\n",
    "            if gid not in analysis or analysis[gid]['avg_gradient'] is None:\n",
    "                continue\n",
    "            \n",
    "            gradient = analysis[gid]['avg_gradient']\n",
    "            class_id = DO.df_train_hypothesis.iloc[gid]['hyp_class_id']\n",
    "            features = DO.df_train_hypothesis.loc[gid, input_cols].values.astype(np.float64)\n",
    "            \n",
    "            # Compute raw adaptive score\n",
    "            raw_score = compute_adaptive_score(gradient, features, class_id, anchor_data)\n",
    "            class_scores[class_id].append(raw_score)\n",
    "    \n",
    "    # Compute statistics per class\n",
    "    score_stats = {}\n",
    "    for class_id in range(hyp_per_sample):\n",
    "        scores = class_scores[class_id]\n",
    "        if len(scores) > 0:\n",
    "            score_stats[class_id] = {\n",
    "                'mean': float(np.mean(scores)),\n",
    "                'std': float(np.std(scores)),\n",
    "                'min': float(np.min(scores)),\n",
    "                'max': float(np.max(scores)),\n",
    "                'count': len(scores)\n",
    "            }\n",
    "        else:\n",
    "            score_stats[class_id] = {'mean': 0.0, 'std': 1.0, 'min': 0.0, 'max': 0.0, 'count': 0}\n",
    "    \n",
    "    return score_stats\n",
    "\n",
    "\n",
    "def compute_adaptive_score_normalized(gradient, features, class_id, anchor_data):\n",
    "    \"\"\"\n",
    "    Compute score and normalize using pre-computed class statistics.\n",
    "    This ensures all classes have comparable score scales (mean~0, std~1).\n",
    "    \"\"\"\n",
    "    raw_score = compute_adaptive_score(gradient, features, class_id, anchor_data)\n",
    "    \n",
    "    # Normalize using class-specific mean and std\n",
    "    score_stats = anchor_data.get('score_stats', {})\n",
    "    if class_id in score_stats:\n",
    "        stats = score_stats[class_id]\n",
    "        normalized_score = (raw_score - stats['mean']) / (stats['std'] + 1e-8)\n",
    "    else:\n",
    "        normalized_score = raw_score\n",
    "    \n",
    "    return normalized_score\n",
    "\n",
    "\n",
    "def compute_anchor_data_with_stats(trainer, DO):\n",
    "    \"\"\"\n",
    "    Wrapper that computes anchor data AND score statistics.\n",
    "    Call this instead of compute_anchor_data when using normalized scores.\n",
    "    \"\"\"\n",
    "    # First compute anchor data\n",
    "    anchor_data = compute_anchor_data(trainer, DO)\n",
    "    \n",
    "    # Then compute score statistics using raw adaptive scores\n",
    "    score_stats = compute_score_stats(trainer, DO, anchor_data)\n",
    "    \n",
    "    # Add stats to anchor_data\n",
    "    anchor_data['score_stats'] = score_stats\n",
    "    \n",
    "    return anchor_data\n",
    "\n",
    "\n",
    "def print_score_stats(anchor_data, hyp_per_sample):\n",
    "    \"\"\"Print score statistics per class.\"\"\"\n",
    "    print(\"\\nScore statistics per class (for Z-score normalization):\")\n",
    "    print(\"-\" * 60)\n",
    "    score_stats = anchor_data.get('score_stats', {})\n",
    "    for class_id in range(hyp_per_sample):\n",
    "        if class_id in score_stats:\n",
    "            stats = score_stats[class_id]\n",
    "            use_enr = anchor_data['use_enriched'].get(class_id, False)\n",
    "            method = \"enriched\" if use_enr else \"grad-only\"\n",
    "            print(f\"  Class {class_id} ({method}): mean={stats['mean']:+.3f}, std={stats['std']:.3f}, range=[{stats['min']:.2f}, {stats['max']:.2f}]\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Adaptive context utilities loaded (with Z-score normalization).\")\n",
    "print(\"  - compute_anchor_data(trainer, DO): Compute all anchors\")\n",
    "print(\"  - compute_anchor_data_with_stats(trainer, DO): Compute anchors + score stats for normalization\")\n",
    "print(\"  - compute_adaptive_score(gradient, features, class_id, anchor_data): Raw adaptive score\")\n",
    "print(\"  - compute_adaptive_score_normalized(gradient, features, class_id, anchor_data): Z-score normalized\")\n",
    "print(\"  - print_adaptive_method_summary(anchor_data, hyp_per_sample): Show method per class\")\n",
    "print(\"  - print_score_stats(anchor_data, hyp_per_sample): Show score statistics per class\")\n",
    "\n",
    "\n",
    "    \n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved to: ../saved_results/Red Wine Hybrid\n",
      "Phase 1: 30 epochs (track last 10) - EXTENDED\n",
      "Phase 2: 200 epochs with GGH selection\n",
      "Hypothesis values: [9.4, 10.5, 12.0]\n"
     ]
    }
   ],
   "source": [
    "# Data configuration\n",
    "data_path = '../data/wine/red_wine.csv'\n",
    "results_path = \"../saved_results/Red Wine Hybrid\"\n",
    "inpt_vars = ['volatile acidity', 'total sulfur dioxide', 'citric acid'] \n",
    "target_vars = ['quality']\n",
    "miss_vars = ['alcohol']\n",
    "\n",
    "# Hypothesis values based on natural breaks in alcohol distribution:\n",
    "# - Boundary at 9.7: after the major peak at 9.4-9.6 (245 samples)\n",
    "# - Boundary at 10.4: between plateau regions\n",
    "# - Boundary at 11.4: before sparse tail\n",
    "# Coverage: 31.1%, 23.6%, 25.8%, 19.5% (vs old 31%, 34%, 34%, 1.3%!)\n",
    "# Each hypothesis ≈ class mean: 9.4→9.36, 10.0→9.97, 10.8→10.82, 12.0→12.14\n",
    "#hypothesis = [[9.4, 10.0, 10.8, 12.0]]\n",
    "hypothesis = [[9.4, 10.5, 12.0]]\n",
    "\n",
    "# Model parameters\n",
    "hidden_size = 32\n",
    "output_size = len(target_vars)\n",
    "hyp_per_sample = len(hypothesis[0])\n",
    "batch_size = 100 * hyp_per_sample  # 400\n",
    "\n",
    "# Training parameters\n",
    "partial_perc = 0.025  # 2.5% complete data\n",
    "rand_state = 0\n",
    "lr = 0.001\n",
    "\n",
    "# Phase 1 parameters - EXPERIMENT 1: EXTENDED TRAINING\n",
    "phase1_epochs = 30  # Was 30 - now 100 for more stable gradients\n",
    "phase1_analysis_epochs = 10  # Was 10 - now 20 for better gradient averaging\n",
    "\n",
    "# Phase 2 parameters  \n",
    "phase2_epochs = 200  # GGH selection training (was 50, using Wine.ipynb standard)\n",
    "\n",
    "# Create directories\n",
    "import os\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "for folder in ['phase1', 'phase2', 'use hypothesis', 'partial info', 'use known only', 'full info']:\n",
    "    os.makedirs(f'{results_path}/{folder}', exist_ok=True)\n",
    "\n",
    "print(f\"Results will be saved to: {results_path}\")\n",
    "print(f\"Phase 1: {phase1_epochs} epochs (track last {phase1_analysis_epochs}) - EXTENDED\")\n",
    "print(f\"Phase 2: {phase2_epochs} epochs with GGH selection\")\n",
    "print(f\"Hypothesis values: {hypothesis[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase1_header",
   "metadata": {},
   "source": [
    "## Phase 1: Unbiased Training with Hypothesis-Amplifying Architecture\n",
    "\n",
    "Train on ALL hypotheses equally. No selection = no feedback loop bias.\n",
    "\n",
    "**Architecture idea**: Since 3/4 of input features are identical across hypotheses,\n",
    "we design a network that gives the hypothesis feature (alcohol) more influence:\n",
    "- Separate embedding path for hypothesis feature\n",
    "- Larger hidden dimension for hypothesis processing\n",
    "- This should amplify gradient differences between hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "phase1_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models defined.\n"
     ]
    }
   ],
   "source": [
    "class HypothesisAmplifyingModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network that amplifies the impact of hypothesis feature on gradients.\n",
    "    \n",
    "    Architecture:\n",
    "    - Shared features (non-hypothesis): small embedding\n",
    "    - Hypothesis feature: separate, larger embedding path\n",
    "    - Concatenate and process through final layers\n",
    "    \n",
    "    This ensures the hypothesis feature has outsized influence on gradients.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_shared_features, n_hypothesis_features=1, \n",
    "                 shared_hidden=16, hypothesis_hidden=32, final_hidden=32, output_size=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Shared features path (smaller)\n",
    "        self.shared_path = nn.Sequential(\n",
    "            nn.Linear(n_shared_features, shared_hidden),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Hypothesis feature path (larger - amplifies its importance)\n",
    "        self.hypothesis_path = nn.Sequential(\n",
    "            nn.Linear(n_hypothesis_features, hypothesis_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hypothesis_hidden, hypothesis_hidden),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Combined path\n",
    "        combined_size = shared_hidden + hypothesis_hidden\n",
    "        self.final_path = nn.Sequential(\n",
    "            nn.Linear(combined_size, final_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(final_hidden, output_size)\n",
    "        )\n",
    "        \n",
    "        self.n_shared = n_shared_features\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Split input: shared features vs hypothesis feature\n",
    "        # Assuming hypothesis feature is the LAST column\n",
    "        shared_features = x[:, :self.n_shared]\n",
    "        hypothesis_feature = x[:, self.n_shared:]\n",
    "        \n",
    "        # Process separately\n",
    "        shared_emb = self.shared_path(shared_features)\n",
    "        hypothesis_emb = self.hypothesis_path(hypothesis_feature)\n",
    "        \n",
    "        # Combine and predict\n",
    "        combined = torch.cat([shared_emb, hypothesis_emb], dim=1)\n",
    "        return self.final_path(combined)\n",
    "\n",
    "\n",
    "class StandardModel(nn.Module):\n",
    "    \"\"\"Standard MLP for comparison.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size=32, output_size=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "print(\"Models defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "phase1_trainer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase1Trainer defined.\n"
     ]
    }
   ],
   "source": [
    "class Phase1Trainer:\n",
    "    \"\"\"\n",
    "    Phase 1: Train on ALL hypotheses equally (no selection).\n",
    "    Track per-hypothesis losses and gradients in the last N epochs.\n",
    "    \"\"\"\n",
    "    def __init__(self, DO, model, lr=0.001, device='cpu'):\n",
    "        self.DO = DO\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        self.criterion = nn.MSELoss(reduction='none')\n",
    "        self.hyp_per_sample = DO.num_hyp_comb\n",
    "        \n",
    "        # Tracking data\n",
    "        self.loss_history = {}  # global_id -> list of losses per epoch\n",
    "        self.gradient_history = {}  # global_id -> list of gradient vectors\n",
    "        \n",
    "    def train_epoch(self, dataloader, epoch, track_data=False):\n",
    "        \"\"\"Train one epoch on ALL hypotheses equally.\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_idx, (inputs, targets, global_ids) in enumerate(dataloader):\n",
    "            inputs = inputs.to(self.device)\n",
    "            targets = targets.to(self.device)\n",
    "            \n",
    "            # Standard forward pass on ALL hypotheses\n",
    "            predictions = self.model(inputs)\n",
    "            \n",
    "            # Compute loss (mean over all hypotheses - no selection)\n",
    "            individual_losses = self.criterion(predictions, targets).mean(dim=1)\n",
    "            batch_loss = individual_losses.mean()\n",
    "            \n",
    "            # Track per-hypothesis data if in analysis window\n",
    "            if track_data:\n",
    "                self._track_hypothesis_data(inputs, targets, global_ids, individual_losses)\n",
    "            \n",
    "            # Standard backprop on ALL hypotheses\n",
    "            self.optimizer.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += batch_loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        return total_loss / num_batches\n",
    "    \n",
    "    def _track_hypothesis_data(self, inputs, targets, global_ids, losses):\n",
    "        \"\"\"Track loss and gradient for each hypothesis in the batch.\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        for i in range(len(inputs)):\n",
    "            gid = global_ids[i].item()\n",
    "            \n",
    "            # Track loss\n",
    "            if gid not in self.loss_history:\n",
    "                self.loss_history[gid] = []\n",
    "            self.loss_history[gid].append(losses[i].item())\n",
    "            \n",
    "            # Compute and track gradient for this hypothesis\n",
    "            inp = inputs[i:i+1].clone().requires_grad_(True)\n",
    "            pred = self.model(inp)\n",
    "            loss = nn.MSELoss()(pred, targets[i:i+1])\n",
    "            \n",
    "            # Get gradient w.r.t. last layer weights\n",
    "            params = list(self.model.parameters())\n",
    "            grad_param = grad(loss, params[-2], retain_graph=False)[0]\n",
    "            grad_vec = grad_param.flatten().detach().cpu().numpy()\n",
    "            \n",
    "            if gid not in self.gradient_history:\n",
    "                self.gradient_history[gid] = []\n",
    "            self.gradient_history[gid].append(grad_vec)\n",
    "        \n",
    "        self.model.train()\n",
    "    \n",
    "    def get_hypothesis_analysis(self):\n",
    "        \"\"\"Compile analysis results for each hypothesis.\"\"\"\n",
    "        analysis = {}\n",
    "        \n",
    "        for gid in self.loss_history:\n",
    "            analysis[gid] = {\n",
    "                'avg_loss': np.mean(self.loss_history[gid]),\n",
    "                'loss_std': np.std(self.loss_history[gid]),\n",
    "                'loss_trajectory': self.loss_history[gid],\n",
    "                'avg_gradient': np.mean(self.gradient_history[gid], axis=0) if gid in self.gradient_history else None,\n",
    "                'gradient_magnitude': np.mean([np.linalg.norm(g) for g in self.gradient_history.get(gid, [])]),\n",
    "            }\n",
    "        \n",
    "        return analysis\n",
    "\n",
    "print(\"Phase1Trainer defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "phase1_dataset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase1Dataset defined.\n"
     ]
    }
   ],
   "source": [
    "# Custom dataloader that includes global IDs for tracking\n",
    "class Phase1Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, DO):\n",
    "        # Build input tensor from df_train_hypothesis\n",
    "        # Input features = inpt_vars + hypothesis column (alcohol_hypothesis)\n",
    "        input_cols = DO.inpt_vars + [f'{DO.miss_vars[0]}_hypothesis']\n",
    "        self.inputs = torch.tensor(\n",
    "            DO.df_train_hypothesis[input_cols].values,\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        self.targets = torch.tensor(\n",
    "            DO.df_train_hypothesis[DO.target_vars].values, \n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        self.global_ids = torch.arange(len(self.inputs))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx], self.global_ids[idx]\n",
    "\n",
    "print(\"Phase1Dataset defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "phase1_init",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lack partial coverage: False\n",
      "Number of training hypotheses: 3453\n",
      "Hypotheses per sample: 3\n",
      "\n",
      "Input structure:\n",
      "  Total input size: 4\n",
      "  Shared features: 3 (same across hypotheses)\n",
      "  Hypothesis feature: 1 (differs)\n"
     ]
    }
   ],
   "source": [
    "# Initialize data and model for Phase 1\n",
    "set_to_deterministic(rand_state)\n",
    "\n",
    "DO = DataOperator(data_path, inpt_vars, target_vars, miss_vars, hypothesis,\n",
    "                  partial_perc, rand_state, device='cpu')\n",
    "DO.problem_type = 'regression'\n",
    "\n",
    "print(f\"Lack partial coverage: {DO.lack_partial_coverage}\")\n",
    "print(f\"Number of training hypotheses: {len(DO.df_train_hypothesis)}\")\n",
    "print(f\"Hypotheses per sample: {DO.num_hyp_comb}\")\n",
    "\n",
    "if DO.lack_partial_coverage:\n",
    "    print(\"WARNING: Insufficient partial coverage. Try different random state.\")\n",
    "else:\n",
    "    # Create Phase 1 dataloader\n",
    "    phase1_dataset = Phase1Dataset(DO)\n",
    "    phase1_dataloader = torch.utils.data.DataLoader(\n",
    "        phase1_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Check input structure from the dataset we just created\n",
    "    input_size = phase1_dataset.inputs.shape[1]\n",
    "    n_shared_features = len(inpt_vars)  # Features that are same across hypotheses\n",
    "    n_hypothesis_features = 1  # The hypothesis feature (alcohol)\n",
    "    \n",
    "    print(f\"\\nInput structure:\")\n",
    "    print(f\"  Total input size: {input_size}\")\n",
    "    print(f\"  Shared features: {n_shared_features} (same across hypotheses)\")\n",
    "    print(f\"  Hypothesis feature: {n_hypothesis_features} (differs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "phase1_create_models",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis-Amplifying Model:\n",
      "  Shared path: 3 -> 16\n",
      "  Hypothesis path: 1 -> 32 -> 32\n",
      "  Final path: 48 -> 32 -> 1\n",
      "\n",
      "Standard Model:\n",
      "  4 -> 32 -> 32 -> 1\n"
     ]
    }
   ],
   "source": [
    "# Create both model types for comparison\n",
    "if not DO.lack_partial_coverage:\n",
    "    # Hypothesis-amplifying model\n",
    "    model_amplified = HypothesisAmplifyingModel(\n",
    "        n_shared_features=n_shared_features,\n",
    "        n_hypothesis_features=n_hypothesis_features,\n",
    "        shared_hidden=16,      # Smaller path for shared features\n",
    "        hypothesis_hidden=32,  # Larger path for hypothesis feature\n",
    "        final_hidden=32,\n",
    "        output_size=output_size\n",
    "    )\n",
    "    \n",
    "    # Standard model for comparison\n",
    "    model_standard = StandardModel(\n",
    "        input_size=input_size,\n",
    "        hidden_size=32,\n",
    "        output_size=output_size\n",
    "    )\n",
    "    \n",
    "    print(\"Hypothesis-Amplifying Model:\")\n",
    "    print(f\"  Shared path: {n_shared_features} -> 16\")\n",
    "    print(f\"  Hypothesis path: {n_hypothesis_features} -> 32 -> 32\")\n",
    "    print(f\"  Final path: 48 -> 32 -> {output_size}\")\n",
    "    print(f\"\\nStandard Model:\")\n",
    "    print(f\"  {input_size} -> 32 -> 32 -> {output_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "phase1_train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PHASE 1: Unbiased Training (Hypothesis-Amplifying Model)\n",
      "============================================================\n",
      "Training on ALL hypotheses equally - no selection bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [00:00<00:00, 29.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: Loss = 0.0257 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [00:00<00:00, 29.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: Loss = 0.0223 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:11<00:00,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: Loss = 0.0218 (tracking)\n",
      "\n",
      "Phase 1 complete. Final loss: 0.0218\n",
      "Tracked 3453 hypotheses over last 10 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run Phase 1 training with AMPLIFIED model\n",
    "if not DO.lack_partial_coverage:\n",
    "    trainer_amp = Phase1Trainer(DO, model_amplified, lr=lr)\n",
    "    \n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"PHASE 1: Unbiased Training (Hypothesis-Amplifying Model)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Training on ALL hypotheses equally - no selection bias\")\n",
    "    \n",
    "    phase1_losses_amp = []\n",
    "    \n",
    "    for epoch in tqdm(range(phase1_epochs)):\n",
    "        # Track data in last N epochs for analysis\n",
    "        track = epoch >= (phase1_epochs - phase1_analysis_epochs)\n",
    "        \n",
    "        loss = trainer_amp.train_epoch(phase1_dataloader, epoch, track_data=track)\n",
    "        phase1_losses_amp.append(loss)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            status = \"(tracking)\" if track else \"\"\n",
    "            print(f\"Epoch {epoch+1}/{phase1_epochs}: Loss = {loss:.4f} {status}\")\n",
    "    \n",
    "    print(f\"\\nPhase 1 complete. Final loss: {phase1_losses_amp[-1]:.4f}\")\n",
    "    print(f\"Tracked {len(trainer_amp.loss_history)} hypotheses over last {phase1_analysis_epochs} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "phase1_train_standard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PHASE 1: Unbiased Training (Standard Model)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard model final loss: 0.0212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run Phase 1 training with STANDARD model for comparison\n",
    "if not DO.lack_partial_coverage:\n",
    "    # Reset for fair comparison\n",
    "    set_to_deterministic(rand_state)\n",
    "    model_standard = StandardModel(input_size=input_size, hidden_size=32, output_size=output_size)\n",
    "    \n",
    "    trainer_std = Phase1Trainer(DO, model_standard, lr=lr)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PHASE 1: Unbiased Training (Standard Model)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    phase1_losses_std = []\n",
    "    \n",
    "    for epoch in tqdm(range(phase1_epochs)):\n",
    "        track = epoch >= (phase1_epochs - phase1_analysis_epochs)\n",
    "        loss = trainer_std.train_epoch(phase1_dataloader, epoch, track_data=track)\n",
    "        phase1_losses_std.append(loss)\n",
    "    \n",
    "    print(f\"Standard model final loss: {phase1_losses_std[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic_header",
   "metadata": {},
   "source": [
    "## Diagnostic: Compare Signal Quality\n",
    "\n",
    "Does the hypothesis-amplifying architecture produce better separation between correct and incorrect hypotheses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "diagnostic_compare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "HYPOTHESIS-AMPLIFYING MODEL\n",
      "============================================================\n",
      "\n",
      "Loss Statistics:\n",
      "  Correct (1151):   0.0215 +/- 0.0343\n",
      "  Incorrect (2302): 0.0218 +/- 0.0349\n",
      "  Difference (incorrect - correct): 0.0004\n",
      "\n",
      "Gradient Statistics:\n",
      "  Cosine similarity between means: -0.8015\n",
      "  Euclidean distance between means: 0.0088\n",
      "  (Lower cosine sim = better separation)\n",
      "\n",
      "============================================================\n",
      "STANDARD MODEL\n",
      "============================================================\n",
      "\n",
      "Loss Statistics:\n",
      "  Correct (1151):   0.0211 +/- 0.0342\n",
      "  Incorrect (2302): 0.0211 +/- 0.0347\n",
      "  Difference (incorrect - correct): 0.0000\n",
      "\n",
      "Gradient Statistics:\n",
      "  Cosine similarity between means: -0.9586\n",
      "  Euclidean distance between means: 0.0139\n",
      "  (Lower cosine sim = better separation)\n"
     ]
    }
   ],
   "source": [
    "def analyze_separation(trainer, DO, model_name):\n",
    "    \"\"\"Analyze how well the model separates correct vs incorrect hypotheses.\"\"\"\n",
    "    analysis = trainer.get_hypothesis_analysis()\n",
    "    \n",
    "    correct_losses = []\n",
    "    incorrect_losses = []\n",
    "    correct_grads = []\n",
    "    incorrect_grads = []\n",
    "    \n",
    "    for gid, data in analysis.items():\n",
    "        is_correct = DO.df_train_hypothesis.iloc[gid]['correct_hypothesis']\n",
    "        \n",
    "        if is_correct:\n",
    "            correct_losses.append(data['avg_loss'])\n",
    "            if data['avg_gradient'] is not None:\n",
    "                correct_grads.append(data['avg_gradient'])\n",
    "        else:\n",
    "            incorrect_losses.append(data['avg_loss'])\n",
    "            if data['avg_gradient'] is not None:\n",
    "                incorrect_grads.append(data['avg_gradient'])\n",
    "    \n",
    "    # Loss separation\n",
    "    loss_diff = np.mean(incorrect_losses) - np.mean(correct_losses)\n",
    "    \n",
    "    # Gradient separation (cosine similarity between means)\n",
    "    if correct_grads and incorrect_grads:\n",
    "        correct_mean = np.mean(correct_grads, axis=0)\n",
    "        incorrect_mean = np.mean(incorrect_grads, axis=0)\n",
    "        \n",
    "        cosine_sim = np.dot(correct_mean, incorrect_mean) / (\n",
    "            np.linalg.norm(correct_mean) * np.linalg.norm(incorrect_mean) + 1e-8\n",
    "        )\n",
    "        euclidean_dist = np.linalg.norm(correct_mean - incorrect_mean)\n",
    "    else:\n",
    "        cosine_sim = None\n",
    "        euclidean_dist = None\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nLoss Statistics:\")\n",
    "    print(f\"  Correct ({len(correct_losses)}):   {np.mean(correct_losses):.4f} +/- {np.std(correct_losses):.4f}\")\n",
    "    print(f\"  Incorrect ({len(incorrect_losses)}): {np.mean(incorrect_losses):.4f} +/- {np.std(incorrect_losses):.4f}\")\n",
    "    print(f\"  Difference (incorrect - correct): {loss_diff:.4f}\")\n",
    "    \n",
    "    if cosine_sim is not None:\n",
    "        print(f\"\\nGradient Statistics:\")\n",
    "        print(f\"  Cosine similarity between means: {cosine_sim:.4f}\")\n",
    "        print(f\"  Euclidean distance between means: {euclidean_dist:.4f}\")\n",
    "        print(f\"  (Lower cosine sim = better separation)\")\n",
    "    \n",
    "    return {\n",
    "        'correct_losses': correct_losses,\n",
    "        'incorrect_losses': incorrect_losses,\n",
    "        'correct_grads': correct_grads,\n",
    "        'incorrect_grads': incorrect_grads,\n",
    "        'loss_diff': loss_diff,\n",
    "        'cosine_sim': cosine_sim,\n",
    "        'euclidean_dist': euclidean_dist\n",
    "    }\n",
    "\n",
    "if not DO.lack_partial_coverage:\n",
    "    results_amp = analyze_separation(trainer_amp, DO, \"HYPOTHESIS-AMPLIFYING MODEL\")\n",
    "    results_std = analyze_separation(trainer_std, DO, \"STANDARD MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "diagnostic_comparison_summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SELECTION METHOD COMPARISON\n",
      "======================================================================\n",
      "\n",
      "Method                                             Precision    vs Random\n",
      "---------------------------------------------------------------------------\n",
      "Random baseline                                      33.3%      +0.0pp \n",
      "Loss ranking (Amplified)                             38.9%      +5.6pp ***\n",
      "Loss ranking (Standard)                              28.3%      -5.0pp \n",
      "Adaptive context selection (Amplified)               48.9%      +15.6pp ***\n",
      "\n",
      "* = above random, ** = 2+pp above, *** = 5+pp above\n"
     ]
    }
   ],
   "source": [
    "# COMPARISON SUMMARY: All Selection Methods\n",
    "if not DO.lack_partial_coverage:\n",
    "    random_baseline = 1.0 / hyp_per_sample\n",
    "    random_baseline_pct = random_baseline * 100\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"SELECTION METHOD COMPARISON\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\n{'Method':<50} {'Precision':<12} {'vs Random'}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    methods = [\n",
    "        (\"Random baseline\", random_baseline_pct, 0.0),\n",
    "        (\"Loss ranking (Amplified)\", top1_amp * 100, (top1_amp - random_baseline) * 100),\n",
    "        (\"Loss ranking (Standard)\", top1_std * 100, (top1_std - random_baseline) * 100),\n",
    "        (\"Adaptive context selection (Amplified)\", selection_results['precision'] * 100, \n",
    "         (selection_results['precision'] - random_baseline) * 100),\n",
    "    ]\n",
    "    \n",
    "    for name, precision, improvement in methods:\n",
    "        marker = \"***\" if improvement >= 5 else (\"**\" if improvement >= 2 else (\"*\" if improvement > 0 else \"\"))\n",
    "        print(f\"{name:<50} {precision:>6.1f}%      {improvement:+.1f}pp {marker}\")\n",
    "    \n",
    "    print(f\"\\n* = above random, ** = 2+pp above, *** = 5+pp above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "diagnostic_histograms",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ../saved_results/Red Wine Hybrid/phase1/model_comparison.png\n"
     ]
    }
   ],
   "source": [
    "# Visualize loss distributions for both models\n",
    "if not DO.lack_partial_coverage:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    for idx, (results, name) in enumerate([\n",
    "        (results_amp, \"Hypothesis-Amplifying Model\"),\n",
    "        (results_std, \"Standard Model\")\n",
    "    ]):\n",
    "        # Loss distribution\n",
    "        ax1 = axes[idx, 0]\n",
    "        ax1.hist(results['correct_losses'], bins=30, alpha=0.6, label='Correct', color='green', density=True)\n",
    "        ax1.hist(results['incorrect_losses'], bins=30, alpha=0.6, label='Incorrect', color='red', density=True)\n",
    "        ax1.axvline(np.mean(results['correct_losses']), color='green', linestyle='--', linewidth=2)\n",
    "        ax1.axvline(np.mean(results['incorrect_losses']), color='red', linestyle='--', linewidth=2)\n",
    "        ax1.set_xlabel('Average Loss')\n",
    "        ax1.set_ylabel('Density')\n",
    "        ax1.set_title(f'{name}\\nLoss Distribution')\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Gradient magnitude distribution\n",
    "        ax2 = axes[idx, 1]\n",
    "        correct_mags = [np.linalg.norm(g) for g in results['correct_grads']]\n",
    "        incorrect_mags = [np.linalg.norm(g) for g in results['incorrect_grads']]\n",
    "        ax2.hist(correct_mags, bins=30, alpha=0.6, label='Correct', color='green', density=True)\n",
    "        ax2.hist(incorrect_mags, bins=30, alpha=0.6, label='Incorrect', color='red', density=True)\n",
    "        ax2.set_xlabel('Gradient Magnitude')\n",
    "        ax2.set_ylabel('Density')\n",
    "        ax2.set_title(f'{name}\\nGradient Magnitude Distribution')\n",
    "        ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{results_path}/phase1/model_comparison.png', dpi=150)\n",
    "    plt.show()\n",
    "    print(f\"Saved to {results_path}/phase1/model_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "diagnostic_ranking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "WITHIN-SAMPLE RANKING ACCURACY\n",
      "============================================================\n",
      "\n",
      "Random baseline: 33.3% (top 1), 66.7% (top 2)\n",
      "\n",
      "Hypothesis-Amplifying Model:\n",
      "  Correct ranked #1: 38.9%\n",
      "  Correct in top 2:  77.8%\n",
      "\n",
      "Standard Model:\n",
      "  Correct ranked #1: 28.3%\n",
      "  Correct in top 2:  65.6%\n"
     ]
    }
   ],
   "source": [
    "# Within-sample ranking accuracy for both models\n",
    "def compute_ranking_accuracy(trainer, DO, hyp_per_sample):\n",
    "    \"\"\"Check if correct hypothesis has lowest loss within each sample.\"\"\"\n",
    "    analysis = trainer.get_hypothesis_analysis()\n",
    "    n_samples = len(DO.df_train_hypothesis) // hyp_per_sample\n",
    "    \n",
    "    correct_ranked_first = 0\n",
    "    correct_in_top2 = 0\n",
    "    \n",
    "    for sample_idx in range(n_samples):\n",
    "        start = sample_idx * hyp_per_sample\n",
    "        \n",
    "        sample_data = []\n",
    "        correct_hyp_idx = None\n",
    "        \n",
    "        for hyp_idx in range(hyp_per_sample):\n",
    "            gid = start + hyp_idx\n",
    "            if gid in analysis:\n",
    "                sample_data.append((hyp_idx, analysis[gid]['avg_loss']))\n",
    "                if DO.df_train_hypothesis.iloc[gid]['correct_hypothesis']:\n",
    "                    correct_hyp_idx = hyp_idx\n",
    "        \n",
    "        if sample_data and correct_hyp_idx is not None:\n",
    "            sample_data.sort(key=lambda x: x[1])  # Sort by loss\n",
    "            ranked = [x[0] for x in sample_data]\n",
    "            \n",
    "            if ranked[0] == correct_hyp_idx:\n",
    "                correct_ranked_first += 1\n",
    "            if correct_hyp_idx in ranked[:2]:\n",
    "                correct_in_top2 += 1\n",
    "    \n",
    "    return correct_ranked_first / n_samples, correct_in_top2 / n_samples\n",
    "\n",
    "if not DO.lack_partial_coverage:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"WITHIN-SAMPLE RANKING ACCURACY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nRandom baseline: {100/hyp_per_sample:.1f}% (top 1), {200/hyp_per_sample:.1f}% (top 2)\")\n",
    "    \n",
    "    top1_amp, top2_amp = compute_ranking_accuracy(trainer_amp, DO, hyp_per_sample)\n",
    "    top1_std, top2_std = compute_ranking_accuracy(trainer_std, DO, hyp_per_sample)\n",
    "    \n",
    "    print(f\"\\nHypothesis-Amplifying Model:\")\n",
    "    print(f\"  Correct ranked #1: {top1_amp*100:.1f}%\")\n",
    "    print(f\"  Correct in top 2:  {top2_amp*100:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nStandard Model:\")\n",
    "    print(f\"  Correct ranked #1: {top1_std*100:.1f}%\")\n",
    "    print(f\"  Correct in top 2:  {top2_std*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "v39gu9udnz",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CONSTRAINED ANCHOR-BASED SELECTION\n",
      "(Adaptive Context + Z-Score Normalization)\n",
      "======================================================================\n",
      "\n",
      "Per-class method selection:\n",
      "  Class 0: grad_sim=-0.992 (good) → GRADIENT-ONLY\n",
      "  Class 1: grad_sim=+0.976 (poor) → ENRICHED (enriched_sim=-0.353)\n",
      "  Class 2: grad_sim=-0.420 (good) → GRADIENT-ONLY\n",
      "\n",
      "Score statistics per class (for Z-score normalization):\n",
      "------------------------------------------------------------\n",
      "  Class 0 (grad-only): mean=+0.129, std=1.983, range=[-2.00, 2.00]\n",
      "  Class 1 (enriched): mean=-0.201, std=0.946, range=[-1.62, 1.58]\n",
      "  Class 2 (grad-only): mean=-0.109, std=1.389, range=[-1.50, 1.50]\n",
      "\n",
      "Results:\n",
      "  Total selected: 1123\n",
      "  Correct: 549 (48.9% precision)\n",
      "  Random baseline: 25.0%\n",
      "\n",
      "  Per-class breakdown:\n",
      "    Class 0 (grad-only): 434 selected, 280 correct (64.5%)\n",
      "    Class 1 (enriched): 236 selected, 98 correct (41.5%)\n",
      "    Class 2 (grad-only): 453 selected, 171 correct (37.7%)\n"
     ]
    }
   ],
   "source": [
    "# CONSTRAINED ANCHOR-BASED SELECTION WITH ADAPTIVE CONTEXT + Z-SCORE NORMALIZATION\n",
    "# Uses all available information layers:\n",
    "# 1. One-per-sample constraint (guarantees 1/hyp_per_sample selection)\n",
    "# 2. Class-specific anchors from partial data\n",
    "# 3. ADAPTIVE: gradient-only OR enriched based on anchor quality per class\n",
    "# 4. Z-SCORE NORMALIZATION: ensures all classes have comparable score scales\n",
    "\n",
    "def constrained_anchor_selection_adaptive(trainer, DO, verbose=True):\n",
    "    \"\"\"\n",
    "    Select hypotheses using adaptive context with Z-score normalization.\n",
    "    \"\"\"\n",
    "    # Get anchor data WITH score statistics for normalization\n",
    "    anchor_data = compute_anchor_data_with_stats(trainer, DO)\n",
    "    \n",
    "    analysis = trainer.get_hypothesis_analysis()\n",
    "    hyp_per_sample = DO.num_hyp_comb\n",
    "    n_samples = len(DO.df_train_hypothesis) // hyp_per_sample\n",
    "    input_cols = anchor_data['input_cols']\n",
    "    \n",
    "    partial_sample_indices = anchor_data['partial_sample_indices']\n",
    "    blacklisted_gids = anchor_data['blacklisted_gids']\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"=\"*70)\n",
    "        print(\"CONSTRAINED ANCHOR-BASED SELECTION\")\n",
    "        print(\"(Adaptive Context + Z-Score Normalization)\")\n",
    "        print(\"=\"*70)\n",
    "        print()\n",
    "        print_adaptive_method_summary(anchor_data, hyp_per_sample)\n",
    "        print_score_stats(anchor_data, hyp_per_sample)\n",
    "    \n",
    "    # Select one hypothesis per sample using NORMALIZED scores\n",
    "    selected_gids = []\n",
    "    selection_correct = 0\n",
    "    class_selections = {c: 0 for c in range(hyp_per_sample)}\n",
    "    class_correct = {c: 0 for c in range(hyp_per_sample)}\n",
    "    \n",
    "    for sample_idx in range(n_samples):\n",
    "        if sample_idx in partial_sample_indices:\n",
    "            continue\n",
    "            \n",
    "        start = sample_idx * hyp_per_sample\n",
    "        best_score = -np.inf\n",
    "        best_gid = None\n",
    "        best_class = None\n",
    "        best_is_correct = False\n",
    "        \n",
    "        for hyp_idx in range(hyp_per_sample):\n",
    "            gid = start + hyp_idx\n",
    "            if gid in blacklisted_gids:\n",
    "                continue\n",
    "            if gid not in analysis or analysis[gid]['avg_gradient'] is None:\n",
    "                continue\n",
    "            \n",
    "            gradient = analysis[gid]['avg_gradient']\n",
    "            class_id = DO.df_train_hypothesis.iloc[gid]['hyp_class_id']\n",
    "            features = DO.df_train_hypothesis.loc[gid, input_cols].values.astype(np.float64)\n",
    "            \n",
    "            # NORMALIZED ADAPTIVE SCORE\n",
    "            score = compute_adaptive_score_normalized(gradient, features, class_id, anchor_data)\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_gid = gid\n",
    "                best_class = class_id\n",
    "                best_is_correct = DO.df_train_hypothesis.iloc[gid]['correct_hypothesis']\n",
    "        \n",
    "        if best_gid is not None:\n",
    "            selected_gids.append(best_gid)\n",
    "            class_selections[best_class] += 1\n",
    "            if best_is_correct:\n",
    "                selection_correct += 1\n",
    "                class_correct[best_class] += 1\n",
    "    \n",
    "    precision = selection_correct / len(selected_gids) if selected_gids else 0\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nResults:\")\n",
    "        print(f\"  Total selected: {len(selected_gids)}\")\n",
    "        print(f\"  Correct: {selection_correct} ({precision*100:.1f}% precision)\")\n",
    "        print(f\"  Random baseline: 25.0%\")\n",
    "        print(f\"\\n  Per-class breakdown:\")\n",
    "        for c in range(hyp_per_sample):\n",
    "            sel = class_selections[c]\n",
    "            corr = class_correct[c]\n",
    "            prec = corr/sel*100 if sel > 0 else 0\n",
    "            use_enr = anchor_data['use_enriched'].get(c, False)\n",
    "            method = \"enriched\" if use_enr else \"grad-only\"\n",
    "            print(f\"    Class {c} ({method}): {sel} selected, {corr} correct ({prec:.1f}%)\")\n",
    "    \n",
    "    return {\n",
    "        'selected_gids': selected_gids,\n",
    "        'precision': precision,\n",
    "        'n_correct': selection_correct,\n",
    "        'class_selections': class_selections,\n",
    "        'class_correct': class_correct,\n",
    "        'anchor_data': anchor_data\n",
    "    }\n",
    "\n",
    "# Run adaptive selection with normalization\n",
    "if not DO.lack_partial_coverage:\n",
    "    selection_results = constrained_anchor_selection_adaptive(trainer_amp, DO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8dkqeaod9v9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "THRESHOLD PRECISION ANALYSIS (Adaptive Context)\n",
      "======================================================================\n",
      "\n",
      "Per-class method selection:\n",
      "  Class 0: grad_sim=-0.992 (good) → GRADIENT-ONLY\n",
      "  Class 1: grad_sim=+0.976 (poor) → ENRICHED (enriched_sim=-0.353)\n",
      "  Class 2: grad_sim=-0.420 (good) → GRADIENT-ONLY\n",
      "\n",
      "Precision by Top Percentile (highest scores first):\n",
      "--------------------------------------------------\n",
      "Top  10%:  112 samples, precision=62.5%\n",
      "Top  20%:  224 samples, precision=67.9%\n",
      "Top  30%:  336 samples, precision=68.5%\n",
      "Top  40%:  449 samples, precision=64.1%\n",
      "Top  50%:  561 samples, precision=60.2%\n",
      "Top  60%:  673 samples, precision=57.8%\n",
      "Top  70%:  786 samples, precision=56.1%\n",
      "Top  80%:  898 samples, precision=52.9%\n",
      "Top  90%: 1010 samples, precision=50.2%\n",
      "Top 100%: 1123 samples, precision=48.7%\n",
      "\n",
      "Precision by Score Bin:\n",
      "--------------------------------------------------\n",
      "Score -1.28--0.95:    1 samples, precision=0.0%\n",
      "Score 0.36-0.69:    1 samples, precision=0.0%\n",
      "Score 0.69-1.01:    1 samples, precision=100.0%\n",
      "Score 1.01-1.34:   74 samples, precision=37.8%\n",
      "Score 1.34-1.67:  448 samples, precision=38.4%\n",
      "Score 1.67-2.00:  597 samples, precision=58.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# THRESHOLD SELECTION ANALYSIS WITH ADAPTIVE CONTEXT\n",
    "# Question: Does higher score = higher precision?\n",
    "# Uses adaptive scoring: gradient-only or enriched based on anchor quality per class\n",
    "\n",
    "def analyze_threshold_precision_adaptive(trainer, DO, verbose=True):\n",
    "    \"\"\"\n",
    "    Analyze relationship between score threshold and precision using ADAPTIVE context.\n",
    "    \"\"\"\n",
    "    # Get anchor data with adaptive context info\n",
    "    anchor_data = compute_anchor_data(trainer, DO)\n",
    "    \n",
    "    analysis = trainer.get_hypothesis_analysis()\n",
    "    hyp_per_sample = DO.num_hyp_comb\n",
    "    n_samples = len(DO.df_train_hypothesis) // hyp_per_sample\n",
    "    input_cols = anchor_data['input_cols']\n",
    "    \n",
    "    partial_sample_indices = anchor_data['partial_sample_indices']\n",
    "    blacklisted_gids = anchor_data['blacklisted_gids']\n",
    "    \n",
    "    # Collect ALL scores and correctness for non-partial samples\n",
    "    all_selections = []  # List of (score, is_correct, sample_idx)\n",
    "    \n",
    "    for sample_idx in range(n_samples):\n",
    "        if sample_idx in partial_sample_indices:\n",
    "            continue\n",
    "        \n",
    "        start = sample_idx * hyp_per_sample\n",
    "        best_score = -np.inf\n",
    "        best_is_correct = False\n",
    "        \n",
    "        for hyp_idx in range(hyp_per_sample):\n",
    "            gid = start + hyp_idx\n",
    "            if gid in blacklisted_gids:\n",
    "                continue\n",
    "            if gid not in analysis or analysis[gid]['avg_gradient'] is None:\n",
    "                continue\n",
    "            \n",
    "            gradient = analysis[gid]['avg_gradient']\n",
    "            class_id = DO.df_train_hypothesis.iloc[gid]['hyp_class_id']\n",
    "            features = DO.df_train_hypothesis.loc[gid, input_cols].values.astype(np.float64)\n",
    "            \n",
    "            # ADAPTIVE SCORE\n",
    "            score = compute_adaptive_score(gradient, features, class_id, anchor_data)\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_is_correct = DO.df_train_hypothesis.iloc[gid]['correct_hypothesis']\n",
    "        \n",
    "        if best_score > -np.inf:\n",
    "            all_selections.append((best_score, best_is_correct, sample_idx))\n",
    "    \n",
    "    # Sort by score (descending)\n",
    "    all_selections.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # Compute precision at different thresholds (top N%)\n",
    "    results = []\n",
    "    percentiles = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    \n",
    "    for pct in percentiles:\n",
    "        n_include = max(1, int(len(all_selections) * pct / 100))\n",
    "        top_selections = all_selections[:n_include]\n",
    "        n_correct = sum(1 for _, is_correct, _ in top_selections if is_correct)\n",
    "        precision = n_correct / n_include\n",
    "        results.append({\n",
    "            'percentile': pct,\n",
    "            'n_samples': n_include,\n",
    "            'n_correct': n_correct,\n",
    "            'precision': precision\n",
    "        })\n",
    "    \n",
    "    # Also compute precision in score bins\n",
    "    scores = [s[0] for s in all_selections]\n",
    "    min_score, max_score = min(scores), max(scores)\n",
    "    n_bins = 10\n",
    "    bin_results = []\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        bin_low = min_score + (max_score - min_score) * i / n_bins\n",
    "        bin_high = min_score + (max_score - min_score) * (i + 1) / n_bins\n",
    "        bin_selections = [(s, c) for s, c, _ in all_selections if bin_low <= s < bin_high]\n",
    "        if bin_selections:\n",
    "            bin_correct = sum(1 for _, c in bin_selections if c)\n",
    "            bin_results.append({\n",
    "                'bin': f'{bin_low:.2f}-{bin_high:.2f}',\n",
    "                'n_samples': len(bin_selections),\n",
    "                'precision': bin_correct / len(bin_selections)\n",
    "            })\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"=\"*70)\n",
    "        print(\"THRESHOLD PRECISION ANALYSIS (Adaptive Context)\")\n",
    "        print(\"=\"*70)\n",
    "        print()\n",
    "        print_adaptive_method_summary(anchor_data, hyp_per_sample)\n",
    "        \n",
    "        print(\"\\nPrecision by Top Percentile (highest scores first):\")\n",
    "        print(\"-\" * 50)\n",
    "        for r in results:\n",
    "            print(f\"Top {r['percentile']:>3}%: {r['n_samples']:>4} samples, \"\n",
    "                  f\"precision={r['precision']*100:.1f}%\")\n",
    "        \n",
    "        print(\"\\nPrecision by Score Bin:\")\n",
    "        print(\"-\" * 50)\n",
    "        for r in bin_results:\n",
    "            print(f\"Score {r['bin']}: {r['n_samples']:>4} samples, \"\n",
    "                  f\"precision={r['precision']*100:.1f}%\")\n",
    "    \n",
    "    return results, bin_results, all_selections, anchor_data\n",
    "\n",
    "# Run analysis with adaptive context\n",
    "if not DO.lack_partial_coverage:\n",
    "    results, bin_results, all_selections, anchor_data = analyze_threshold_precision_adaptive(trainer_amp, DO)\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Plot 1: Precision vs Top Percentile\n",
    "    ax1 = axes[0]\n",
    "    pcts = [r['percentile'] for r in results]\n",
    "    precs = [r['precision'] * 100 for r in results]\n",
    "    ax1.plot(pcts, precs, 'bo-', linewidth=2, markersize=8)\n",
    "    ax1.axhline(y=25, color='r', linestyle='--', label='Random baseline (25%)')\n",
    "    ax1.set_xlabel('Top Percentile (by score)')\n",
    "    ax1.set_ylabel('Precision (%)')\n",
    "    ax1.set_title('Precision vs Selection Threshold (Adaptive Context)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Precision by Score Bin\n",
    "    ax2 = axes[1]\n",
    "    bins = [r['bin'] for r in bin_results]\n",
    "    bin_precs = [r['precision'] * 100 for r in bin_results]\n",
    "    ax2.bar(range(len(bins)), bin_precs, color='steelblue', alpha=0.7)\n",
    "    ax2.axhline(y=25, color='r', linestyle='--', label='Random baseline')\n",
    "    ax2.set_xticks(range(len(bins)))\n",
    "    ax2.set_xticklabels(bins, rotation=45, ha='right')\n",
    "    ax2.set_xlabel('Score Bin')\n",
    "    ax2.set_ylabel('Precision (%)')\n",
    "    ax2.set_title('Precision by Score Bin (Adaptive Context)')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{results_path}/phase1/threshold_precision_adaptive.png', dpi=150)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "quk1ouguy1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ADAPTIVE CONTEXT + Z-SCORE NORMALIZATION\n",
      "======================================================================\n",
      "Per-class method selection:\n",
      "  Class 0: grad_sim=-0.992 (good) → GRADIENT-ONLY\n",
      "  Class 1: grad_sim=+0.976 (poor) → ENRICHED (enriched_sim=-0.353)\n",
      "  Class 2: grad_sim=-0.420 (good) → GRADIENT-ONLY\n",
      "\n",
      "Score statistics per class (for Z-score normalization):\n",
      "------------------------------------------------------------\n",
      "  Class 0 (grad-only): mean=+0.129, std=1.983, range=[-2.00, 2.00]\n",
      "  Class 1 (enriched): mean=-0.201, std=0.946, range=[-1.62, 1.58]\n",
      "  Class 2 (grad-only): mean=-0.109, std=1.389, range=[-1.50, 1.50]\n",
      "\n",
      "======================================================================\n",
      "SELECTION RESULTS\n",
      "======================================================================\n",
      "\n",
      "Overall: 549/1123 correct = 48.9% precision\n",
      "(Random baseline: 25.0%)\n",
      "\n",
      "Per-Class Results:\n",
      "------------------------------------------------------------\n",
      "  Class 0 (grad-only): 434 selected, 280 correct (64.5% precision), 473 true samples\n",
      "  Class 1 (enriched): 236 selected, 98 correct (41.5% precision), 397 true samples\n",
      "  Class 2 (grad-only): 453 selected, 171 correct (37.7% precision), 253 true samples\n",
      "\n",
      "======================================================================\n",
      "CONFUSION MATRIX (True vs Selected)\n",
      "======================================================================\n",
      "\n",
      "      Selected →\n",
      "True ↓    C0    C1    C2  \n",
      "  C0      280    82   111 \n",
      "  C1      128    98   171 \n",
      "  C2       26    56   171 \n"
     ]
    }
   ],
   "source": [
    "# DIAGNOSTIC: Understanding Selection Precision with Z-SCORE NORMALIZATION\n",
    "# Goal: Identify WHY precision is limited and WHERE we can improve\n",
    "\n",
    "def diagnose_selection_precision_adaptive(trainer, DO, verbose=True):\n",
    "    \"\"\"\n",
    "    Deep diagnostic analysis of selection precision using ADAPTIVE context\n",
    "    with Z-SCORE NORMALIZATION for fair comparison across classes.\n",
    "    \"\"\"\n",
    "    # Compute anchor data WITH score statistics\n",
    "    anchor_data = compute_anchor_data_with_stats(trainer, DO)\n",
    "    \n",
    "    analysis = trainer.get_hypothesis_analysis()\n",
    "    hyp_per_sample = DO.num_hyp_comb\n",
    "    n_samples = len(DO.df_train_hypothesis) // hyp_per_sample\n",
    "    input_cols = anchor_data['input_cols']\n",
    "    \n",
    "    partial_correct_gids = anchor_data['partial_correct_gids']\n",
    "    blacklisted_gids = anchor_data['blacklisted_gids']\n",
    "    partial_sample_indices = anchor_data['partial_sample_indices']\n",
    "    \n",
    "    # Print adaptive context decision\n",
    "    print(\"=\"*70)\n",
    "    print(\"ADAPTIVE CONTEXT + Z-SCORE NORMALIZATION\")\n",
    "    print(\"=\"*70)\n",
    "    print_adaptive_method_summary(anchor_data, hyp_per_sample)\n",
    "    print_score_stats(anchor_data, hyp_per_sample)\n",
    "    \n",
    "    # === SELECTION WITH NORMALIZED SCORING ===\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SELECTION RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Track results\n",
    "    class_selections = {c: {'selected': 0, 'correct': 0, 'true_count': 0} for c in range(hyp_per_sample)}\n",
    "    all_selections = []  # (gid, score, is_correct, true_class, selected_class)\n",
    "    \n",
    "    for sample_idx in range(n_samples):\n",
    "        if sample_idx in partial_sample_indices:\n",
    "            continue\n",
    "            \n",
    "        start = sample_idx * hyp_per_sample\n",
    "        \n",
    "        # Find true class for this sample\n",
    "        true_class = None\n",
    "        for hyp_idx in range(hyp_per_sample):\n",
    "            gid = start + hyp_idx\n",
    "            if DO.df_train_hypothesis.iloc[gid]['correct_hypothesis']:\n",
    "                true_class = hyp_idx\n",
    "                class_selections[true_class]['true_count'] += 1\n",
    "                break\n",
    "        \n",
    "        # Score each hypothesis using NORMALIZED adaptive method\n",
    "        best_score = -np.inf\n",
    "        best_gid = None\n",
    "        best_class = None\n",
    "        \n",
    "        for hyp_idx in range(hyp_per_sample):\n",
    "            gid = start + hyp_idx\n",
    "            if gid in blacklisted_gids:\n",
    "                continue\n",
    "            if gid not in analysis or analysis[gid]['avg_gradient'] is None:\n",
    "                continue\n",
    "            \n",
    "            gradient = analysis[gid]['avg_gradient']\n",
    "            class_id = DO.df_train_hypothesis.iloc[gid]['hyp_class_id']\n",
    "            features = DO.df_train_hypothesis.loc[gid, input_cols].values.astype(np.float64)\n",
    "            \n",
    "            # NORMALIZED ADAPTIVE SCORE\n",
    "            score = compute_adaptive_score_normalized(gradient, features, class_id, anchor_data)\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_gid = gid\n",
    "                best_class = class_id\n",
    "        \n",
    "        if best_gid is not None:\n",
    "            is_correct = DO.df_train_hypothesis.iloc[best_gid]['correct_hypothesis']\n",
    "            class_selections[best_class]['selected'] += 1\n",
    "            if is_correct:\n",
    "                class_selections[best_class]['correct'] += 1\n",
    "            all_selections.append((best_gid, best_score, is_correct, true_class, best_class))\n",
    "    \n",
    "    # === RESULTS ===\n",
    "    total_selected = sum(c['selected'] for c in class_selections.values())\n",
    "    total_correct = sum(c['correct'] for c in class_selections.values())\n",
    "    overall_precision = total_correct / total_selected if total_selected > 0 else 0\n",
    "    \n",
    "    print(f\"\\nOverall: {total_correct}/{total_selected} correct = {overall_precision*100:.1f}% precision\")\n",
    "    print(f\"(Random baseline: 25.0%)\")\n",
    "    \n",
    "    print(\"\\nPer-Class Results:\")\n",
    "    print(\"-\" * 60)\n",
    "    for c in range(hyp_per_sample):\n",
    "        sel = class_selections[c]['selected']\n",
    "        corr = class_selections[c]['correct']\n",
    "        true_cnt = class_selections[c]['true_count']\n",
    "        prec = corr/sel*100 if sel > 0 else 0\n",
    "        use_enr = anchor_data['use_enriched'].get(c, False)\n",
    "        method = \"enriched\" if use_enr else \"grad-only\"\n",
    "        print(f\"  Class {c} ({method}): {sel} selected, {corr} correct ({prec:.1f}% precision), {true_cnt} true samples\")\n",
    "    \n",
    "    # === CONFUSION MATRIX ===\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CONFUSION MATRIX (True vs Selected)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    confusion = np.zeros((hyp_per_sample, hyp_per_sample), dtype=int)\n",
    "    for _, _, _, true_class, selected_class in all_selections:\n",
    "        if true_class is not None:\n",
    "            confusion[true_class, selected_class] += 1\n",
    "    \n",
    "    print(\"\\n      Selected →\")\n",
    "    print(\"True ↓  \", end=\"\")\n",
    "    for c in range(hyp_per_sample):\n",
    "        print(f\"  C{c}  \", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    for true_c in range(hyp_per_sample):\n",
    "        print(f\"  C{true_c}    \", end=\"\")\n",
    "        for sel_c in range(hyp_per_sample):\n",
    "            print(f\" {confusion[true_c, sel_c]:4d} \", end=\"\")\n",
    "        print()\n",
    "    \n",
    "    return {\n",
    "        'class_selections': class_selections,\n",
    "        'all_selections': all_selections,\n",
    "        'precision': overall_precision,\n",
    "        'anchor_data': anchor_data\n",
    "    }\n",
    "\n",
    "# Run with normalized adaptive context\n",
    "if not DO.lack_partial_coverage:\n",
    "    results_adaptive = diagnose_selection_precision_adaptive(trainer_amp, DO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "class1_diagnostic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CLASS SELECTION ANALYSIS (Adaptive Context)\n",
      "======================================================================\n",
      "\n",
      "Per-class method selection:\n",
      "  Class 0: grad_sim=-0.992 (good) → GRADIENT-ONLY\n",
      "  Class 1: grad_sim=+0.976 (poor) → ENRICHED (enriched_sim=-0.353)\n",
      "  Class 2: grad_sim=-0.420 (good) → GRADIENT-ONLY\n",
      "\n",
      "======================================================================\n",
      "SELECTION DISTRIBUTION\n",
      "======================================================================\n",
      "\n",
      "Total non-partial samples: 1123\n",
      "\n",
      "How often each class is selected:\n",
      "  Class 0 (grad-only): 598/1123 = 53.3%  (precision: 57.9%)\n",
      "  Class 1 (enriched): 12/1123 = 1.1%  (precision: 50.0%)\n",
      "  Class 2 (grad-only): 513/1123 = 45.7%  (precision: 38.0%)\n",
      "\n",
      "======================================================================\n",
      "SCORE STATISTICS BY CLASS\n",
      "======================================================================\n",
      "\n",
      "Class 0:\n",
      "  Score: mean=0.1292, std=1.9830\n",
      "  Range: [-1.9957, 1.9960]\n",
      "\n",
      "Class 1:\n",
      "  Score: mean=-0.2006, std=0.9462\n",
      "  Range: [-1.6250, 1.5796]\n",
      "\n",
      "Class 2:\n",
      "  Score: mean=-0.1089, std=1.3893\n",
      "  Range: [-1.5041, 1.4980]\n"
     ]
    }
   ],
   "source": [
    "# DIAGNOSTIC: Class Selection Distribution with ADAPTIVE CONTEXT\n",
    "\n",
    "def diagnose_class_selection_adaptive(trainer, DO):\n",
    "    \"\"\"\n",
    "    Investigate class selection distribution with adaptive context.\n",
    "    \"\"\"\n",
    "    # Get anchor data\n",
    "    anchor_data = compute_anchor_data(trainer, DO)\n",
    "    \n",
    "    analysis = trainer.get_hypothesis_analysis()\n",
    "    hyp_per_sample = DO.num_hyp_comb\n",
    "    n_samples = len(DO.df_train_hypothesis) // hyp_per_sample\n",
    "    input_cols = anchor_data['input_cols']\n",
    "    \n",
    "    partial_sample_indices = anchor_data['partial_sample_indices']\n",
    "    blacklisted_gids = anchor_data['blacklisted_gids']\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"CLASS SELECTION ANALYSIS (Adaptive Context)\")\n",
    "    print(\"=\"*70)\n",
    "    print()\n",
    "    print_adaptive_method_summary(anchor_data, hyp_per_sample)\n",
    "    \n",
    "    # Collect scores by class\n",
    "    all_scores = {c: [] for c in range(hyp_per_sample)}\n",
    "    wins_by_class = {c: 0 for c in range(hyp_per_sample)}\n",
    "    correct_by_class = {c: 0 for c in range(hyp_per_sample)}\n",
    "    total_samples = 0\n",
    "    \n",
    "    for sample_idx in range(n_samples):\n",
    "        if sample_idx in partial_sample_indices:\n",
    "            continue\n",
    "        \n",
    "        start = sample_idx * hyp_per_sample\n",
    "        sample_scores = []\n",
    "        \n",
    "        for hyp_idx in range(hyp_per_sample):\n",
    "            gid = start + hyp_idx\n",
    "            if gid in blacklisted_gids:\n",
    "                sample_scores.append((hyp_idx, -np.inf, False))\n",
    "                continue\n",
    "            if gid not in analysis or analysis[gid]['avg_gradient'] is None:\n",
    "                sample_scores.append((hyp_idx, -np.inf, False))\n",
    "                continue\n",
    "            \n",
    "            gradient = analysis[gid]['avg_gradient']\n",
    "            class_id = DO.df_train_hypothesis.iloc[gid]['hyp_class_id']\n",
    "            features = DO.df_train_hypothesis.loc[gid, input_cols].values.astype(np.float64)\n",
    "            \n",
    "            # ADAPTIVE SCORE\n",
    "            score = compute_adaptive_score(gradient, features, class_id, anchor_data)\n",
    "            is_correct = DO.df_train_hypothesis.iloc[gid]['correct_hypothesis']\n",
    "            \n",
    "            sample_scores.append((hyp_idx, score, is_correct))\n",
    "            all_scores[class_id].append({'score': score, 'is_correct': is_correct})\n",
    "        \n",
    "        # Find winner\n",
    "        winner_idx, winner_score, winner_correct = max(sample_scores, key=lambda x: x[1])\n",
    "        wins_by_class[winner_idx] += 1\n",
    "        if winner_correct:\n",
    "            correct_by_class[winner_idx] += 1\n",
    "        total_samples += 1\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SELECTION DISTRIBUTION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nTotal non-partial samples: {total_samples}\")\n",
    "    print(\"\\nHow often each class is selected:\")\n",
    "    for c in range(hyp_per_sample):\n",
    "        pct = wins_by_class[c] / total_samples * 100\n",
    "        corr = correct_by_class[c]\n",
    "        prec = corr / wins_by_class[c] * 100 if wins_by_class[c] > 0 else 0\n",
    "        use_enr = anchor_data['use_enriched'].get(c, False)\n",
    "        method = \"enriched\" if use_enr else \"grad-only\"\n",
    "        print(f\"  Class {c} ({method}): {wins_by_class[c]}/{total_samples} = {pct:.1f}%  (precision: {prec:.1f}%)\")\n",
    "    \n",
    "    # Score statistics\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SCORE STATISTICS BY CLASS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for c in range(hyp_per_sample):\n",
    "        scores = [s['score'] for s in all_scores[c]]\n",
    "        if scores:\n",
    "            print(f\"\\nClass {c}:\")\n",
    "            print(f\"  Score: mean={np.mean(scores):.4f}, std={np.std(scores):.4f}\")\n",
    "            print(f\"  Range: [{min(scores):.4f}, {max(scores):.4f}]\")\n",
    "    \n",
    "    return {\n",
    "        'wins_by_class': wins_by_class,\n",
    "        'correct_by_class': correct_by_class,\n",
    "        'all_scores': all_scores,\n",
    "        'anchor_data': anchor_data\n",
    "    }\n",
    "\n",
    "# Run diagnostic\n",
    "if not DO.lack_partial_coverage:\n",
    "    class_results = diagnose_class_selection_adaptive(trainer_amp, DO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "gradient_vs_context_diagnostic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GRADIENT vs GRADIENT+CONTEXT ANCHOR SEPARATION\n",
      "======================================================================\n",
      "\n",
      "Using 3 input features: ['volatile acidity', 'total sulfur dioxide', 'citric acid']\n",
      "\n",
      "Class 0 (alcohol=9.4):\n",
      "  Samples: correct=9, incorrect=19\n",
      "  Gradient only:             anchor_similarity = -0.9922\n",
      "  Gradient + input_features: anchor_similarity = -0.6219\n",
      "  Gradient + features + loss: anchor_similarity = -0.6385\n",
      "  → Adding input features does NOT help\n",
      "  \n",
      "  Input feature statistics:\n",
      "    Largest mean difference: volatile acidity (Δ = 0.1078)\n",
      "\n",
      "Class 1 (alcohol=10.5):\n",
      "  Samples: correct=10, incorrect=18\n",
      "  Gradient only:             anchor_similarity = 0.9762\n",
      "  Gradient + input_features: anchor_similarity = -0.3102\n",
      "  Gradient + features + loss: anchor_similarity = -0.3121\n",
      "  → Adding input features IMPROVES separation (Δ = 1.2864)\n",
      "  \n",
      "  Input feature statistics:\n",
      "    Largest mean difference: citric acid (Δ = 0.1276)\n",
      "\n",
      "Class 2 (alcohol=12.0):\n",
      "  Samples: correct=9, incorrect=19\n",
      "  Gradient only:             anchor_similarity = -0.4201\n",
      "  Gradient + input_features: anchor_similarity = -0.3852\n",
      "  Gradient + features + loss: anchor_similarity = -0.4492\n",
      "  → Adding input features does NOT help\n",
      "  \n",
      "  Input feature statistics:\n",
      "    Largest mean difference: citric acid (Δ = -0.0745)\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Anchor similarity closer to -1 means BETTER separation (opposite directions)\n",
      "Anchor similarity close to +1 means POOR separation (same direction)\n",
      "\n",
      "| Class | Grad Only | Grad+Feat | Grad+Feat+Loss | Best Method |\n",
      "|-------|-----------|-----------|----------------|-------------|\n",
      "|   0   |  -0.992   |  -0.622   |    -0.638      | Grad Only   |\n",
      "|   1   |  +0.976   |  -0.310   |    -0.312      | Grad+F+L    |\n",
      "|   2   |  -0.420   |  -0.385   |    -0.449      | Grad+F+L    |\n"
     ]
    }
   ],
   "source": [
    "# DIAGNOSTIC: Does adding input features as context improve anchor separation?\n",
    "# Theory: Gradients alone may not distinguish correct from incorrect for Class 1\n",
    "# because both produce similar gradient directions. The INPUT FEATURES should differ.\n",
    "#\n",
    "# BUG FIX: Previously used hypothesis value (constant within class) which dominated gradients.\n",
    "# Now using actual input features (inpt_vars) which vary per sample.\n",
    "\n",
    "def diagnose_gradient_vs_context(trainer, DO, verbose=True):\n",
    "    \"\"\"\n",
    "    Compare anchor separation using:\n",
    "    1. Gradient only\n",
    "    2. Gradient + input features (actual input variables, NOT hypothesis value)\n",
    "    3. Gradient + input features + loss\n",
    "    \"\"\"\n",
    "    analysis = trainer.get_hypothesis_analysis()\n",
    "    hyp_per_sample = DO.num_hyp_comb\n",
    "    n_samples = len(DO.df_train_hypothesis) // hyp_per_sample\n",
    "    \n",
    "    # Get partial data info\n",
    "    partial_correct_gids = set(DO.df_train_hypothesis[\n",
    "        (DO.df_train_hypothesis['partial_full_info'] == 1) & \n",
    "        (DO.df_train_hypothesis['correct_hypothesis'] == True)\n",
    "    ].index.tolist())\n",
    "    blacklisted_gids = set(DO.df_train_hypothesis[\n",
    "        (DO.df_train_hypothesis['partial_full_info'] == 1) & \n",
    "        (DO.df_train_hypothesis['correct_hypothesis'] == False)\n",
    "    ].index.tolist())\n",
    "    \n",
    "    # Get the input feature columns (NOT hypothesis value)\n",
    "    input_cols = DO.inpt_vars  # These vary per sample!\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"GRADIENT vs GRADIENT+CONTEXT ANCHOR SEPARATION\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nUsing {len(input_cols)} input features: {input_cols}\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for class_id in range(hyp_per_sample):\n",
    "        class_correct_gids = [gid for gid in partial_correct_gids \n",
    "                              if DO.df_train_hypothesis.iloc[gid]['hyp_class_id'] == class_id]\n",
    "        class_incorrect_gids = [gid for gid in blacklisted_gids \n",
    "                                if DO.df_train_hypothesis.iloc[gid]['hyp_class_id'] == class_id]\n",
    "        \n",
    "        if not class_correct_gids or not class_incorrect_gids:\n",
    "            print(f\"\\nClass {class_id}: Insufficient data (correct={len(class_correct_gids)}, incorrect={len(class_incorrect_gids)})\")\n",
    "            continue\n",
    "        \n",
    "        # Collect data for correct and incorrect\n",
    "        correct_grads = []\n",
    "        correct_features = []\n",
    "        correct_losses = []\n",
    "        \n",
    "        incorrect_grads = []\n",
    "        incorrect_features = []\n",
    "        incorrect_losses = []\n",
    "        \n",
    "        for gid in class_correct_gids:\n",
    "            if gid in analysis and analysis[gid]['avg_gradient'] is not None:\n",
    "                correct_grads.append(analysis[gid]['avg_gradient'])\n",
    "                # Extract features as a numpy array explicitly\n",
    "                feat_values = DO.df_train_hypothesis.loc[gid, input_cols].values.astype(np.float64)\n",
    "                correct_features.append(feat_values)\n",
    "                correct_losses.append(float(analysis[gid]['avg_loss']))\n",
    "        \n",
    "        for gid in class_incorrect_gids:\n",
    "            if gid in analysis and analysis[gid]['avg_gradient'] is not None:\n",
    "                incorrect_grads.append(analysis[gid]['avg_gradient'])\n",
    "                feat_values = DO.df_train_hypothesis.loc[gid, input_cols].values.astype(np.float64)\n",
    "                incorrect_features.append(feat_values)\n",
    "                incorrect_losses.append(float(analysis[gid]['avg_loss']))\n",
    "        \n",
    "        if not correct_grads or not incorrect_grads:\n",
    "            print(f\"\\nClass {class_id}: No valid gradients\")\n",
    "            continue\n",
    "        \n",
    "        # Convert to arrays with explicit dtype\n",
    "        correct_grads = np.array(correct_grads, dtype=np.float64)\n",
    "        incorrect_grads = np.array(incorrect_grads, dtype=np.float64)\n",
    "        correct_features = np.array(correct_features, dtype=np.float64)\n",
    "        incorrect_features = np.array(incorrect_features, dtype=np.float64)\n",
    "        correct_losses = np.array(correct_losses, dtype=np.float64).reshape(-1, 1)\n",
    "        incorrect_losses = np.array(incorrect_losses, dtype=np.float64).reshape(-1, 1)\n",
    "        \n",
    "        # Normalize features and losses to be on similar scale as gradients\n",
    "        # Use the gradient norm as reference scale\n",
    "        grad_norms = [np.linalg.norm(g) for g in correct_grads] + [np.linalg.norm(g) for g in incorrect_grads]\n",
    "        grad_scale = float(np.mean(grad_norms))\n",
    "        \n",
    "        all_features = np.vstack([correct_features, incorrect_features])\n",
    "        feature_mean = np.mean(all_features, axis=0).astype(np.float64)\n",
    "        feature_std = np.std(all_features, axis=0).astype(np.float64) + 1e-8\n",
    "        \n",
    "        # Normalize features to have similar scale as gradients\n",
    "        correct_features_norm = (correct_features - feature_mean) / feature_std * grad_scale\n",
    "        incorrect_features_norm = (incorrect_features - feature_mean) / feature_std * grad_scale\n",
    "        \n",
    "        all_losses = np.vstack([correct_losses, incorrect_losses])\n",
    "        loss_mean = float(np.mean(all_losses))\n",
    "        loss_std = float(np.std(all_losses)) + 1e-8\n",
    "        correct_losses_norm = (correct_losses - loss_mean) / loss_std * grad_scale\n",
    "        incorrect_losses_norm = (incorrect_losses - loss_mean) / loss_std * grad_scale\n",
    "        \n",
    "        # Method 1: Gradient only\n",
    "        anchor_correct_grad = np.mean(correct_grads, axis=0)\n",
    "        anchor_incorrect_grad = np.mean(incorrect_grads, axis=0)\n",
    "        sim_grad = float(np.dot(anchor_correct_grad, anchor_incorrect_grad) / (\n",
    "            np.linalg.norm(anchor_correct_grad) * np.linalg.norm(anchor_incorrect_grad) + 1e-8))\n",
    "        \n",
    "        # Method 2: Gradient + input features\n",
    "        correct_grad_feat = np.hstack([correct_grads, correct_features_norm])\n",
    "        incorrect_grad_feat = np.hstack([incorrect_grads, incorrect_features_norm])\n",
    "        anchor_correct_gf = np.mean(correct_grad_feat, axis=0)\n",
    "        anchor_incorrect_gf = np.mean(incorrect_grad_feat, axis=0)\n",
    "        sim_grad_feat = float(np.dot(anchor_correct_gf, anchor_incorrect_gf) / (\n",
    "            np.linalg.norm(anchor_correct_gf) * np.linalg.norm(anchor_incorrect_gf) + 1e-8))\n",
    "        \n",
    "        # Method 3: Gradient + input features + loss\n",
    "        correct_grad_feat_loss = np.hstack([correct_grads, correct_features_norm, correct_losses_norm])\n",
    "        incorrect_grad_feat_loss = np.hstack([incorrect_grads, incorrect_features_norm, incorrect_losses_norm])\n",
    "        anchor_correct_gfl = np.mean(correct_grad_feat_loss, axis=0)\n",
    "        anchor_incorrect_gfl = np.mean(incorrect_grad_feat_loss, axis=0)\n",
    "        sim_grad_feat_loss = float(np.dot(anchor_correct_gfl, anchor_incorrect_gfl) / (\n",
    "            np.linalg.norm(anchor_correct_gfl) * np.linalg.norm(anchor_incorrect_gfl) + 1e-8))\n",
    "        \n",
    "        hyp_value = hypothesis[0][class_id]\n",
    "        print(f\"\\nClass {class_id} (alcohol={hyp_value}):\")\n",
    "        print(f\"  Samples: correct={len(correct_grads)}, incorrect={len(incorrect_grads)}\")\n",
    "        print(f\"  Gradient only:             anchor_similarity = {sim_grad:.4f}\")\n",
    "        print(f\"  Gradient + input_features: anchor_similarity = {sim_grad_feat:.4f}\")\n",
    "        print(f\"  Gradient + features + loss: anchor_similarity = {sim_grad_feat_loss:.4f}\")\n",
    "        \n",
    "        # Check if context helps (similarity closer to -1 is better)\n",
    "        if sim_grad_feat < sim_grad:\n",
    "            print(f\"  → Adding input features IMPROVES separation (Δ = {sim_grad - sim_grad_feat:.4f})\")\n",
    "        else:\n",
    "            print(f\"  → Adding input features does NOT help\")\n",
    "        \n",
    "        # Also check the actual feature differences\n",
    "        print(f\"  \\n  Input feature statistics:\")\n",
    "        correct_feat_mean = np.mean(correct_features, axis=0)\n",
    "        incorrect_feat_mean = np.mean(incorrect_features, axis=0)\n",
    "        feat_diff = correct_feat_mean - incorrect_feat_mean\n",
    "        max_diff_idx = np.argmax(np.abs(feat_diff))\n",
    "        print(f\"    Largest mean difference: {input_cols[max_diff_idx]} (Δ = {feat_diff[max_diff_idx]:.4f})\")\n",
    "        \n",
    "        results[class_id] = {\n",
    "            'sim_grad': sim_grad,\n",
    "            'sim_grad_feat': sim_grad_feat,\n",
    "            'sim_grad_feat_loss': sim_grad_feat_loss,\n",
    "            'n_correct': len(correct_grads),\n",
    "            'n_incorrect': len(incorrect_grads)\n",
    "        }\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nAnchor similarity closer to -1 means BETTER separation (opposite directions)\")\n",
    "    print(\"Anchor similarity close to +1 means POOR separation (same direction)\")\n",
    "    print(\"\\n| Class | Grad Only | Grad+Feat | Grad+Feat+Loss | Best Method |\")\n",
    "    print(\"|-------|-----------|-----------|----------------|-------------|\")\n",
    "    for c, r in results.items():\n",
    "        best = \"Grad Only\"\n",
    "        best_sim = r['sim_grad']\n",
    "        if r['sim_grad_feat'] < best_sim:\n",
    "            best = \"Grad+Feat\"\n",
    "            best_sim = r['sim_grad_feat']\n",
    "        if r['sim_grad_feat_loss'] < best_sim:\n",
    "            best = \"Grad+F+L\"\n",
    "        print(f\"|   {c}   |  {r['sim_grad']:+.3f}   |  {r['sim_grad_feat']:+.3f}   |    {r['sim_grad_feat_loss']:+.3f}      | {best:11} |\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the diagnostic\n",
    "if not DO.lack_partial_coverage:\n",
    "    context_results = diagnose_gradient_vs_context(trainer_amp, DO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive_context_helpers",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "tn69hfx3pig",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXPERIMENT 4: ALCOHOL DISTRIBUTION ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "1. Alcohol Distribution in Training Data:\n",
      "   Min:    0.15\n",
      "   Max:    0.55\n",
      "   Mean:   0.30\n",
      "   Median: 0.32\n",
      "   Std:    0.15\n",
      "\n",
      "   Quantiles:\n",
      "     10%: 0.15\n",
      "     25%: 0.15\n",
      "     50%: 0.32\n",
      "     75%: 0.32\n",
      "     90%: 0.55\n",
      "\n",
      "2. Current Hypotheses: [9.4, 10.5, 12.0]\n",
      "\n",
      "3. Samples per Hypothesis Class:\n",
      "   Class 0 (alcohol= 9.40):  482 samples ( 41.9%) \n",
      "   Class 1 (alcohol=10.50):  407 samples ( 35.4%) \n",
      "   Class 2 (alcohol=12.00):  262 samples ( 22.8%) \n",
      "\n",
      "4. Suggested Alternative Hypotheses (based on quantiles):\n",
      "   10%, 33%, 66%, 90% quantiles: [np.float64(0.15), np.float64(0.15), np.float64(0.32), np.float64(0.55)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved to ../saved_results/Red Wine Hybrid/phase1/alcohol_distribution.png\n"
     ]
    }
   ],
   "source": [
    "# EXPERIMENT 4: Check Alcohol Distribution vs Hypotheses\n",
    "# Goal: Understand if hypothesis values match the actual data distribution\n",
    "\n",
    "if not DO.lack_partial_coverage:\n",
    "    print(f\"{'='*70}\")\n",
    "    print(\"EXPERIMENT 4: ALCOHOL DISTRIBUTION ANALYSIS\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Get actual alcohol values for correct hypotheses\n",
    "    correct_hyp_mask = DO.df_train_hypothesis['correct_hypothesis'] == True\n",
    "    alcohol_col = f'{miss_vars[0]}_hypothesis'\n",
    "    alcohol_values = DO.df_train_hypothesis[correct_hyp_mask][alcohol_col]\n",
    "    \n",
    "    print(\"\\n1. Alcohol Distribution in Training Data:\")\n",
    "    print(f\"   Min:    {alcohol_values.min():.2f}\")\n",
    "    print(f\"   Max:    {alcohol_values.max():.2f}\")\n",
    "    print(f\"   Mean:   {alcohol_values.mean():.2f}\")\n",
    "    print(f\"   Median: {alcohol_values.median():.2f}\")\n",
    "    print(f\"   Std:    {alcohol_values.std():.2f}\")\n",
    "    \n",
    "    print(f\"\\n   Quantiles:\")\n",
    "    for q in [0.1, 0.25, 0.5, 0.75, 0.9]:\n",
    "        print(f\"     {int(q*100):>2}%: {alcohol_values.quantile(q):.2f}\")\n",
    "    \n",
    "    print(f\"\\n2. Current Hypotheses: {hypothesis[0]}\")\n",
    "    \n",
    "    print(f\"\\n3. Samples per Hypothesis Class:\")\n",
    "    total_samples = len(alcohol_values)\n",
    "    class_counts = {}\n",
    "    for class_id in range(hyp_per_sample):\n",
    "        count = (DO.df_train_hypothesis[correct_hyp_mask]['hyp_class_id'] == class_id).sum()\n",
    "        hyp_value = hypothesis[0][class_id]\n",
    "        pct = count / total_samples * 100\n",
    "        class_counts[class_id] = count\n",
    "        marker = \"⚠️ SPARSE!\" if pct < 5 else (\"⚠️ LOW\" if pct < 15 else \"\")\n",
    "        print(f\"   Class {class_id} (alcohol={hyp_value:>5.2f}): {count:>4} samples ({pct:>5.1f}%) {marker}\")\n",
    "    \n",
    "    print(f\"\\n4. Suggested Alternative Hypotheses (based on quantiles):\")\n",
    "    suggested = [\n",
    "        alcohol_values.quantile(0.1),\n",
    "        alcohol_values.quantile(0.33),\n",
    "        alcohol_values.quantile(0.66),\n",
    "        alcohol_values.quantile(0.9)\n",
    "    ]\n",
    "    print(f\"   10%, 33%, 66%, 90% quantiles: {[round(x, 2) for x in suggested]}\")\n",
    "    \n",
    "    # Plot distribution\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Histogram with hypothesis lines\n",
    "    ax1 = axes[0]\n",
    "    ax1.hist(alcohol_values, bins=30, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "    colors = ['red', 'orange', 'green', 'purple']\n",
    "    for i, hyp_val in enumerate(hypothesis[0]):\n",
    "        ax1.axvline(x=hyp_val, color=colors[i], linestyle='--', linewidth=2, \n",
    "                   label=f'Class {i}: {hyp_val}')\n",
    "    ax1.set_xlabel('Alcohol Value')\n",
    "    ax1.set_ylabel('Count')\n",
    "    ax1.set_title('Alcohol Distribution with Current Hypotheses')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Bar chart of class counts\n",
    "    ax2 = axes[1]\n",
    "    bars = ax2.bar(range(hyp_per_sample), [class_counts[i] for i in range(hyp_per_sample)], \n",
    "                   color=colors, alpha=0.7)\n",
    "    ax2.set_xticks(range(hyp_per_sample))\n",
    "    ax2.set_xticklabels([f'Class {i}\\n({hypothesis[0][i]})' for i in range(hyp_per_sample)])\n",
    "    ax2.set_ylabel('Number of Samples')\n",
    "    ax2.set_title('Samples per Hypothesis Class')\n",
    "    \n",
    "    # Add count labels on bars\n",
    "    for bar, count in zip(bars, [class_counts[i] for i in range(hyp_per_sample)]):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10, \n",
    "                str(count), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{results_path}/phase1/alcohol_distribution.png', dpi=150)\n",
    "    plt.show()\n",
    "    print(f\"\\nSaved to {results_path}/phase1/alcohol_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "hna9fjbdfjr",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEBUG: NORMALIZED SCORE SAMPLE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Per-class method selection:\n",
      "  Class 0: grad_sim=-0.992 (good) → GRADIENT-ONLY\n",
      "  Class 1: grad_sim=+0.976 (poor) → ENRICHED (enriched_sim=-0.353)\n",
      "  Class 2: grad_sim=-0.420 (good) → GRADIENT-ONLY\n",
      "\n",
      "Score statistics per class (for Z-score normalization):\n",
      "------------------------------------------------------------\n",
      "  Class 0 (grad-only): mean=+0.129, std=1.983, range=[-2.00, 2.00]\n",
      "  Class 1 (enriched): mean=-0.201, std=0.946, range=[-1.62, 1.58]\n",
      "  Class 2 (grad-only): mean=-0.109, std=1.389, range=[-1.50, 1.50]\n",
      "\n",
      "======================================================================\n",
      "SAMPLE SELECTIONS (first 5 non-partial)\n",
      "======================================================================\n",
      "\n",
      "Sample 0 (True class: 1):\n",
      "  Class 2 (grd): norm=+1.097 (raw=+1.415) ← SELECTED\n",
      "  Class 1 (enr): norm=+0.044 (raw=-0.159) ← TRUE\n",
      "  Class 0 (grd): norm=-1.070 (raw=-1.993)\n",
      "\n",
      "Sample 1 (True class: 0):\n",
      "  Class 0 (grd): norm=+0.936 (raw=+1.986) ← TRUE ← SELECTED\n",
      "  Class 2 (grd): norm=-0.858 (raw=-1.301)\n",
      "  Class 1 (enr): norm=-0.900 (raw=-1.053)\n",
      "\n",
      "Sample 2 (True class: 2):\n",
      "  Class 2 (grd): norm=+1.133 (raw=+1.466) ← TRUE ← SELECTED\n",
      "  Class 1 (enr): norm=+0.668 (raw=+0.431)\n",
      "  Class 0 (grd): norm=-1.062 (raw=-1.976)\n",
      "\n",
      "Sample 3 (True class: 1):\n",
      "  Class 2 (grd): norm=+1.081 (raw=+1.392) ← SELECTED\n",
      "  Class 1 (enr): norm=-0.346 (raw=-0.528) ← TRUE\n",
      "  Class 0 (grd): norm=-1.072 (raw=-1.996)\n",
      "\n",
      "Sample 4 (True class: 1):\n",
      "  Class 1 (enr): norm=+1.521 (raw=+1.239) ← TRUE ← SELECTED\n",
      "  Class 0 (grd): norm=+0.937 (raw=+1.986)\n",
      "  Class 2 (grd): norm=-0.969 (raw=-1.455)\n"
     ]
    }
   ],
   "source": [
    "# DEBUG: Sample-Level Analysis with NORMALIZED Scores\n",
    "\n",
    "if not DO.lack_partial_coverage:\n",
    "    print(f\"{'='*70}\")\n",
    "    print(\"DEBUG: NORMALIZED SCORE SAMPLE ANALYSIS\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Get anchor data with stats\n",
    "    anchor_data = compute_anchor_data_with_stats(trainer_amp, DO)\n",
    "    analysis = trainer_amp.get_hypothesis_analysis()\n",
    "    hyp_per_sample = DO.num_hyp_comb\n",
    "    n_samples = len(DO.df_train_hypothesis) // hyp_per_sample\n",
    "    input_cols = anchor_data['input_cols']\n",
    "    \n",
    "    partial_sample_indices = anchor_data['partial_sample_indices']\n",
    "    blacklisted_gids = anchor_data['blacklisted_gids']\n",
    "    \n",
    "    # Show method per class with stats\n",
    "    print()\n",
    "    print_adaptive_method_summary(anchor_data, hyp_per_sample)\n",
    "    print_score_stats(anchor_data, hyp_per_sample)\n",
    "    \n",
    "    # Show a few sample selections\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SAMPLE SELECTIONS (first 5 non-partial)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    shown = 0\n",
    "    for sample_idx in range(n_samples):\n",
    "        if sample_idx in partial_sample_indices:\n",
    "            continue\n",
    "        if shown >= 5:\n",
    "            break\n",
    "            \n",
    "        start = sample_idx * hyp_per_sample\n",
    "        \n",
    "        # Find true class\n",
    "        true_class = None\n",
    "        for hyp_idx in range(hyp_per_sample):\n",
    "            gid = start + hyp_idx\n",
    "            if DO.df_train_hypothesis.iloc[gid]['correct_hypothesis']:\n",
    "                true_class = hyp_idx\n",
    "                break\n",
    "        \n",
    "        print(f\"\\nSample {sample_idx} (True class: {true_class}):\")\n",
    "        \n",
    "        scores = []\n",
    "        for hyp_idx in range(hyp_per_sample):\n",
    "            gid = start + hyp_idx\n",
    "            if gid in blacklisted_gids:\n",
    "                scores.append((hyp_idx, -np.inf, -np.inf))\n",
    "                continue\n",
    "            if gid not in analysis or analysis[gid]['avg_gradient'] is None:\n",
    "                scores.append((hyp_idx, -np.inf, -np.inf))\n",
    "                continue\n",
    "            \n",
    "            gradient = analysis[gid]['avg_gradient']\n",
    "            class_id = DO.df_train_hypothesis.iloc[gid]['hyp_class_id']\n",
    "            features = DO.df_train_hypothesis.loc[gid, input_cols].values.astype(np.float64)\n",
    "            \n",
    "            raw_score = compute_adaptive_score(gradient, features, class_id, anchor_data)\n",
    "            norm_score = compute_adaptive_score_normalized(gradient, features, class_id, anchor_data)\n",
    "            scores.append((hyp_idx, norm_score, raw_score))\n",
    "        \n",
    "        # Sort by NORMALIZED score\n",
    "        sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "        winner = sorted_scores[0][0]\n",
    "        \n",
    "        for hyp_idx, norm_score, raw_score in sorted_scores:\n",
    "            use_enr = anchor_data['use_enriched'].get(hyp_idx, False)\n",
    "            method = \"enr\" if use_enr else \"grd\"\n",
    "            marker = \"\"\n",
    "            if hyp_idx == true_class:\n",
    "                marker = \" ← TRUE\"\n",
    "            if hyp_idx == winner:\n",
    "                marker += \" ← SELECTED\"\n",
    "            print(f\"  Class {hyp_idx} ({method}): norm={norm_score:+.3f} (raw={raw_score:+.3f}){marker}\")\n",
    "        \n",
    "        shown += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9yqqe7ilrm4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TESTING DIFFERENT PRIOR WEIGHTS\n",
      "======================================================================\n",
      "\n",
      "  Prior weight=0.0: 48.9% precision\n",
      "  Prior weight=0.5: 50.1% precision\n",
      "======================================================================\n",
      "CLASS PRIOR CORRECTION + ADAPTIVE CONTEXT + Z-SCORE NORMALIZATION\n",
      "======================================================================\n",
      "\n",
      "Prior weight: 1.0\n",
      "\n",
      "True class distribution and adjustments:\n",
      "  Class 0 (grad-only): 41.9% → prior adj: +0.228\n",
      "  Class 1 (enriched): 35.4% → prior adj: +0.059\n",
      "  Class 2 (grad-only): 22.8% → prior adj: -0.381\n",
      "Per-class method selection:\n",
      "  Class 0: grad_sim=-0.992 (good) → GRADIENT-ONLY\n",
      "  Class 1: grad_sim=+0.976 (poor) → ENRICHED (enriched_sim=-0.353)\n",
      "  Class 2: grad_sim=-0.420 (good) → GRADIENT-ONLY\n",
      "\n",
      "Score statistics per class (for Z-score normalization):\n",
      "------------------------------------------------------------\n",
      "  Class 0 (grad-only): mean=+0.129, std=1.983, range=[-2.00, 2.00]\n",
      "  Class 1 (enriched): mean=-0.201, std=0.946, range=[-1.62, 1.58]\n",
      "  Class 2 (grad-only): mean=-0.109, std=1.389, range=[-1.50, 1.50]\n",
      "\n",
      "======================================================================\n",
      "RESULTS\n",
      "======================================================================\n",
      "\n",
      "  Total selected: 1123\n",
      "  Correct: 550 (49.0% precision)\n",
      "  Random baseline: 33.3%\n",
      "\n",
      "  Per-class breakdown:\n",
      "    Class 0 (grad-only): 456 selected (40.6%), 293 correct (64.3% prec) | True: 41.9%\n",
      "    Class 1 (enriched): 273 selected (24.3%), 113 correct (41.4% prec) | True: 35.4%\n",
      "    Class 2 (grad-only): 394 selected (35.1%), 144 correct (36.5% prec) | True: 22.8%\n",
      "\n",
      "======================================================================\n",
      "CONFUSION MATRIX (True vs Selected)\n",
      "======================================================================\n",
      "\n",
      "      Selected →\n",
      "True ↓    C0     C1     C2  \n",
      "  C0      293     77    103 \n",
      "  C1      137    113    147 \n",
      "  C2       26     83    144 \n",
      "  Prior weight=1.5: 47.7% precision\n",
      "  Prior weight=2.0: 47.5% precision\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IDEA 1: CLASS PRIOR CORRECTION + ADAPTIVE CONTEXT + Z-SCORE NORMALIZATION\n",
    "# =============================================================================\n",
    "# Problem: We're selecting 40% Class 2 when truth is only 22.5%\n",
    "# Solution: Add log-prior penalty to adjust scores toward true distribution\n",
    "# \n",
    "# This version uses:\n",
    "# - Adaptive context (gradient-only or enriched based on anchor quality)\n",
    "# - Z-score normalization (comparable score scales across classes)\n",
    "# - Class prior correction (penalize over-represented classes)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def selection_with_prior_correction_adaptive(trainer, DO, prior_weight=1.0, verbose=True):\n",
    "    \"\"\"\n",
    "    Select hypotheses using:\n",
    "    1. Adaptive context (gradient-only or enriched per class)\n",
    "    2. Z-score normalization \n",
    "    3. Class prior correction\n",
    "    \n",
    "    final_score = normalized_adaptive_score + prior_weight * log(true_prior / uniform_prior)\n",
    "    \"\"\"\n",
    "    # Get anchor data WITH score statistics for normalization\n",
    "    anchor_data = compute_anchor_data_with_stats(trainer, DO)\n",
    "    \n",
    "    analysis = trainer.get_hypothesis_analysis()\n",
    "    hyp_per_sample = DO.num_hyp_comb\n",
    "    n_samples = len(DO.df_train_hypothesis) // hyp_per_sample\n",
    "    input_cols = anchor_data['input_cols']\n",
    "    \n",
    "    partial_sample_indices = anchor_data['partial_sample_indices']\n",
    "    blacklisted_gids = anchor_data['blacklisted_gids']\n",
    "    \n",
    "    # Compute TRUE class distribution from known correct hypotheses\n",
    "    correct_mask = DO.df_train_hypothesis['correct_hypothesis'] == True\n",
    "    true_class_counts = DO.df_train_hypothesis[correct_mask]['hyp_class_id'].value_counts().sort_index()\n",
    "    true_priors = (true_class_counts / true_class_counts.sum()).to_dict()\n",
    "    \n",
    "    # Uniform prior for comparison\n",
    "    uniform_prior = 1.0 / hyp_per_sample\n",
    "    \n",
    "    # Compute log-prior adjustment per class\n",
    "    # Positive for under-represented classes, negative for over-represented\n",
    "    prior_adjustment = {}\n",
    "    for c in range(hyp_per_sample):\n",
    "        prior_adjustment[c] = np.log(true_priors.get(c, uniform_prior) / uniform_prior)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"=\"*70)\n",
    "        print(\"CLASS PRIOR CORRECTION + ADAPTIVE CONTEXT + Z-SCORE NORMALIZATION\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\nPrior weight: {prior_weight}\")\n",
    "        print(f\"\\nTrue class distribution and adjustments:\")\n",
    "        for c in range(hyp_per_sample):\n",
    "            use_enr = anchor_data['use_enriched'].get(c, False)\n",
    "            method = \"enriched\" if use_enr else \"grad-only\"\n",
    "            print(f\"  Class {c} ({method}): {true_priors.get(c, 0)*100:.1f}% → prior adj: {prior_adjustment[c]:+.3f}\")\n",
    "        \n",
    "        print_adaptive_method_summary(anchor_data, hyp_per_sample)\n",
    "        print_score_stats(anchor_data, hyp_per_sample)\n",
    "    \n",
    "    # Selection with adaptive scoring + prior correction\n",
    "    selected_gids = []\n",
    "    selection_correct = 0\n",
    "    class_selections = {c: 0 for c in range(hyp_per_sample)}\n",
    "    class_correct_sel = {c: 0 for c in range(hyp_per_sample)}\n",
    "    \n",
    "    # Track for confusion matrix\n",
    "    confusion = {true_c: {sel_c: 0 for sel_c in range(hyp_per_sample)} for true_c in range(hyp_per_sample)}\n",
    "    \n",
    "    for sample_idx in range(n_samples):\n",
    "        if sample_idx in partial_sample_indices:\n",
    "            continue\n",
    "        \n",
    "        start = sample_idx * hyp_per_sample\n",
    "        best_final_score = -np.inf\n",
    "        best_gid = None\n",
    "        best_class = None\n",
    "        best_is_correct = False\n",
    "        \n",
    "        # Track true class for this sample\n",
    "        true_class = None\n",
    "        \n",
    "        for hyp_idx in range(hyp_per_sample):\n",
    "            gid = start + hyp_idx\n",
    "            if gid in blacklisted_gids:\n",
    "                continue\n",
    "            if gid not in analysis or analysis[gid]['avg_gradient'] is None:\n",
    "                continue\n",
    "            \n",
    "            gradient = analysis[gid]['avg_gradient']\n",
    "            class_id = DO.df_train_hypothesis.iloc[gid]['hyp_class_id']\n",
    "            is_correct = DO.df_train_hypothesis.iloc[gid]['correct_hypothesis']\n",
    "            features = DO.df_train_hypothesis.loc[gid, input_cols].values.astype(np.float64)\n",
    "            \n",
    "            if is_correct:\n",
    "                true_class = class_id\n",
    "            \n",
    "            # Compute NORMALIZED ADAPTIVE score\n",
    "            normalized_score = compute_adaptive_score_normalized(gradient, features, class_id, anchor_data)\n",
    "            \n",
    "            # Apply prior correction\n",
    "            final_score = normalized_score + prior_weight * prior_adjustment[class_id]\n",
    "            \n",
    "            if final_score > best_final_score:\n",
    "                best_final_score = final_score\n",
    "                best_gid = gid\n",
    "                best_class = class_id\n",
    "                best_is_correct = is_correct\n",
    "        \n",
    "        if best_gid is not None:\n",
    "            selected_gids.append(best_gid)\n",
    "            class_selections[best_class] += 1\n",
    "            if best_is_correct:\n",
    "                selection_correct += 1\n",
    "                class_correct_sel[best_class] += 1\n",
    "            \n",
    "            # Update confusion matrix\n",
    "            if true_class is not None:\n",
    "                confusion[true_class][best_class] += 1\n",
    "    \n",
    "    precision = selection_correct / len(selected_gids) if selected_gids else 0\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"RESULTS\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\n  Total selected: {len(selected_gids)}\")\n",
    "        print(f\"  Correct: {selection_correct} ({precision*100:.1f}% precision)\")\n",
    "        print(f\"  Random baseline: {100/hyp_per_sample:.1f}%\")\n",
    "        print(f\"\\n  Per-class breakdown:\")\n",
    "        for c in range(hyp_per_sample):\n",
    "            sel = class_selections[c]\n",
    "            corr = class_correct_sel[c]\n",
    "            prec = corr/sel*100 if sel > 0 else 0\n",
    "            true_pct = true_priors.get(c, 0) * 100\n",
    "            sel_pct = sel / len(selected_gids) * 100 if selected_gids else 0\n",
    "            use_enr = anchor_data['use_enriched'].get(c, False)\n",
    "            method = \"enriched\" if use_enr else \"grad-only\"\n",
    "            print(f\"    Class {c} ({method}): {sel} selected ({sel_pct:.1f}%), {corr} correct ({prec:.1f}% prec) | True: {true_pct:.1f}%\")\n",
    "        \n",
    "        # Print confusion matrix\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"CONFUSION MATRIX (True vs Selected)\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\n      Selected →\")\n",
    "        header = \"True ↓ \" + \"\".join([f\"   C{c}  \" for c in range(hyp_per_sample)])\n",
    "        print(header)\n",
    "        for true_c in range(hyp_per_sample):\n",
    "            row = f\"  C{true_c}   \"\n",
    "            for sel_c in range(hyp_per_sample):\n",
    "                row += f\" {confusion[true_c][sel_c]:>5} \"\n",
    "            print(row)\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'selected_gids': selected_gids,\n",
    "        'class_selections': class_selections,\n",
    "        'class_correct': class_correct_sel,\n",
    "        'prior_adjustment': prior_adjustment,\n",
    "        'confusion': confusion\n",
    "    }\n",
    "\n",
    "# Run the test with different prior weights\n",
    "if not DO.lack_partial_coverage:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TESTING DIFFERENT PRIOR WEIGHTS\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    for weight in [0.0, 0.5, 1.0, 1.5, 2.0]:\n",
    "        results = selection_with_prior_correction_adaptive(trainer_amp, DO, prior_weight=weight, verbose=(weight==1.0))\n",
    "        if weight != 1.0:\n",
    "            print(f\"  Prior weight={weight}: {results['precision']*100:.1f}% precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "vklgyghfdym",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PART 1: STABILITY ANALYSIS - Is there a signal?\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "PART 2: SELECTION WITH STABILITY\n",
      "======================================================================\n",
      "\n",
      "  Stability weight=0.0: 48.8% precision\n",
      "  Stability weight=0.25: 48.8% precision\n",
      "======================================================================\n",
      "GRADIENT STABILITY ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Samples analyzed: 1151 correct, 2302 incorrect\n",
      "\n",
      "Metric                    Correct         Incorrect       Diff       Signal?\n",
      "----------------------------------------------------------------------\n",
      "direction stability           0.9569         0.9597     -0.0028    ✗ weak\n",
      "magnitude stability           0.8756         0.8761     -0.0005    ✗ weak\n",
      "final stability               0.9790         0.9774     +0.0016    ✗ weak\n",
      "combined stability            0.9372         0.9377     -0.0005    ✗ weak\n",
      "\n",
      "======================================================================\n",
      "SELECTION WITH STABILITY (weight=0.5)\n",
      "======================================================================\n",
      "\n",
      "Results:\n",
      "  Total selected: 1123\n",
      "  Correct: 548 (48.8% precision)\n",
      "  Random baseline: 33.3%\n",
      "\n",
      "  Per-class breakdown:\n",
      "    Class 0: 598 selected (53.3%), 346 correct (57.9% prec)\n",
      "    Class 1: 11 selected (1.0%), 6 correct (54.5% prec)\n",
      "    Class 2: 514 selected (45.8%), 196 correct (38.1% prec)\n",
      "  Stability weight=1.0: 48.8% precision\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IDEA 6: GRADIENT TRAJECTORY / STABILITY\n",
    "# =============================================================================\n",
    "# Hypothesis: Correct hypotheses have more STABLE gradients over training epochs\n",
    "# - Correct: gradient direction stays consistent as model learns\n",
    "# - Incorrect: gradient direction may fluctuate as model struggles\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def compute_gradient_stability(trainer, DO, verbose=True):\n",
    "    \"\"\"\n",
    "    Analyze gradient stability across training epochs.\n",
    "    \n",
    "    Metrics:\n",
    "    1. Direction stability: Average cosine similarity between consecutive epoch gradients\n",
    "    2. Magnitude stability: Coefficient of variation of gradient magnitudes\n",
    "    3. Final direction alignment: How aligned is final gradient with average direction\n",
    "    \"\"\"\n",
    "    hyp_per_sample = DO.num_hyp_comb\n",
    "    \n",
    "    # Access raw gradient history from trainer\n",
    "    gradient_history = trainer.gradient_history\n",
    "    \n",
    "    stability_metrics = {}\n",
    "    \n",
    "    for gid, grad_list in gradient_history.items():\n",
    "        if len(grad_list) < 2:\n",
    "            continue\n",
    "        \n",
    "        grads = np.array(grad_list)\n",
    "        n_epochs = len(grads)\n",
    "        \n",
    "        # 1. Direction stability: cosine similarity between consecutive epochs\n",
    "        direction_sims = []\n",
    "        for i in range(n_epochs - 1):\n",
    "            g1, g2 = grads[i], grads[i+1]\n",
    "            norm1, norm2 = np.linalg.norm(g1), np.linalg.norm(g2)\n",
    "            if norm1 > 1e-8 and norm2 > 1e-8:\n",
    "                sim = np.dot(g1, g2) / (norm1 * norm2)\n",
    "                direction_sims.append(sim)\n",
    "        \n",
    "        direction_stability = np.mean(direction_sims) if direction_sims else 0.0\n",
    "        \n",
    "        # 2. Magnitude stability: coefficient of variation (std/mean)\n",
    "        magnitudes = np.linalg.norm(grads, axis=1)\n",
    "        magnitude_cv = np.std(magnitudes) / (np.mean(magnitudes) + 1e-8)\n",
    "        magnitude_stability = 1.0 / (1.0 + magnitude_cv)  # Higher = more stable\n",
    "        \n",
    "        # 3. Final alignment: how aligned is final gradient with average\n",
    "        avg_grad = np.mean(grads, axis=0)\n",
    "        final_grad = grads[-1]\n",
    "        avg_norm, final_norm = np.linalg.norm(avg_grad), np.linalg.norm(final_grad)\n",
    "        if avg_norm > 1e-8 and final_norm > 1e-8:\n",
    "            final_alignment = np.dot(avg_grad, final_grad) / (avg_norm * final_norm)\n",
    "        else:\n",
    "            final_alignment = 0.0\n",
    "        \n",
    "        stability_metrics[gid] = {\n",
    "            'direction_stability': direction_stability,\n",
    "            'magnitude_stability': magnitude_stability,\n",
    "            'final_alignment': final_alignment,\n",
    "            'combined_stability': (direction_stability + magnitude_stability + final_alignment) / 3\n",
    "        }\n",
    "    \n",
    "    # Analyze by correctness\n",
    "    correct_stabilities = {'direction': [], 'magnitude': [], 'final': [], 'combined': []}\n",
    "    incorrect_stabilities = {'direction': [], 'magnitude': [], 'final': [], 'combined': []}\n",
    "    \n",
    "    for gid, metrics in stability_metrics.items():\n",
    "        is_correct = DO.df_train_hypothesis.iloc[gid]['correct_hypothesis']\n",
    "        target = correct_stabilities if is_correct else incorrect_stabilities\n",
    "        target['direction'].append(metrics['direction_stability'])\n",
    "        target['magnitude'].append(metrics['magnitude_stability'])\n",
    "        target['final'].append(metrics['final_alignment'])\n",
    "        target['combined'].append(metrics['combined_stability'])\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"=\"*70)\n",
    "        print(\"GRADIENT STABILITY ANALYSIS\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\nSamples analyzed: {len(correct_stabilities['direction'])} correct, {len(incorrect_stabilities['direction'])} incorrect\")\n",
    "        \n",
    "        print(f\"\\n{'Metric':<25} {'Correct':<15} {'Incorrect':<15} {'Diff':<10} {'Signal?'}\")\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "        for metric_name in ['direction', 'magnitude', 'final', 'combined']:\n",
    "            corr_mean = np.mean(correct_stabilities[metric_name])\n",
    "            incorr_mean = np.mean(incorrect_stabilities[metric_name])\n",
    "            diff = corr_mean - incorr_mean\n",
    "            signal = \"✓ YES\" if abs(diff) > 0.02 else \"✗ weak\"\n",
    "            print(f\"{metric_name + ' stability':<25} {corr_mean:>10.4f}     {incorr_mean:>10.4f}     {diff:>+.4f}    {signal}\")\n",
    "    \n",
    "    return stability_metrics, correct_stabilities, incorrect_stabilities\n",
    "\n",
    "\n",
    "def selection_with_stability(trainer, DO, stability_weight=0.5, verbose=True):\n",
    "    \"\"\"\n",
    "    Select hypotheses using gradient scores + stability bonus.\n",
    "    \n",
    "    final_score = gradient_score + stability_weight * stability_score\n",
    "    \"\"\"\n",
    "    # First compute stability metrics\n",
    "    stability_metrics, correct_stab, incorrect_stab = compute_gradient_stability(trainer, DO, verbose=verbose)\n",
    "    \n",
    "    analysis = trainer.get_hypothesis_analysis()\n",
    "    hyp_per_sample = DO.num_hyp_comb\n",
    "    n_samples = len(DO.df_train_hypothesis) // hyp_per_sample\n",
    "    \n",
    "    # Get partial data info\n",
    "    partial_correct_gids = set(DO.df_train_hypothesis[\n",
    "        (DO.df_train_hypothesis['partial_full_info'] == 1) & \n",
    "        (DO.df_train_hypothesis['correct_hypothesis'] == True)\n",
    "    ].index.tolist())\n",
    "    blacklisted_gids = set(DO.df_train_hypothesis[\n",
    "        (DO.df_train_hypothesis['partial_full_info'] == 1) & \n",
    "        (DO.df_train_hypothesis['correct_hypothesis'] == False)\n",
    "    ].index.tolist())\n",
    "    partial_sample_indices = set(gid // hyp_per_sample for gid in partial_correct_gids)\n",
    "    \n",
    "    # Compute anchors\n",
    "    anchor_correct = {}\n",
    "    anchor_incorrect = {}\n",
    "    \n",
    "    for class_id in range(hyp_per_sample):\n",
    "        class_correct = [gid for gid in partial_correct_gids \n",
    "                        if DO.df_train_hypothesis.iloc[gid]['hyp_class_id'] == class_id]\n",
    "        class_incorrect = [gid for gid in blacklisted_gids \n",
    "                          if DO.df_train_hypothesis.iloc[gid]['hyp_class_id'] == class_id]\n",
    "        \n",
    "        if class_correct:\n",
    "            grads = [analysis[gid]['avg_gradient'] for gid in class_correct \n",
    "                    if gid in analysis and analysis[gid]['avg_gradient'] is not None]\n",
    "            anchor_correct[class_id] = np.mean(grads, axis=0) if grads else None\n",
    "        \n",
    "        if class_incorrect:\n",
    "            grads = [analysis[gid]['avg_gradient'] for gid in class_incorrect \n",
    "                    if gid in analysis and analysis[gid]['avg_gradient'] is not None]\n",
    "            anchor_incorrect[class_id] = np.mean(grads, axis=0) if grads else None\n",
    "    \n",
    "    # Selection with stability\n",
    "    selected_gids = []\n",
    "    selection_correct = 0\n",
    "    class_selections = {c: 0 for c in range(hyp_per_sample)}\n",
    "    class_correct_sel = {c: 0 for c in range(hyp_per_sample)}\n",
    "    \n",
    "    for sample_idx in range(n_samples):\n",
    "        if sample_idx in partial_sample_indices:\n",
    "            continue\n",
    "        \n",
    "        start = sample_idx * hyp_per_sample\n",
    "        best_final_score = -np.inf\n",
    "        best_gid = None\n",
    "        best_class = None\n",
    "        best_is_correct = False\n",
    "        \n",
    "        for hyp_idx in range(hyp_per_sample):\n",
    "            gid = start + hyp_idx\n",
    "            if gid in blacklisted_gids:\n",
    "                continue\n",
    "            if gid not in analysis or analysis[gid]['avg_gradient'] is None:\n",
    "                continue\n",
    "            \n",
    "            gradient = analysis[gid]['avg_gradient']\n",
    "            class_id = DO.df_train_hypothesis.iloc[gid]['hyp_class_id']\n",
    "            is_correct = DO.df_train_hypothesis.iloc[gid]['correct_hypothesis']\n",
    "            \n",
    "            # Compute gradient score\n",
    "            anchor_c = anchor_correct.get(class_id)\n",
    "            anchor_i = anchor_incorrect.get(class_id)\n",
    "            \n",
    "            if anchor_c is None:\n",
    "                grad_score = 0.0\n",
    "            else:\n",
    "                sim_c = np.dot(gradient, anchor_c) / (np.linalg.norm(gradient) * np.linalg.norm(anchor_c) + 1e-8)\n",
    "                if anchor_i is not None:\n",
    "                    sim_i = np.dot(gradient, anchor_i) / (np.linalg.norm(gradient) * np.linalg.norm(anchor_i) + 1e-8)\n",
    "                else:\n",
    "                    sim_i = 0.0\n",
    "                grad_score = sim_c - sim_i\n",
    "            \n",
    "            # Get stability score\n",
    "            stab = stability_metrics.get(gid, {})\n",
    "            stability_score = stab.get('combined_stability', 0.0)\n",
    "            \n",
    "            # Combined score\n",
    "            final_score = grad_score + stability_weight * stability_score\n",
    "            \n",
    "            if final_score > best_final_score:\n",
    "                best_final_score = final_score\n",
    "                best_gid = gid\n",
    "                best_class = class_id\n",
    "                best_is_correct = is_correct\n",
    "        \n",
    "        if best_gid is not None:\n",
    "            selected_gids.append(best_gid)\n",
    "            class_selections[best_class] += 1\n",
    "            if best_is_correct:\n",
    "                selection_correct += 1\n",
    "                class_correct_sel[best_class] += 1\n",
    "    \n",
    "    precision = selection_correct / len(selected_gids) if selected_gids else 0\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"SELECTION WITH STABILITY (weight={stability_weight})\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\nResults:\")\n",
    "        print(f\"  Total selected: {len(selected_gids)}\")\n",
    "        print(f\"  Correct: {selection_correct} ({precision*100:.1f}% precision)\")\n",
    "        print(f\"  Random baseline: {100/hyp_per_sample:.1f}%\")\n",
    "        print(f\"\\n  Per-class breakdown:\")\n",
    "        for c in range(hyp_per_sample):\n",
    "            sel = class_selections[c]\n",
    "            corr = class_correct_sel[c]\n",
    "            prec = corr/sel*100 if sel > 0 else 0\n",
    "            sel_pct = sel / len(selected_gids) * 100 if selected_gids else 0\n",
    "            print(f\"    Class {c}: {sel} selected ({sel_pct:.1f}%), {corr} correct ({prec:.1f}% prec)\")\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'selected_gids': selected_gids,\n",
    "        'class_selections': class_selections,\n",
    "        'stability_metrics': stability_metrics\n",
    "    }\n",
    "\n",
    "# Run the tests\n",
    "if not DO.lack_partial_coverage:\n",
    "    # First, just analyze stability (is there a signal?)\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PART 1: STABILITY ANALYSIS - Is there a signal?\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Test different stability weights\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PART 2: SELECTION WITH STABILITY\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    for weight in [0.0, 0.25, 0.5, 1.0]:\n",
    "        results_stab = selection_with_stability(trainer_amp, DO, stability_weight=weight, verbose=(weight==0.5))\n",
    "        if weight != 0.5:\n",
    "            print(f\"  Stability weight={weight}: {results_stab['precision']*100:.1f}% precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc52ef7e-3324-48ac-b6c8-26926c269965",
   "metadata": {},
   "source": [
    "# PHASE 1.5: Train on Partial Data + Constrained Anchor Selections\n",
    "# Test across 15 random states to validate the approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5nuj3ebui0w",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment functions defined.\n",
      "NEW: top_percentile parameter - only include top N% of selections by score\n"
     ]
    }
   ],
   "source": [
    "# PHASE 1.5: Train on Partial Data + Constrained Anchor Selections\n",
    "# Test across 15 random states to validate the approach\n",
    "\n",
    "def run_hybrid_experiment(rand_state, phase1_epochs=30, phase2_epochs=200, \n",
    "                          use_trajectory=False, partial_weight=2, top_percentile=100,\n",
    "                          verbose=False):\n",
    "    \"\"\"\n",
    "    Run full hybrid pipeline:\n",
    "    1. Phase 1: Unbiased training to get gradients\n",
    "    2. Constrained anchor selection (with blacklist enforcement)\n",
    "    3. Filter to top N% by score (threshold selection)\n",
    "    4. Train final model on partial + selected hypotheses (partial weighted)\n",
    "    5. Evaluate on test set\n",
    "    \n",
    "    Args:\n",
    "        partial_weight: How many times to duplicate partial data (default 2x)\n",
    "        top_percentile: Only include top N% of selections by score (default 100 = all)\n",
    "    \"\"\"\n",
    "    set_to_deterministic(rand_state)\n",
    "    \n",
    "    # Initialize data\n",
    "    DO = DataOperator(data_path, inpt_vars, target_vars, miss_vars, hypothesis,\n",
    "                      partial_perc, rand_state, device='cpu')\n",
    "    DO.problem_type = 'regression'\n",
    "    \n",
    "    if DO.lack_partial_coverage:\n",
    "        return None\n",
    "    \n",
    "    # Phase 1: Train amplified model on all hypotheses\n",
    "    phase1_dataset = Phase1Dataset(DO)\n",
    "    phase1_dataloader = torch.utils.data.DataLoader(\n",
    "        phase1_dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    \n",
    "    input_size = phase1_dataset.inputs.shape[1]\n",
    "    model_p1 = HypothesisAmplifyingModel(\n",
    "        n_shared_features=len(inpt_vars),\n",
    "        n_hypothesis_features=1,\n",
    "        shared_hidden=16, hypothesis_hidden=32, final_hidden=32,\n",
    "        output_size=output_size\n",
    "    )\n",
    "    \n",
    "    trainer = Phase1Trainer(DO, model_p1, lr=lr)\n",
    "    \n",
    "    for epoch in range(phase1_epochs):\n",
    "        track = epoch >= (phase1_epochs - phase1_analysis_epochs)\n",
    "        trainer.train_epoch(phase1_dataloader, epoch, track_data=track)\n",
    "    \n",
    "    # === CRITICAL: Identify partial data samples and blacklisted hypotheses ===\n",
    "    hyp_per_sample = DO.num_hyp_comb\n",
    "    n_samples = len(DO.df_train_hypothesis) // hyp_per_sample\n",
    "    \n",
    "    # Get partial data info\n",
    "    partial_correct_gids = set(DO.df_train_hypothesis[\n",
    "        (DO.df_train_hypothesis['partial_full_info'] == 1) & \n",
    "        (DO.df_train_hypothesis['correct_hypothesis'] == True)\n",
    "    ].index.tolist())\n",
    "    \n",
    "    # BLACKLIST: Known incorrect hypotheses from partial data - NEVER select these\n",
    "    blacklisted_gids = set(DO.df_train_hypothesis[\n",
    "        (DO.df_train_hypothesis['partial_full_info'] == 1) & \n",
    "        (DO.df_train_hypothesis['correct_hypothesis'] == False)\n",
    "    ].index.tolist())\n",
    "    \n",
    "    # Identify which samples are partial (have known correct hypothesis)\n",
    "    partial_sample_indices = set()\n",
    "    for gid in partial_correct_gids:\n",
    "        sample_idx = gid // hyp_per_sample\n",
    "        partial_sample_indices.add(sample_idx)\n",
    "    \n",
    "    # === Constrained anchor selection WITH blacklist enforcement ===\n",
    "    analysis = trainer.get_hypothesis_analysis()\n",
    "    \n",
    "    # Compute anchors from partial data\n",
    "    anchor_correct = {}\n",
    "    anchor_incorrect = {}\n",
    "    \n",
    "    for class_id in range(hyp_per_sample):\n",
    "        class_correct = [gid for gid in partial_correct_gids \n",
    "                        if DO.df_train_hypothesis.iloc[gid]['hyp_class_id'] == class_id]\n",
    "        if class_correct:\n",
    "            grads = [analysis[gid]['avg_gradient'] for gid in class_correct \n",
    "                    if gid in analysis and analysis[gid]['avg_gradient'] is not None]\n",
    "            anchor_correct[class_id] = np.mean(grads, axis=0) if grads else None\n",
    "        else:\n",
    "            anchor_correct[class_id] = None\n",
    "\n",
    "        class_incorrect = [gid for gid in blacklisted_gids \n",
    "                          if DO.df_train_hypothesis.iloc[gid]['hyp_class_id'] == class_id]\n",
    "        if class_incorrect:\n",
    "            grads = [analysis[gid]['avg_gradient'] for gid in class_incorrect \n",
    "                    if gid in analysis and analysis[gid]['avg_gradient'] is not None]\n",
    "            anchor_incorrect[class_id] = np.mean(grads, axis=0) if grads else None\n",
    "        else:\n",
    "            anchor_incorrect[class_id] = None\n",
    "    \n",
    "    # Compute anchor similarity for anchor-aware scoring\n",
    "    anchor_similarity = {}\n",
    "    for class_id in range(hyp_per_sample):\n",
    "        if anchor_correct.get(class_id) is not None and anchor_incorrect.get(class_id) is not None:\n",
    "            anchor_similarity[class_id] = np.dot(anchor_correct[class_id], anchor_incorrect[class_id]) / (\n",
    "                np.linalg.norm(anchor_correct[class_id]) * np.linalg.norm(anchor_incorrect[class_id]) + 1e-8)\n",
    "        else:\n",
    "            anchor_similarity[class_id] = 0\n",
    "\n",
    "    # === Select hypotheses with scores for threshold filtering ===\n",
    "    all_selections = []  # (gid, score, is_correct, sample_idx)\n",
    "    \n",
    "    for sample_idx in range(n_samples):\n",
    "        start = sample_idx * hyp_per_sample\n",
    "        \n",
    "        # For partial samples, use KNOWN correct hypothesis (always include, no scoring)\n",
    "        if sample_idx in partial_sample_indices:\n",
    "            for hyp_idx in range(hyp_per_sample):\n",
    "                gid = start + hyp_idx\n",
    "                if gid in partial_correct_gids:\n",
    "                    # Give partial data a very high score so they're always included\n",
    "                    all_selections.append((gid, float('inf'), True, sample_idx, True))  # is_partial=True\n",
    "                    break\n",
    "            continue\n",
    "        \n",
    "        # For non-partial samples, use gradient-based selection\n",
    "        best_score = -np.inf\n",
    "        best_gid = None\n",
    "        best_is_correct = False\n",
    "        \n",
    "        for hyp_idx in range(hyp_per_sample):\n",
    "            gid = start + hyp_idx\n",
    "            \n",
    "            if gid in blacklisted_gids:\n",
    "                continue\n",
    "                \n",
    "            if gid not in analysis or analysis[gid]['avg_gradient'] is None:\n",
    "                continue\n",
    "\n",
    "            gradient = analysis[gid]['avg_gradient']\n",
    "            class_id = DO.df_train_hypothesis.iloc[gid]['hyp_class_id']\n",
    "\n",
    "            score = 0\n",
    "            if anchor_correct.get(class_id) is not None:\n",
    "                sim_correct = np.dot(gradient, anchor_correct[class_id]) / (\n",
    "                    np.linalg.norm(gradient) * np.linalg.norm(anchor_correct[class_id]) + 1e-8)\n",
    "                score += sim_correct\n",
    "\n",
    "            if anchor_incorrect.get(class_id) is not None:\n",
    "                sim_incorrect = np.dot(gradient, anchor_incorrect[class_id]) / (\n",
    "                    np.linalg.norm(gradient) * np.linalg.norm(anchor_incorrect[class_id]) + 1e-8)\n",
    "\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_gid = gid\n",
    "                best_is_correct = DO.df_train_hypothesis.iloc[gid]['correct_hypothesis']\n",
    "\n",
    "        if best_gid is not None:\n",
    "            all_selections.append((best_gid, best_score, best_is_correct, sample_idx, False))  # is_partial=False\n",
    "    \n",
    "    # === Apply threshold: keep only top N% by score (partial always included) ===\n",
    "    partial_selections = [s for s in all_selections if s[4]]  # is_partial=True\n",
    "    non_partial_selections = [s for s in all_selections if not s[4]]\n",
    "    \n",
    "    # Sort non-partial by score (descending) and take top N%\n",
    "    non_partial_selections.sort(key=lambda x: x[1], reverse=True)\n",
    "    n_keep = max(1, int(len(non_partial_selections) * top_percentile / 100))\n",
    "    top_selections = non_partial_selections[:n_keep]\n",
    "    \n",
    "    # Combine: all partial + top N% of non-partial\n",
    "    final_selections = partial_selections + top_selections\n",
    "    \n",
    "    # Calculate precision on the selected non-partial samples\n",
    "    n_correct_selected = sum(1 for s in top_selections if s[2])\n",
    "    selection_precision = n_correct_selected / len(top_selections) if top_selections else 0\n",
    "    \n",
    "    # === Build training set with partial data weighting ===\n",
    "    input_cols = DO.inpt_vars + [f'{DO.miss_vars[0]}_hypothesis']\n",
    "    \n",
    "    partial_gids = [s[0] for s in partial_selections]\n",
    "    selected_gids = [s[0] for s in top_selections]\n",
    "    \n",
    "    # Weight partial data by duplicating it\n",
    "    weighted_gids = partial_gids * partial_weight + selected_gids\n",
    "    \n",
    "    train_inputs = torch.tensor(\n",
    "        DO.df_train_hypothesis.iloc[weighted_gids][input_cols].values,\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "    train_targets = torch.tensor(\n",
    "        DO.df_train_hypothesis.iloc[weighted_gids][DO.target_vars].values,\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Seed {rand_state}: {len(partial_gids)} partial x{partial_weight} + \"\n",
    "              f\"{len(selected_gids)} selected (top {top_percentile}%), \"\n",
    "              f\"precision={selection_precision*100:.1f}%\")\n",
    "    \n",
    "    # Phase 2: Train final model on selected data\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_inputs, train_targets)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=min(64, len(train_inputs)), shuffle=True)\n",
    "    \n",
    "    model_final = StandardModel(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n",
    "    optimizer = torch.optim.Adam(model_final.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_state = None\n",
    "    \n",
    "    val_inputs = torch.tensor(DO.full_val_input, dtype=torch.float32)\n",
    "    val_targets = DO.val_outcomes_tensor\n",
    "    \n",
    "    for epoch in range(phase2_epochs):\n",
    "        model_final.train()\n",
    "        for batch_inputs, batch_targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model_final(batch_inputs)\n",
    "            loss = criterion(pred, batch_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model_final.eval()\n",
    "        with torch.no_grad():\n",
    "            val_pred = model_final(val_inputs)\n",
    "            val_loss = criterion(val_pred, val_targets).item()\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_state = model_final.state_dict().copy()\n",
    "    \n",
    "    model_final.load_state_dict(best_state)\n",
    "    model_final.eval()\n",
    "    \n",
    "    test_inputs = DO.full_test_input_tensor\n",
    "    test_targets = DO.df_test[target_vars].values\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_pred = model_final(test_inputs).numpy()\n",
    "    \n",
    "    r2_hybrid = r2_score(test_targets, test_pred)\n",
    "    \n",
    "    return {\n",
    "        'rand_state': rand_state,\n",
    "        'selection_precision': selection_precision,\n",
    "        'n_training_samples': len(weighted_gids),\n",
    "        'n_partial': len(partial_gids),\n",
    "        'n_selected': len(selected_gids),\n",
    "        'top_percentile': top_percentile,\n",
    "        'r2': r2_hybrid\n",
    "    }\n",
    "\n",
    "\n",
    "def run_baseline_experiment(rand_state, use_info, num_epochs=200, baseline_lr=0.002, baseline_dropout=0.1):\n",
    "    \"\"\"\n",
    "    Run baseline experiment for comparison.\n",
    "    \n",
    "    NOTE: Uses Wine.ipynb parameters:\n",
    "    - 200 epochs (4x amplification for small datasets)\n",
    "    - lr=0.002\n",
    "    - dropout=0.1\n",
    "    \"\"\"\n",
    "    set_to_deterministic(rand_state)\n",
    "    \n",
    "    DO = DataOperator(data_path, inpt_vars, target_vars, miss_vars, hypothesis,\n",
    "                      partial_perc, rand_state, device='cpu')\n",
    "    DO.problem_type = 'regression'\n",
    "    \n",
    "    if DO.lack_partial_coverage:\n",
    "        return None\n",
    "    \n",
    "    AM = AlgoModulators(DO, lr=baseline_lr, nu=0.1, normalize_grads_contx=False,\n",
    "                       use_context=True, freqperc_cutoff=0.25)\n",
    "    \n",
    "    dataloader = DO.prep_dataloader(use_info, batch_size)\n",
    "    model = initialize_model(DO, dataloader, hidden_size, rand_state, dropout=baseline_dropout)\n",
    "    \n",
    "    TVM = TrainValidationManager(use_info, num_epochs, dataloader, batch_size,\n",
    "                                 rand_state, results_path, final_analysis=False)\n",
    "    TVM.train_model(DO, AM, model, final_analysis=False)\n",
    "    \n",
    "    model.load_state_dict(torch.load(TVM.weights_save_path))\n",
    "    model.eval()\n",
    "    \n",
    "    if use_info in ['use hypothesis', 'partial info', 'full info']:\n",
    "        test_pred = model(DO.full_test_input_tensor)\n",
    "    else:\n",
    "        test_pred = model(DO.known_test_input_tensor)\n",
    "    \n",
    "    test_true = DO.df_test[target_vars].values\n",
    "    r2 = r2_score(test_true, test_pred.detach().numpy())\n",
    "    \n",
    "    return {'rand_state': rand_state, 'r2': r2}\n",
    "\n",
    "\n",
    "print(\"Experiment functions defined.\")\n",
    "print(\"NEW: top_percentile parameter - only include top N% of selections by score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "wid65jxmqu7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXPERIMENT: Optimal Training vs Analysis Epochs\n",
      "======================================================================\n",
      "Fixed: top_percentile=5, partial_weight=3, 15 random states\n",
      "Phase 2: 200 epochs with early stopping\n",
      "\n",
      "Using random states: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Config: 60 training epochs, last 1 for analysis\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(60,1): 100%|██████████| 15/15 [01:01<00:00,  4.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  R2: 0.1969 +/- 0.0890\n",
      "  Selection Precision: 47.1%\n",
      "\n",
      "======================================================================\n",
      "Config: 60 training epochs, last 3 for analysis\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(60,3): 100%|██████████| 15/15 [01:31<00:00,  6.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  R2: 0.1993 +/- 0.0909\n",
      "  Selection Precision: 47.2%\n",
      "\n",
      "======================================================================\n",
      "Config: 60 training epochs, last 5 for analysis\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(60,5): 100%|██████████| 15/15 [02:01<00:00,  8.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  R2: 0.1979 +/- 0.0916\n",
      "  Selection Precision: 47.2%\n",
      "\n",
      "======================================================================\n",
      "Config: 200 training epochs, last 5 for analysis\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(200,5): 100%|██████████| 15/15 [03:15<00:00, 13.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  R2: 0.1932 +/- 0.0838\n",
      "  Selection Precision: 46.8%\n",
      "\n",
      "======================================================================\n",
      "SUMMARY: All Configurations\n",
      "======================================================================\n",
      "\n",
      "Config (epochs, analysis)      Mean R2      Std        Precision\n",
      "----------------------------------------------------------------------\n",
      "(60,  3)                           0.1993     0.0909     47.2%  ★ BEST\n",
      "(60,  5)                           0.1979     0.0916     47.2%  \n",
      "(60,  1)                           0.1969     0.0890     47.1%  \n",
      "(200,  5)                           0.1932     0.0838     46.8%  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# EXPERIMENT: Optimal Training Epochs vs Analysis Epochs\n",
    "# =============================================================================\n",
    "# Question: Which gradient configuration produces best separation?\n",
    "# - Model trained for 15, 30, or 60 epochs\n",
    "# - Looking at last 5, 10, or 20 gradients for averaging\n",
    "#\n",
    "# Fixed parameters: top_percentile=5, partial_weight=3, 15 random states\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_hybrid_experiment_configurable(rand_state, phase1_epochs, phase1_analysis_epochs,\n",
    "                                        phase2_epochs=200, partial_weight=3, top_percentile=5,\n",
    "                                        verbose=False):\n",
    "    \"\"\"\n",
    "    Run hybrid experiment with configurable phase1 training and analysis epochs.\n",
    "    Matches the original run_hybrid_experiment implementation.\n",
    "    \"\"\"\n",
    "    set_to_deterministic(rand_state)\n",
    "    \n",
    "    # Initialize data\n",
    "    DO = DataOperator(data_path, inpt_vars, target_vars, miss_vars, hypothesis,\n",
    "                      partial_perc, rand_state, device='cpu')\n",
    "    DO.problem_type = 'regression'\n",
    "    \n",
    "    if DO.lack_partial_coverage:\n",
    "        return None\n",
    "    \n",
    "    # Phase 1: Train amplified model\n",
    "    phase1_dataset = Phase1Dataset(DO)\n",
    "    phase1_dataloader = torch.utils.data.DataLoader(\n",
    "        phase1_dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    \n",
    "    input_size = phase1_dataset.inputs.shape[1]\n",
    "    model_p1 = HypothesisAmplifyingModel(\n",
    "        n_shared_features=len(inpt_vars),\n",
    "        n_hypothesis_features=1,\n",
    "        shared_hidden=16, hypothesis_hidden=32, final_hidden=32,\n",
    "        output_size=output_size\n",
    "    )\n",
    "    \n",
    "    trainer = Phase1Trainer(DO, model_p1, lr=lr)\n",
    "    \n",
    "    for epoch in range(phase1_epochs):\n",
    "        track = epoch >= (phase1_epochs - phase1_analysis_epochs)\n",
    "        trainer.train_epoch(phase1_dataloader, epoch, track_data=track)\n",
    "    \n",
    "    # Constrained anchor selection\n",
    "    hyp_per_sample = DO.num_hyp_comb\n",
    "    n_samples = len(DO.df_train_hypothesis) // hyp_per_sample\n",
    "    \n",
    "    partial_correct_gids = set(DO.df_train_hypothesis[\n",
    "        (DO.df_train_hypothesis['partial_full_info'] == 1) & \n",
    "        (DO.df_train_hypothesis['correct_hypothesis'] == True)\n",
    "    ].index.tolist())\n",
    "    \n",
    "    blacklisted_gids = set(DO.df_train_hypothesis[\n",
    "        (DO.df_train_hypothesis['partial_full_info'] == 1) & \n",
    "        (DO.df_train_hypothesis['correct_hypothesis'] == False)\n",
    "    ].index.tolist())\n",
    "    \n",
    "    partial_sample_indices = set(gid // hyp_per_sample for gid in partial_correct_gids)\n",
    "    \n",
    "    analysis = trainer.get_hypothesis_analysis()\n",
    "    \n",
    "    # Compute anchors\n",
    "    anchor_correct = {}\n",
    "    anchor_incorrect = {}\n",
    "    \n",
    "    for class_id in range(hyp_per_sample):\n",
    "        class_correct = [gid for gid in partial_correct_gids \n",
    "                        if DO.df_train_hypothesis.iloc[gid]['hyp_class_id'] == class_id]\n",
    "        if class_correct:\n",
    "            grads = [analysis[gid]['avg_gradient'] for gid in class_correct \n",
    "                    if gid in analysis and analysis[gid]['avg_gradient'] is not None]\n",
    "            anchor_correct[class_id] = np.mean(grads, axis=0) if grads else None\n",
    "        else:\n",
    "            anchor_correct[class_id] = None\n",
    "\n",
    "        class_incorrect = [gid for gid in blacklisted_gids \n",
    "                          if DO.df_train_hypothesis.iloc[gid]['hyp_class_id'] == class_id]\n",
    "        if class_incorrect:\n",
    "            grads = [analysis[gid]['avg_gradient'] for gid in class_incorrect \n",
    "                    if gid in analysis and analysis[gid]['avg_gradient'] is not None]\n",
    "            anchor_incorrect[class_id] = np.mean(grads, axis=0) if grads else None\n",
    "        else:\n",
    "            anchor_incorrect[class_id] = None\n",
    "    \n",
    "    # Score and select\n",
    "    all_selections = []\n",
    "    \n",
    "    for sample_idx in range(n_samples):\n",
    "        if sample_idx in partial_sample_indices:\n",
    "            for hyp_idx in range(hyp_per_sample):\n",
    "                gid = sample_idx * hyp_per_sample + hyp_idx\n",
    "                if gid in partial_correct_gids:\n",
    "                    all_selections.append((gid, float('inf'), True, sample_idx, True))\n",
    "                    break\n",
    "            continue\n",
    "        \n",
    "        start = sample_idx * hyp_per_sample\n",
    "        best_score = -np.inf\n",
    "        best_gid = None\n",
    "        best_is_correct = False\n",
    "        \n",
    "        for hyp_idx in range(hyp_per_sample):\n",
    "            gid = start + hyp_idx\n",
    "            if gid in blacklisted_gids:\n",
    "                continue\n",
    "            if gid not in analysis or analysis[gid]['avg_gradient'] is None:\n",
    "                continue\n",
    "            \n",
    "            gradient = analysis[gid]['avg_gradient']\n",
    "            class_id = DO.df_train_hypothesis.iloc[gid]['hyp_class_id']\n",
    "            \n",
    "            anchor_c = anchor_correct.get(class_id)\n",
    "            anchor_i = anchor_incorrect.get(class_id)\n",
    "            \n",
    "            if anchor_c is None:\n",
    "                score = 0.0\n",
    "            else:\n",
    "                sim_c = np.dot(gradient, anchor_c) / (np.linalg.norm(gradient) * np.linalg.norm(anchor_c) + 1e-8)\n",
    "                if anchor_i is not None:\n",
    "                    sim_i = np.dot(gradient, anchor_i) / (np.linalg.norm(gradient) * np.linalg.norm(anchor_i) + 1e-8)\n",
    "                else:\n",
    "                    sim_i = 0.0\n",
    "                score = sim_c - sim_i\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_gid = gid\n",
    "                best_is_correct = DO.df_train_hypothesis.iloc[gid]['correct_hypothesis']\n",
    "        \n",
    "        if best_gid is not None:\n",
    "            all_selections.append((best_gid, best_score, best_is_correct, sample_idx, False))\n",
    "    \n",
    "    # Compute selection precision\n",
    "    non_partial = [s for s in all_selections if not s[4]]\n",
    "    selection_correct = sum(1 for s in non_partial if s[2])\n",
    "    selection_precision = selection_correct / len(non_partial) if non_partial else 0\n",
    "    \n",
    "    # Apply top percentile filter\n",
    "    non_partial_sorted = sorted(non_partial, key=lambda x: x[1], reverse=True)\n",
    "    n_keep = max(1, int(len(non_partial_sorted) * top_percentile / 100))\n",
    "    top_selections = non_partial_sorted[:n_keep]\n",
    "    \n",
    "    # Build training set - INCLUDE HYPOTHESIS VALUE (like original)\n",
    "    input_cols = DO.inpt_vars + [f'{DO.miss_vars[0]}_hypothesis']\n",
    "    input_size_p2 = len(input_cols)\n",
    "    \n",
    "    partial_gids = [s[0] for s in all_selections if s[4]]\n",
    "    selected_gids = [s[0] for s in top_selections]\n",
    "    \n",
    "    # Weight partial data by duplicating\n",
    "    weighted_gids = partial_gids * partial_weight + selected_gids\n",
    "    \n",
    "    train_inputs = torch.tensor(\n",
    "        DO.df_train_hypothesis.iloc[weighted_gids][input_cols].values,\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "    train_targets = torch.tensor(\n",
    "        DO.df_train_hypothesis.iloc[weighted_gids][target_vars].values,\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "    \n",
    "    train_dataset = torch.utils.data.TensorDataset(train_inputs, train_targets)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=min(64, len(train_inputs)), shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Use StandardModel with early stopping (like original)\n",
    "    model_final = StandardModel(input_size=input_size_p2, hidden_size=hidden_size, output_size=output_size)\n",
    "    optimizer = torch.optim.Adam(model_final.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_state = None\n",
    "    \n",
    "    val_inputs = torch.tensor(DO.full_val_input, dtype=torch.float32)\n",
    "    val_targets = DO.val_outcomes_tensor\n",
    "    \n",
    "    for epoch in range(phase2_epochs):\n",
    "        model_final.train()\n",
    "        for batch_inputs, batch_targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model_final(batch_inputs)\n",
    "            loss = criterion(pred, batch_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model_final.eval()\n",
    "        with torch.no_grad():\n",
    "            val_pred = model_final(val_inputs)\n",
    "            val_loss = criterion(val_pred, val_targets).item()\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_state = model_final.state_dict().copy()\n",
    "    \n",
    "    model_final.load_state_dict(best_state)\n",
    "    model_final.eval()\n",
    "    \n",
    "    # Evaluate using full_test_input_tensor (includes hypothesis)\n",
    "    test_inputs = DO.full_test_input_tensor\n",
    "    test_targets = DO.df_test[target_vars].values\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_pred = model_final(test_inputs).numpy()\n",
    "    \n",
    "    r2 = r2_score(test_targets, test_pred)\n",
    "    \n",
    "    return {\n",
    "        'rand_state': rand_state,\n",
    "        'r2': r2,\n",
    "        'selection_precision': selection_precision\n",
    "    }\n",
    "\n",
    "\n",
    "# Define parameter configurations to test\n",
    "configs = [\n",
    "    (60, 1),   # 60 epochs, last 5 gradients\n",
    "    (60, 3),   # 60 epochs, last 5 gradients\n",
    "    (60, 5),   # 60 epochs, last 5 gradients\n",
    "    (200, 5),  # 60 epochs, last 20 gradients\n",
    "]\n",
    "\n",
    "# Run experiments\n",
    "print(\"=\"*70)\n",
    "print(\"EXPERIMENT: Optimal Training vs Analysis Epochs\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Fixed: top_percentile=5, partial_weight=3, 15 random states\")\n",
    "print(f\"Phase 2: 200 epochs with early stopping\")\n",
    "print()\n",
    "\n",
    "# Find valid seeds first\n",
    "valid_seeds = []\n",
    "for rs in range(100):\n",
    "    set_to_deterministic(rs)\n",
    "    DO_test = DataOperator(data_path, inpt_vars, target_vars, miss_vars, hypothesis,\n",
    "                           partial_perc, rs, device='cpu')\n",
    "    if not DO_test.lack_partial_coverage:\n",
    "        valid_seeds.append(rs)\n",
    "    if len(valid_seeds) >= 15:\n",
    "        break\n",
    "\n",
    "print(f\"Using random states: {valid_seeds}\")\n",
    "print()\n",
    "\n",
    "results_by_config = {}\n",
    "\n",
    "for p1_epochs, p1_analysis in configs:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Config: {p1_epochs} training epochs, last {p1_analysis} for analysis\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    r2_scores = []\n",
    "    precisions = []\n",
    "    \n",
    "    for i, rs in enumerate(tqdm(valid_seeds, desc=f\"({p1_epochs},{p1_analysis})\")):\n",
    "        result = run_hybrid_experiment_configurable(\n",
    "            rs, \n",
    "            phase1_epochs=p1_epochs,\n",
    "            phase1_analysis_epochs=p1_analysis,\n",
    "            phase2_epochs=200,\n",
    "            partial_weight=3,\n",
    "            top_percentile=5,\n",
    "            verbose=False\n",
    "        )\n",
    "        if result:\n",
    "            r2_scores.append(result['r2'])\n",
    "            precisions.append(result['selection_precision'])\n",
    "    \n",
    "    mean_r2 = np.mean(r2_scores)\n",
    "    std_r2 = np.std(r2_scores)\n",
    "    mean_prec = np.mean(precisions)\n",
    "    \n",
    "    results_by_config[(p1_epochs, p1_analysis)] = {\n",
    "        'mean_r2': mean_r2,\n",
    "        'std_r2': std_r2,\n",
    "        'mean_precision': mean_prec,\n",
    "        'r2_scores': r2_scores\n",
    "    }\n",
    "    \n",
    "    print(f\"  R2: {mean_r2:.4f} +/- {std_r2:.4f}\")\n",
    "    print(f\"  Selection Precision: {mean_prec*100:.1f}%\")\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY: All Configurations\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'Config (epochs, analysis)':<30} {'Mean R2':<12} {'Std':<10} {'Precision'}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Sort by mean R2\n",
    "sorted_configs = sorted(results_by_config.items(), key=lambda x: x[1]['mean_r2'], reverse=True)\n",
    "\n",
    "for (epochs, analysis), res in sorted_configs:\n",
    "    marker = \"★ BEST\" if (epochs, analysis) == sorted_configs[0][0] else \"\"\n",
    "    print(f\"({epochs:>2}, {analysis:>2})                         {res['mean_r2']:>8.4f}     {res['std_r2']:>6.4f}    {res['mean_precision']*100:>5.1f}%  {marker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aam8rivkjrb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RUNNING 15 EXPERIMENTS\n",
      "======================================================================\n",
      "Hybrid: Top 5% selections only, partial weight=4x\n",
      "Baselines: 200 epochs, lr=0.002, dropout=0.1 (matching Wine.ipynb)\n",
      "\n",
      "Found 15 valid seeds: [0, 1, 2, 3, 4]... \n",
      "\n",
      "[1/15] Seed 0... R2=0.1787, Prec=14.3%, Train=28x4+56\n",
      "[2/15] Seed 1... R2=0.3322, Prec=46.4%, Train=28x4+56\n",
      "[3/15] Seed 2... R2=0.2105, Prec=51.8%, Train=28x4+56\n",
      "[4/15] Seed 3... R2=0.2051, Prec=50.0%, Train=28x4+56\n",
      "[5/15] Seed 4... R2=0.2009, Prec=46.4%, Train=28x4+56\n",
      "[6/15] Seed 5... R2=0.2177, Prec=44.6%, Train=28x4+56\n",
      "[7/15] Seed 6... R2=0.2417, Prec=64.3%, Train=28x4+56\n",
      "[8/15] Seed 7... R2=0.3172, Prec=33.9%, Train=28x4+56\n",
      "[9/15] Seed 8... R2=0.2398, Prec=55.4%, Train=28x4+56\n",
      "[10/15] Seed 9... R2=0.3230, Prec=37.5%, Train=28x4+56\n",
      "[11/15] Seed 10... R2=-0.2340, Prec=50.0%, Train=28x4+56\n",
      "[12/15] Seed 11... R2=0.0491, Prec=21.4%, Train=28x4+56\n",
      "[13/15] Seed 12... R2=0.1269, Prec=50.0%, Train=28x4+56\n",
      "[14/15] Seed 13... R2=-0.1730, Prec=55.4%, Train=28x4+56\n",
      "[15/15] Seed 14... R2=0.1776, Prec=35.7%, Train=28x4+56\n",
      "\n",
      "======================================================================\n",
      "EXPERIMENTS COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# RUN 15 RANDOM STATE EXPERIMENTS\n",
    "# Compare: Hybrid (Top 10% + Partial x2) vs Partial Info vs Use Known Only\n",
    "# NEW: Only use top 10% highest-scoring selections (58.9% precision vs 42.8% overall)\n",
    "\n",
    "n_experiments = 15\n",
    "partial_weight = 3      # Duplicate partial data 2x\n",
    "top_percentile = 5     # Only use top 10% of selections by score\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"RUNNING {n_experiments} EXPERIMENTS\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Hybrid: Top {top_percentile}% selections only, partial weight={partial_weight}x\")\n",
    "print(f\"Baselines: 200 epochs, lr=0.002, dropout=0.1 (matching Wine.ipynb)\")\n",
    "print()\n",
    "\n",
    "# Collect results\n",
    "hybrid_results = []\n",
    "partial_info_results = []\n",
    "use_known_results = []\n",
    "\n",
    "valid_seeds = []\n",
    "seed = 0\n",
    "\n",
    "# Find valid seeds (those with partial coverage)\n",
    "while len(valid_seeds) < n_experiments and seed < 500:\n",
    "    set_to_deterministic(seed)\n",
    "    DO_test = DataOperator(data_path, inpt_vars, target_vars, miss_vars, hypothesis,\n",
    "                           partial_perc, seed, device='cpu')\n",
    "    if not DO_test.lack_partial_coverage:\n",
    "        valid_seeds.append(seed)\n",
    "    seed += 1\n",
    "\n",
    "print(f\"Found {len(valid_seeds)} valid seeds: {valid_seeds[:5]}... \\n\")\n",
    "\n",
    "# Run experiments\n",
    "for i, rs in enumerate(valid_seeds):\n",
    "    print(f\"[{i+1}/{n_experiments}] Seed {rs}...\", end=\" \")\n",
    "    \n",
    "    # Hybrid approach with top 10% threshold + partial weighting\n",
    "    hybrid_res = run_hybrid_experiment(rs, phase1_epochs=30, phase2_epochs=200, \n",
    "                                        use_trajectory=False, \n",
    "                                        partial_weight=partial_weight,\n",
    "                                        top_percentile=top_percentile,\n",
    "                                        verbose=False)\n",
    "    if hybrid_res:\n",
    "        hybrid_results.append(hybrid_res)\n",
    "    \n",
    "    # Baselines with Wine.ipynb parameters (200 epochs, lr=0.002, dropout=0.1)\n",
    "    partial_res = run_baseline_experiment(rs, 'partial info', num_epochs=200, \n",
    "                                          baseline_lr=0.002, baseline_dropout=0.1)\n",
    "    if partial_res:\n",
    "        partial_info_results.append(partial_res)\n",
    "    \n",
    "    known_res = run_baseline_experiment(rs, 'use known only', num_epochs=200,\n",
    "                                        baseline_lr=0.002, baseline_dropout=0.1)\n",
    "    if known_res:\n",
    "        use_known_results.append(known_res)\n",
    "    \n",
    "    if hybrid_res:\n",
    "        print(f\"R2={hybrid_res['r2']:.4f}, Prec={hybrid_res['selection_precision']*100:.1f}%, \"\n",
    "              f\"Train={hybrid_res['n_partial']}x{partial_weight}+{hybrid_res['n_selected']}\")\n",
    "    else:\n",
    "        print(\"SKIPPED (no partial coverage)\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"EXPERIMENTS COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "xudv0u4q20o",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RESULTS SUMMARY (15 Random States)\n",
      "======================================================================\n",
      "\n",
      "Method                              Mean R2      Std        N\n",
      "----------------------------------------------------------------------\n",
      "Hybrid (Phase1 + Constrained Anchor) 0.1609       0.1599     15\n",
      "Partial Info                        0.2300       0.0612     15\n",
      "Use Known Only                      0.1922       0.0514     15\n",
      "\n",
      "======================================================================\n",
      "COMPARISON TO BEST BASELINE\n",
      "======================================================================\n",
      "\n",
      "Best baseline: Partial Info (R2 = 0.2300)\n",
      "\n",
      "Hybrid improvement over best baseline: -6.91 percentage points\n",
      "\n",
      "======================================================================\n",
      "SELECTION PRECISION\n",
      "======================================================================\n",
      "\n",
      "Mean selection precision: 43.8% +/- 12.8%\n",
      "Random baseline: 33.3%\n",
      "Improvement over random: +10.5 percentage points\n",
      "\n",
      "======================================================================\n",
      "PER-SEED COMPARISON (Hybrid vs Best Baseline)\n",
      "======================================================================\n",
      "Seed   0: Hybrid=0.1787, Best baseline=0.2008, Diff=-2.21pp \n",
      "Seed   1: Hybrid=0.3322, Best baseline=0.2683, Diff=+6.39pp ✓\n",
      "Seed   2: Hybrid=0.2105, Best baseline=0.2714, Diff=-6.09pp \n",
      "Seed   3: Hybrid=0.2051, Best baseline=0.2686, Diff=-6.35pp \n",
      "Seed   4: Hybrid=0.2009, Best baseline=0.1963, Diff=+0.47pp ✓\n",
      "Seed   5: Hybrid=0.2177, Best baseline=0.2426, Diff=-2.50pp \n",
      "Seed   6: Hybrid=0.2417, Best baseline=0.2267, Diff=+1.50pp ✓\n",
      "Seed   7: Hybrid=0.3172, Best baseline=0.3030, Diff=+1.41pp ✓\n",
      "Seed   8: Hybrid=0.2398, Best baseline=0.2977, Diff=-5.78pp \n",
      "Seed   9: Hybrid=0.3230, Best baseline=0.3246, Diff=-0.16pp \n",
      "Seed  10: Hybrid=-0.2340, Best baseline=0.1318, Diff=-36.58pp \n",
      "Seed  11: Hybrid=0.0491, Best baseline=0.2327, Diff=-18.37pp \n",
      "Seed  12: Hybrid=0.1269, Best baseline=0.2168, Diff=-8.99pp \n",
      "Seed  13: Hybrid=-0.1730, Best baseline=0.1794, Diff=-35.24pp \n",
      "Seed  14: Hybrid=0.1776, Best baseline=0.2008, Diff=-2.32pp \n",
      "\n",
      "Hybrid wins: 4/15 (27%)\n"
     ]
    }
   ],
   "source": [
    "# RESULTS SUMMARY\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"RESULTS SUMMARY (15 Random States)\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Compute statistics\n",
    "def compute_stats(results, key='r2'):\n",
    "    values = [r[key] for r in results if r is not None]\n",
    "    return np.mean(values), np.std(values), values\n",
    "\n",
    "hybrid_mean, hybrid_std, hybrid_vals = compute_stats(hybrid_results)\n",
    "partial_mean, partial_std, partial_vals = compute_stats(partial_info_results)\n",
    "known_mean, known_std, known_vals = compute_stats(use_known_results)\n",
    "\n",
    "# Selection precision stats\n",
    "sel_prec_mean, sel_prec_std, _ = compute_stats(hybrid_results, key='selection_precision')\n",
    "\n",
    "# Dynamic random baseline based on number of hypothesis classes\n",
    "random_baseline = 1.0 / hyp_per_sample\n",
    "random_baseline_pct = random_baseline * 100\n",
    "\n",
    "print(f\"{'Method':<35} {'Mean R2':<12} {'Std':<10} {'N'}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Hybrid (Phase1 + Constrained Anchor)':<35} {hybrid_mean:.4f}       {hybrid_std:.4f}     {len(hybrid_vals)}\")\n",
    "print(f\"{'Partial Info':<35} {partial_mean:.4f}       {partial_std:.4f}     {len(partial_vals)}\")\n",
    "print(f\"{'Use Known Only':<35} {known_mean:.4f}       {known_std:.4f}     {len(known_vals)}\")\n",
    "\n",
    "# Best baseline\n",
    "best_baseline_mean = max(partial_mean, known_mean)\n",
    "best_baseline_name = \"Partial Info\" if partial_mean > known_mean else \"Use Known Only\"\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"COMPARISON TO BEST BASELINE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nBest baseline: {best_baseline_name} (R2 = {best_baseline_mean:.4f})\")\n",
    "print(f\"\\nHybrid improvement over best baseline: {(hybrid_mean - best_baseline_mean)*100:+.2f} percentage points\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SELECTION PRECISION\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nMean selection precision: {sel_prec_mean*100:.1f}% +/- {sel_prec_std*100:.1f}%\")\n",
    "print(f\"Random baseline: {random_baseline_pct:.1f}%\")\n",
    "print(f\"Improvement over random: {(sel_prec_mean - random_baseline)*100:+.1f} percentage points\")\n",
    "\n",
    "# Per-seed comparison\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PER-SEED COMPARISON (Hybrid vs Best Baseline)\")\n",
    "print(f\"{'='*70}\")\n",
    "hybrid_wins = 0\n",
    "for i, (h, p, k) in enumerate(zip(hybrid_vals, partial_vals, known_vals)):\n",
    "    best_base = max(p, k)\n",
    "    diff = (h - best_base) * 100\n",
    "    win = \"✓\" if h > best_base else \"\"\n",
    "    if h > best_base:\n",
    "        hybrid_wins += 1\n",
    "    print(f\"Seed {valid_seeds[i]:>3}: Hybrid={h:.4f}, Best baseline={best_base:.4f}, Diff={diff:+.2f}pp {win}\")\n",
    "\n",
    "print(f\"\\nHybrid wins: {hybrid_wins}/{len(hybrid_vals)} ({hybrid_wins/len(hybrid_vals)*100:.0f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29402689-e457-4e00-8665-54d718a25768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d8c077-a8ae-4636-8af7-d2f4a949b199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "phase2_header",
   "metadata": {},
   "source": [
    "## Phase 2: GGH with Phase 1 Insights\n",
    "\n",
    "Use the clean signal from Phase 1 to inform GGH selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phase2_ggh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run standard GGH for comparison (Phase 2)\n",
    "if not DO.lack_partial_coverage:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PHASE 2: Standard GGH Training\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Re-initialize for fair comparison\n",
    "    set_to_deterministic(rand_state)\n",
    "    \n",
    "    DO2 = DataOperator(data_path, inpt_vars, target_vars, miss_vars, hypothesis,\n",
    "                       partial_perc, rand_state, device='cpu')\n",
    "    DO2.problem_type = 'regression'\n",
    "    \n",
    "    AM = AlgoModulators(DO2, lr=lr, nu=0.1, normalize_grads_contx=False,\n",
    "                       use_context=True, freqperc_cutoff=0.25)\n",
    "    \n",
    "    dataloader = DO2.prep_dataloader('use hypothesis', batch_size)\n",
    "    model_phase2 = initialize_model(DO2, dataloader, hidden_size, rand_state, dropout=0.05)\n",
    "    \n",
    "    TVM = TrainValidationManager('use hypothesis', phase2_epochs, dataloader, batch_size,\n",
    "                                 rand_state, results_path, final_analysis=True)\n",
    "    TVM.train_model(DO2, AM, model_phase2, final_analysis=True)\n",
    "    \n",
    "    # Evaluate\n",
    "    model_phase2.load_state_dict(torch.load(TVM.weights_save_path))\n",
    "    model_phase2.eval()\n",
    "    \n",
    "    test_pred = model_phase2(DO2.full_test_input_tensor)\n",
    "    test_true = DO2.df_test[target_vars].values\n",
    "    r2_phase2 = r2_score(test_true, test_pred.detach().numpy())\n",
    "    \n",
    "    print(f\"\\nPhase 2 (GGH) Test R2: {r2_phase2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selection_histogram_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize selection histograms from Phase 2 GGH\n",
    "if not DO.lack_partial_coverage:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SELECTION HISTOGRAMS (Phase 2 GGH)\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    selection_histograms(DO2, TVM, phase2_epochs, rand_state, partial_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baselines",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run baselines for comparison\n",
    "if not DO.lack_partial_coverage:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"BASELINE COMPARISONS\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    results_summary = {'Phase 2 (GGH)': r2_phase2}\n",
    "    \n",
    "    for use_info in ['partial info', 'use known only']:\n",
    "        set_to_deterministic(rand_state)\n",
    "        \n",
    "        DO_baseline = DataOperator(data_path, inpt_vars, target_vars, miss_vars, hypothesis,\n",
    "                                   partial_perc, rand_state, device='cpu')\n",
    "        DO_baseline.problem_type = 'regression'\n",
    "        \n",
    "        AM_baseline = AlgoModulators(DO_baseline, lr=lr, nu=0.1)\n",
    "        dataloader_baseline = DO_baseline.prep_dataloader(use_info, batch_size)\n",
    "        model_baseline = initialize_model(DO_baseline, dataloader_baseline, hidden_size, rand_state)\n",
    "        \n",
    "        TVM_baseline = TrainValidationManager(use_info, phase2_epochs, dataloader_baseline, \n",
    "                                              batch_size, rand_state, results_path, final_analysis=False)\n",
    "        TVM_baseline.train_model(DO_baseline, AM_baseline, model_baseline, final_analysis=False)\n",
    "        \n",
    "        model_baseline.load_state_dict(torch.load(TVM_baseline.weights_save_path))\n",
    "        model_baseline.eval()\n",
    "        \n",
    "        if use_info == 'partial info':\n",
    "            test_pred = model_baseline(DO_baseline.full_test_input_tensor)\n",
    "        else:\n",
    "            test_pred = model_baseline(DO_baseline.known_test_input_tensor)\n",
    "        \n",
    "        test_true = DO_baseline.df_test[target_vars].values\n",
    "        r2 = r2_score(test_true, test_pred.detach().numpy())\n",
    "        results_summary[use_info] = r2\n",
    "        print(f\"{use_info}: R2 = {r2:.4f}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    best_baseline = max(results_summary['partial info'], results_summary['use known only'])\n",
    "    improvement = (results_summary['Phase 2 (GGH)'] - best_baseline) * 100\n",
    "    \n",
    "    for name, r2 in results_summary.items():\n",
    "        print(f\"  {name}: R2 = {r2:.4f}\")\n",
    "    print(f\"\\nGGH improvement over best baseline: {improvement:+.2f} percentage points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "si5ugma9fag",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ORACLE BENCHMARK: 100% Correct Hypothesis Selection\n",
      "======================================================================\n",
      "\n",
      "4-class: [9.4, 10.0, 10.8, 12.0]\n",
      "--------------------------------------------------\n",
      "  Seed 0: R²=0.3302\n",
      "  Seed 1: R²=0.3664\n",
      "  Seed 2: R²=0.3195\n",
      "  Seed 3: R²=0.2783\n",
      "  Seed 4: R²=0.2817\n",
      "  Seed 5: R²=0.2158\n",
      "  Seed 6: R²=0.3142\n",
      "  Seed 7: R²=0.3382\n",
      "  Seed 8: R²=0.3412\n",
      "  Seed 9: R²=0.3610\n",
      "  Seed 10: R²=0.2063\n",
      "  Seed 11: R²=0.3496\n",
      "  Seed 12: R²=0.3465\n",
      "  Seed 13: R²=0.2081\n",
      "  Seed 14: R²=0.2446\n",
      "\n",
      "  4-class R²: 0.3001 ± 0.0551\n",
      "\n",
      "3-class: [9.4, 10.5, 12.0]\n",
      "--------------------------------------------------\n",
      "  Seed 0: R²=0.3211\n",
      "  Seed 1: R²=0.3626\n",
      "  Seed 2: R²=0.3129\n",
      "  Seed 3: R²=0.2801\n",
      "  Seed 4: R²=0.2887\n",
      "  Seed 5: R²=0.2230\n",
      "  Seed 6: R²=0.3104\n",
      "  Seed 7: R²=0.3377\n",
      "  Seed 8: R²=0.3470\n",
      "  Seed 9: R²=0.3603\n",
      "  Seed 10: R²=0.2137\n",
      "  Seed 11: R²=0.3463\n",
      "  Seed 12: R²=0.3510\n",
      "  Seed 13: R²=0.2257\n",
      "  Seed 14: R²=0.2500\n",
      "\n",
      "  3-class R²: 0.3020 ± 0.0507\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "  4-class        : R² = 0.3001 ± 0.0551\n",
      "  3-class        : R² = 0.3020 ± 0.0507\n",
      "\n",
      "This is the CEILING - actual selection methods will be lower.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ORACLE BENCHMARK: Theoretical Ceiling with Perfect Selection\n",
    "# =============================================================================\n",
    "# Simple benchmark: Train on correct hypotheses only (100% precision)\n",
    "# This is the CEILING for any hypothesis selection approach.\n",
    "\n",
    "def run_oracle_experiment(rand_state, hypothesis_values, n_epochs=200, verbose=False):\n",
    "    \"\"\"\n",
    "    Oracle benchmark: Train on correct hypotheses only.\n",
    "    Simple PyTorch training - no GGH overhead.\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import r2_score\n",
    "    \n",
    "    set_to_deterministic(rand_state)\n",
    "    \n",
    "    # Setup DataOperator with specified hypotheses\n",
    "    hyp_config = [hypothesis_values]\n",
    "    DO_oracle = DataOperator(data_path, inpt_vars, target_vars, miss_vars, hyp_config,\n",
    "                             partial_perc=partial_perc, rand_state=rand_state)\n",
    "    \n",
    "    # Get only CORRECT hypothesis rows\n",
    "    correct_mask = DO_oracle.df_train_hypothesis['correct_hypothesis'] == True\n",
    "    \n",
    "    # Prepare training data: input features + hypothesis value\n",
    "    feature_cols = inpt_vars + [f'{mv}_hypothesis' for mv in miss_vars]\n",
    "    X_train = DO_oracle.df_train_hypothesis[correct_mask][feature_cols].values\n",
    "    y_train = DO_oracle.df_train_hypothesis[correct_mask][target_vars].values\n",
    "    \n",
    "    X_train_t = torch.FloatTensor(X_train)\n",
    "    y_train_t = torch.FloatTensor(y_train)\n",
    "    \n",
    "    # Simple model\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(len(feature_cols), hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(hidden_size, hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(hidden_size, output_size)\n",
    "    )\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "    \n",
    "    # Train\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_t)\n",
    "        loss = criterion(outputs, y_train_t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluate on test set (using actual alcohol values)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_test = DO_oracle.df_test[inpt_vars + miss_vars].values\n",
    "        y_test = DO_oracle.df_test[target_vars].values\n",
    "        \n",
    "        X_test_t = torch.FloatTensor(X_test)\n",
    "        predictions = model(X_test_t).numpy()\n",
    "        \n",
    "        r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"  Seed {rand_state}: R²={r2:.4f}\")\n",
    "    \n",
    "    return {'r2': r2, 'n_classes': len(hypothesis_values)}\n",
    "\n",
    "# Test configurations\n",
    "configs = {\n",
    "    '4-class': [9.4, 10.0, 10.8, 12.0],\n",
    "    '3-class': [9.4, 10.5, 12.0],\n",
    "}\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ORACLE BENCHMARK: 100% Correct Hypothesis Selection\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "all_results = {}\n",
    "for config_name, hyp_values in configs.items():\n",
    "    print(f\"\\n{config_name}: {hyp_values}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    results = []\n",
    "    for seed in range(15):\n",
    "        result = run_oracle_experiment(seed, hyp_values, n_epochs=phase2_epochs, verbose=True)\n",
    "        results.append(result)\n",
    "    \n",
    "    r2_mean = np.mean([r['r2'] for r in results])\n",
    "    r2_std = np.std([r['r2'] for r in results])\n",
    "    all_results[config_name] = {'mean': r2_mean, 'std': r2_std}\n",
    "    \n",
    "    print(f\"\\n  {config_name} R²: {r2_mean:.4f} ± {r2_std:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "for config_name, data in all_results.items():\n",
    "    print(f\"  {config_name:15s}: R² = {data['mean']:.4f} ± {data['std']:.4f}\")\n",
    "print()\n",
    "print(\"This is the CEILING - actual selection methods will be lower.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next_steps",
   "metadata": {},
   "source": [
    "## Conclusions & Next Steps\n",
    "\n",
    "**Key questions answered:**\n",
    "1. Does Phase 1 (unbiased training) show separation between correct/incorrect hypotheses?\n",
    "2. Does the hypothesis-amplifying architecture improve separation?\n",
    "3. Can within-sample loss ranking identify correct hypotheses better than random?\n",
    "\n",
    "**If Phase 1 shows good signal:**\n",
    "- Use Phase 1 loss rankings to initialize GGH selection\n",
    "- Pre-filter clearly wrong hypotheses before Phase 2\n",
    "- Weight hypothesis contributions by Phase 1 confidence\n",
    "\n",
    "**If Phase 1 shows poor signal:**\n",
    "- The fundamental problem may be that hypothesis differences are too small\n",
    "- Consider stronger hypothesis-amplifying architectures\n",
    "- Or alternative approaches entirely (e.g., meta-learning, ensemble methods)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-michael_20250605]",
   "language": "python",
   "name": "conda-env-.conda-michael_20250605-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
