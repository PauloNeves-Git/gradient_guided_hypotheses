{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Wine_Claude: Targeted Parameter Search for GGH\n",
    "\n",
    "This notebook systematically tests different parameter configurations to find\n",
    "settings where gradient-guided hypothesis selection significantly outperforms baselines.\n",
    "\n",
    "**Goal**: Find configuration where `use hypothesis` R2 score is at least 4.5 percentage points\n",
    "higher than the best baseline (`partial info` or `use known only`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "sys.path.insert(0, '../GGH')\n",
    "\n",
    "from GGH.data_ops import DataOperator\n",
    "from GGH.selection_algorithms import AlgoModulators\n",
    "from GGH.models import initialize_model, load_model\n",
    "from GGH.train_val_loop import TrainValidationManager\n",
    "from GGH.inspector import Inspector, visualize_train_val_error, selection_histograms, clean_final_analysis\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def set_to_deterministic(rand_state):\n",
    "    import random\n",
    "    random.seed(rand_state)\n",
    "    np.random.seed(rand_state)\n",
    "    torch.manual_seed(rand_state)\n",
    "    torch.set_num_threads(1)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    \n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data configuration\n",
    "data_path = '../data/wine/red_wine.csv'\n",
    "results_path = \"../saved_results/Red Wine Claude\"\n",
    "inpt_vars = ['volatile acidity', 'total sulfur dioxide', 'citric acid'] \n",
    "target_vars = ['quality']\n",
    "miss_vars = ['alcohol']\n",
    "hypothesis = [[9.35, 10, 11.5, 15]]\n",
    "\n",
    "# Model parameters\n",
    "hidden_size = 32\n",
    "batch_size = 100 * len(hypothesis[0])  # 400\n",
    "output_size = len(target_vars)\n",
    "\n",
    "# Create directories\n",
    "import os\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "for folder in ['use hypothesis', 'partial info', 'use known only', 'full info']:\n",
    "    os.makedirs(f'{results_path}/{folder}', exist_ok=True)\n",
    "\n",
    "# Initialize inspector\n",
    "INSPECT = Inspector(results_path, hidden_size)\n",
    "print(f\"Results will be saved to: {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_config(use_info, partial_perc, num_epochs, lr, nu, normalize, freqperc, \n",
    "                dropout=0.05, n_runs=5, verbose=False):\n",
    "    \"\"\"\n",
    "    Test a configuration and return R2 scores across multiple runs.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    valid_runs = 0\n",
    "    \n",
    "    for r_state in range(500):  # Try up to 500 random states to get n_runs valid ones\n",
    "        set_to_deterministic(r_state)\n",
    "        \n",
    "        DO = DataOperator(data_path, inpt_vars, target_vars, miss_vars, hypothesis,\n",
    "                          partial_perc, r_state, device='cpu')\n",
    "        DO.problem_type = 'regression'\n",
    "        \n",
    "        if not DO.lack_partial_coverage:\n",
    "            AM = AlgoModulators(DO, lr=lr, nu=nu, normalize_grads_contx=normalize,\n",
    "                               use_context=True, freqperc_cutoff=freqperc)\n",
    "            dataloader = DO.prep_dataloader(use_info, batch_size)\n",
    "            model = initialize_model(DO, dataloader, hidden_size, r_state, dropout=dropout)\n",
    "            \n",
    "            TVM = TrainValidationManager(use_info, num_epochs, dataloader, batch_size,\n",
    "                                         r_state, results_path, final_analysis=False)\n",
    "            TVM.train_model(DO, AM, model, final_analysis=False)\n",
    "            \n",
    "            # Load best model and evaluate\n",
    "            model.load_state_dict(torch.load(TVM.weights_save_path))\n",
    "            model.eval()\n",
    "            \n",
    "            if use_info in ['use hypothesis', 'partial info', 'full info']:\n",
    "                test_pred = model(DO.full_test_input_tensor)\n",
    "            else:\n",
    "                test_pred = model(DO.known_test_input_tensor)\n",
    "            \n",
    "            test_true = DO.df_test[target_vars].values\n",
    "            r2 = r2_score(test_true, test_pred.detach().numpy())\n",
    "            results.append(r2)\n",
    "            valid_runs += 1\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"  Run {valid_runs} (seed={r_state}): R2={r2:.4f}\")\n",
    "            \n",
    "            if valid_runs >= n_runs:\n",
    "                break\n",
    "    \n",
    "    return np.mean(results), np.std(results), results\n",
    "\n",
    "print(\"Test function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baseline_header",
   "metadata": {},
   "source": [
    "## Step 1: Establish Baselines\n",
    "\n",
    "Test both `partial_perc=0.015` and `partial_perc=0.025` to find which gives better opportunity for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baselines_015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baselines with partial_perc = 0.015 (1.5% complete data)\n",
    "partial_perc = 0.015\n",
    "n_baseline_runs = 5\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"BASELINES with partial_perc = {partial_perc}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "print(\"Testing partial info...\")\n",
    "p_mean_015, p_std_015, p_results_015 = test_config(\n",
    "    'partial info', partial_perc, 200, 0.001, 0.1, False, 0.25, n_runs=n_baseline_runs\n",
    ")\n",
    "print(f\"  partial info: {p_mean_015:.4f} +/- {p_std_015:.4f}\")\n",
    "print(f\"  Individual: {[f'{r:.4f}' for r in p_results_015]}\")\n",
    "\n",
    "print(\"\\nTesting use known only...\")\n",
    "k_mean_015, k_std_015, k_results_015 = test_config(\n",
    "    'use known only', partial_perc, 200, 0.001, 0.1, False, 0.25, n_runs=n_baseline_runs\n",
    ")\n",
    "print(f\"  use known only: {k_mean_015:.4f} +/- {k_std_015:.4f}\")\n",
    "print(f\"  Individual: {[f'{r:.4f}' for r in k_results_015]}\")\n",
    "\n",
    "best_baseline_015 = max(p_mean_015, k_mean_015)\n",
    "target_015 = best_baseline_015 + 0.045\n",
    "print(f\"\\nBest baseline: {best_baseline_015:.4f}\")\n",
    "print(f\"Target (baseline + 4.5pp): {target_015:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baselines_025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baselines with partial_perc = 0.025 (2.5% complete data)\n",
    "partial_perc = 0.025\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"BASELINES with partial_perc = {partial_perc}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "print(\"Testing partial info...\")\n",
    "p_mean_025, p_std_025, p_results_025 = test_config(\n",
    "    'partial info', partial_perc, 200, 0.001, 0.1, False, 0.25, n_runs=n_baseline_runs\n",
    ")\n",
    "print(f\"  partial info: {p_mean_025:.4f} +/- {p_std_025:.4f}\")\n",
    "print(f\"  Individual: {[f'{r:.4f}' for r in p_results_025]}\")\n",
    "\n",
    "print(\"\\nTesting use known only...\")\n",
    "k_mean_025, k_std_025, k_results_025 = test_config(\n",
    "    'use known only', partial_perc, 200, 0.001, 0.1, False, 0.25, n_runs=n_baseline_runs\n",
    ")\n",
    "print(f\"  use known only: {k_mean_025:.4f} +/- {k_std_025:.4f}\")\n",
    "print(f\"  Individual: {[f'{r:.4f}' for r in k_results_025]}\")\n",
    "\n",
    "best_baseline_025 = max(p_mean_025, k_mean_025)\n",
    "target_025 = best_baseline_025 + 0.045\n",
    "print(f\"\\nBest baseline: {best_baseline_025:.4f}\")\n",
    "print(f\"Target (baseline + 4.5pp): {target_025:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baseline_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of baselines\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BASELINE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\npartial_perc=0.015: best baseline={best_baseline_015:.4f}, target={target_015:.4f}\")\n",
    "print(f\"partial_perc=0.025: best baseline={best_baseline_025:.4f}, target={target_025:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "search_header",
   "metadata": {},
   "source": [
    "## Step 2: Targeted Parameter Search\n",
    "\n",
    "Test promising configurations for `use hypothesis` method.\n",
    "\n",
    "**Key parameters:**\n",
    "- `nu`: OneClassSVM parameter (lower = more permissive selection)\n",
    "- `lr`: Learning rate\n",
    "- `freqperc_cutoff`: Frequency threshold for final selection\n",
    "- `normalize_grads_contx`: Whether to normalize gradients + context\n",
    "- `num_epochs`: Training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parameter_configs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define configurations to test\n",
    "# Format: (nu, lr, freqperc_cutoff, normalize, epochs, description)\n",
    "configs_to_test = [\n",
    "    # Baseline-like configs\n",
    "    (0.10, 0.001, 0.25, False, 60, \"baseline\"),\n",
    "    \n",
    "    # Vary nu (selection restrictiveness)\n",
    "    (0.05, 0.001, 0.25, False, 60, \"low nu\"),\n",
    "    (0.08, 0.001, 0.25, False, 60, \"med-low nu\"),\n",
    "    (0.15, 0.001, 0.25, False, 60, \"med-high nu\"),\n",
    "    (0.20, 0.001, 0.25, False, 60, \"high nu\"),\n",
    "    \n",
    "    # Vary learning rate\n",
    "    (0.10, 0.002, 0.25, False, 60, \"higher lr\"),\n",
    "    (0.10, 0.004, 0.25, False, 60, \"high lr\"),\n",
    "    (0.10, 0.0005, 0.25, False, 60, \"low lr\"),\n",
    "    \n",
    "    # Vary frequency cutoff\n",
    "    (0.10, 0.001, 0.15, False, 60, \"low freq cutoff\"),\n",
    "    (0.10, 0.001, 0.20, False, 60, \"med-low freq cutoff\"),\n",
    "    (0.10, 0.001, 0.33, False, 60, \"high freq cutoff\"),\n",
    "    (0.10, 0.001, 0.40, False, 60, \"very high freq cutoff\"),\n",
    "    \n",
    "    # With normalization\n",
    "    (0.10, 0.001, 0.25, True, 60, \"with normalize\"),\n",
    "    (0.10, 0.002, 0.25, True, 60, \"normalize + higher lr\"),\n",
    "    (0.15, 0.002, 0.25, True, 60, \"normalize + higher nu + lr\"),\n",
    "    \n",
    "    # Vary epochs\n",
    "    (0.10, 0.001, 0.25, False, 30, \"fewer epochs\"),\n",
    "    (0.10, 0.001, 0.25, False, 40, \"40 epochs\"),\n",
    "    (0.10, 0.001, 0.25, False, 80, \"more epochs\"),\n",
    "    (0.10, 0.001, 0.25, False, 100, \"100 epochs\"),\n",
    "    \n",
    "    # Combined promising configs\n",
    "    (0.08, 0.002, 0.20, False, 60, \"combined 1\"),\n",
    "    (0.08, 0.002, 0.20, True, 60, \"combined 2 + norm\"),\n",
    "    (0.12, 0.002, 0.25, False, 50, \"combined 3\"),\n",
    "    (0.10, 0.003, 0.20, False, 50, \"combined 4\"),\n",
    "    (0.15, 0.002, 0.30, False, 60, \"combined 5\"),\n",
    "]\n",
    "\n",
    "print(f\"Total configurations to test: {len(configs_to_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "search_015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with partial_perc = 0.015\n",
    "partial_perc = 0.015\n",
    "best_baseline = best_baseline_015\n",
    "target = target_015\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PARAMETER SEARCH with partial_perc = {partial_perc}\")\n",
    "print(f\"Best baseline: {best_baseline:.4f}, Target: {target:.4f}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "results_015 = []\n",
    "best_r2_015 = 0\n",
    "best_config_015 = None\n",
    "\n",
    "for i, (nu, lr, freqperc, normalize, epochs, desc) in enumerate(configs_to_test):\n",
    "    print(f\"[{i+1}/{len(configs_to_test)}] Testing {desc}...\", end=\" \")\n",
    "    \n",
    "    h_mean, h_std, h_results = test_config(\n",
    "        'use hypothesis', partial_perc, epochs, lr, nu, normalize, freqperc, n_runs=3\n",
    "    )\n",
    "    \n",
    "    improvement = (h_mean - best_baseline) * 100\n",
    "    results_015.append({\n",
    "        'desc': desc, 'nu': nu, 'lr': lr, 'freqperc': freqperc,\n",
    "        'normalize': normalize, 'epochs': epochs,\n",
    "        'mean_r2': h_mean, 'std_r2': h_std, 'improvement_pp': improvement\n",
    "    })\n",
    "    \n",
    "    marker = \"***\" if improvement >= 4.5 else (\"**\" if improvement >= 2.0 else (\"*\" if improvement > 0 else \"\"))\n",
    "    print(f\"R2={h_mean:.4f} ({improvement:+.2f}pp) {marker}\")\n",
    "    \n",
    "    if h_mean > best_r2_015:\n",
    "        best_r2_015 = h_mean\n",
    "        best_config_015 = (nu, lr, freqperc, normalize, epochs, desc)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"BEST for partial_perc={partial_perc}:\")\n",
    "print(f\"  R2 = {best_r2_015:.4f} (improvement: {(best_r2_015-best_baseline)*100:.2f}pp)\")\n",
    "print(f\"  Config: {best_config_015}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "search_025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with partial_perc = 0.025\n",
    "partial_perc = 0.025\n",
    "best_baseline = best_baseline_025\n",
    "target = target_025\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PARAMETER SEARCH with partial_perc = {partial_perc}\")\n",
    "print(f\"Best baseline: {best_baseline:.4f}, Target: {target:.4f}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "results_025 = []\n",
    "best_r2_025 = 0\n",
    "best_config_025 = None\n",
    "\n",
    "for i, (nu, lr, freqperc, normalize, epochs, desc) in enumerate(configs_to_test):\n",
    "    print(f\"[{i+1}/{len(configs_to_test)}] Testing {desc}...\", end=\" \")\n",
    "    \n",
    "    h_mean, h_std, h_results = test_config(\n",
    "        'use hypothesis', partial_perc, epochs, lr, nu, normalize, freqperc, n_runs=3\n",
    "    )\n",
    "    \n",
    "    improvement = (h_mean - best_baseline) * 100\n",
    "    results_025.append({\n",
    "        'desc': desc, 'nu': nu, 'lr': lr, 'freqperc': freqperc,\n",
    "        'normalize': normalize, 'epochs': epochs,\n",
    "        'mean_r2': h_mean, 'std_r2': h_std, 'improvement_pp': improvement\n",
    "    })\n",
    "    \n",
    "    marker = \"***\" if improvement >= 4.5 else (\"**\" if improvement >= 2.0 else (\"*\" if improvement > 0 else \"\"))\n",
    "    print(f\"R2={h_mean:.4f} ({improvement:+.2f}pp) {marker}\")\n",
    "    \n",
    "    if h_mean > best_r2_025:\n",
    "        best_r2_025 = h_mean\n",
    "        best_config_025 = (nu, lr, freqperc, normalize, epochs, desc)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"BEST for partial_perc={partial_perc}:\")\n",
    "print(f\"  R2 = {best_r2_025:.4f} (improvement: {(best_r2_025-best_baseline_025)*100:.2f}pp)\")\n",
    "print(f\"  Config: {best_config_025}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results_table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results as tables\n",
    "print(\"\\nResults for partial_perc=0.015:\")\n",
    "df_015 = pd.DataFrame(results_015).sort_values('mean_r2', ascending=False)\n",
    "print(df_015[['desc', 'nu', 'lr', 'freqperc', 'normalize', 'epochs', 'mean_r2', 'improvement_pp']].head(10).to_string())\n",
    "\n",
    "print(\"\\n\\nResults for partial_perc=0.025:\")\n",
    "df_025 = pd.DataFrame(results_025).sort_values('mean_r2', ascending=False)\n",
    "print(df_025[['desc', 'nu', 'lr', 'freqperc', 'normalize', 'epochs', 'mean_r2', 'improvement_pp']].head(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation_header",
   "metadata": {},
   "source": [
    "## Step 3: Validate Best Configuration (15 runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which partial_perc showed better improvement\n",
    "improvement_015 = (best_r2_015 - best_baseline_015) * 100\n",
    "improvement_025 = (best_r2_025 - best_baseline_025) * 100\n",
    "\n",
    "if improvement_015 > improvement_025:\n",
    "    final_partial_perc = 0.015\n",
    "    final_config = best_config_015\n",
    "    final_baseline = best_baseline_015\n",
    "else:\n",
    "    final_partial_perc = 0.025\n",
    "    final_config = best_config_025\n",
    "    final_baseline = best_baseline_025\n",
    "\n",
    "nu, lr, freqperc, normalize, epochs, desc = final_config\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FINAL VALIDATION (15 runs)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nSelected: partial_perc={final_partial_perc}\")\n",
    "print(f\"Config: nu={nu}, lr={lr}, freqperc={freqperc}, normalize={normalize}, epochs={epochs}\")\n",
    "print(f\"\\nRunning 15 validation runs...\")\n",
    "\n",
    "h_mean_final, h_std_final, h_results_final = test_config(\n",
    "    'use hypothesis', final_partial_perc, epochs, lr, nu, normalize, freqperc, \n",
    "    n_runs=15, verbose=True\n",
    ")\n",
    "\n",
    "final_improvement = (h_mean_final - final_baseline) * 100\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FINAL RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Use Hypothesis R2: {h_mean_final:.4f} +/- {h_std_final:.4f}\")\n",
    "print(f\"Best Baseline R2:  {final_baseline:.4f}\")\n",
    "print(f\"Improvement:       {final_improvement:.2f} percentage points\")\n",
    "print(f\"Target achieved:   {'YES!' if final_improvement >= 4.5 else 'Not yet'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
